{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualizing an image data set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkNTfAMTH3ba7J46EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6b3eeb438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "label = mnist.train.labels[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(inputs):\n",
    "    conv = tf.layers.conv2d(inputs, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    conv = tf.layers.max_pooling2d(conv, 16, (2,2), padding='same')\n",
    "    \n",
    "    conv = tf.layers.conv2d(conv, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    conv = tf.layers.max_pooling2d(conv, 8, (2,2), padding='same')\n",
    "    \n",
    "    conv = tf.layers.conv2d(conv, 4, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    conv = tf.layers.max_pooling2d(conv, 4, (2,2), padding='same')\n",
    "    \n",
    "    conv = tf.contrib.layers.flatten(conv)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10, activation_fn=tf.nn.softmax)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='x')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='y')\n",
    "\n",
    "#Building the network\n",
    "\n",
    "logits = conv_net(x)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Network training hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Training helper functions    \n",
    "\n",
    "def train_neural_network(session, optimizer, feature_batch, label_batch):\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "    })\n",
    "    \n",
    "def print_training_stats(session, epoch, batch_i, feature_batch, label_batch, validation_feature, validation_label, cost, accuracy):\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x: validation_feature,\n",
    "                y: validation_label })\n",
    "    print('Epoch {:>2}, MNIST Batch {}: Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch + 1, batch_i, loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, MNIST Batch 0: Loss:     2.3024 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 1: Loss:     2.3022 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 2: Loss:     2.3020 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 3: Loss:     2.3015 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 4: Loss:     2.3016 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 5: Loss:     2.3026 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 6: Loss:     2.3024 Validation Accuracy: 0.107000\n",
      "Epoch  1, MNIST Batch 7: Loss:     2.3011 Validation Accuracy: 0.107800\n",
      "Epoch  1, MNIST Batch 8: Loss:     2.3040 Validation Accuracy: 0.125600\n",
      "Epoch  1, MNIST Batch 9: Loss:     2.3022 Validation Accuracy: 0.150800\n",
      "Epoch  1, MNIST Batch 10: Loss:     2.3026 Validation Accuracy: 0.116800\n",
      "Epoch  1, MNIST Batch 11: Loss:     2.3023 Validation Accuracy: 0.103600\n",
      "Epoch  1, MNIST Batch 12: Loss:     2.3030 Validation Accuracy: 0.099800\n",
      "Epoch  1, MNIST Batch 13: Loss:     2.3036 Validation Accuracy: 0.096800\n",
      "Epoch  1, MNIST Batch 14: Loss:     2.3020 Validation Accuracy: 0.095400\n",
      "Epoch  1, MNIST Batch 15: Loss:     2.3028 Validation Accuracy: 0.097000\n",
      "Epoch  1, MNIST Batch 16: Loss:     2.3018 Validation Accuracy: 0.103400\n",
      "Epoch  1, MNIST Batch 17: Loss:     2.3020 Validation Accuracy: 0.115400\n",
      "Epoch  1, MNIST Batch 18: Loss:     2.3021 Validation Accuracy: 0.127200\n",
      "Epoch  1, MNIST Batch 19: Loss:     2.3019 Validation Accuracy: 0.135200\n",
      "Epoch  1, MNIST Batch 20: Loss:     2.3013 Validation Accuracy: 0.140600\n",
      "Epoch  1, MNIST Batch 21: Loss:     2.3021 Validation Accuracy: 0.143800\n",
      "Epoch  1, MNIST Batch 22: Loss:     2.3017 Validation Accuracy: 0.141000\n",
      "Epoch  1, MNIST Batch 23: Loss:     2.3018 Validation Accuracy: 0.130600\n",
      "Epoch  1, MNIST Batch 24: Loss:     2.3018 Validation Accuracy: 0.120200\n",
      "Epoch  1, MNIST Batch 25: Loss:     2.3010 Validation Accuracy: 0.110000\n",
      "Epoch  1, MNIST Batch 26: Loss:     2.3013 Validation Accuracy: 0.104000\n",
      "Epoch  1, MNIST Batch 27: Loss:     2.3003 Validation Accuracy: 0.098800\n",
      "Epoch  1, MNIST Batch 28: Loss:     2.3010 Validation Accuracy: 0.094200\n",
      "Epoch  1, MNIST Batch 29: Loss:     2.2994 Validation Accuracy: 0.092800\n",
      "Epoch  1, MNIST Batch 30: Loss:     2.3015 Validation Accuracy: 0.092600\n",
      "Epoch  1, MNIST Batch 31: Loss:     2.3012 Validation Accuracy: 0.093400\n",
      "Epoch  1, MNIST Batch 32: Loss:     2.3005 Validation Accuracy: 0.093400\n",
      "Epoch  1, MNIST Batch 33: Loss:     2.3000 Validation Accuracy: 0.094800\n",
      "Epoch  1, MNIST Batch 34: Loss:     2.3004 Validation Accuracy: 0.096200\n",
      "Epoch  1, MNIST Batch 35: Loss:     2.2998 Validation Accuracy: 0.095200\n",
      "Epoch  1, MNIST Batch 36: Loss:     2.2998 Validation Accuracy: 0.095400\n",
      "Epoch  1, MNIST Batch 37: Loss:     2.2996 Validation Accuracy: 0.095400\n",
      "Epoch  1, MNIST Batch 38: Loss:     2.2999 Validation Accuracy: 0.098000\n",
      "Epoch  1, MNIST Batch 39: Loss:     2.2973 Validation Accuracy: 0.096200\n",
      "Epoch  1, MNIST Batch 40: Loss:     2.2974 Validation Accuracy: 0.094200\n",
      "Epoch  1, MNIST Batch 41: Loss:     2.2972 Validation Accuracy: 0.093600\n",
      "Epoch  1, MNIST Batch 42: Loss:     2.2992 Validation Accuracy: 0.093400\n",
      "Epoch  1, MNIST Batch 43: Loss:     2.2980 Validation Accuracy: 0.094000\n",
      "Epoch  1, MNIST Batch 44: Loss:     2.2960 Validation Accuracy: 0.094200\n",
      "Epoch  1, MNIST Batch 45: Loss:     2.3002 Validation Accuracy: 0.095000\n",
      "Epoch  1, MNIST Batch 46: Loss:     2.2972 Validation Accuracy: 0.097200\n",
      "Epoch  1, MNIST Batch 47: Loss:     2.2946 Validation Accuracy: 0.099000\n",
      "Epoch  1, MNIST Batch 48: Loss:     2.2956 Validation Accuracy: 0.102600\n",
      "Epoch  1, MNIST Batch 49: Loss:     2.2963 Validation Accuracy: 0.111000\n",
      "Epoch  1, MNIST Batch 50: Loss:     2.2960 Validation Accuracy: 0.124200\n",
      "Epoch  1, MNIST Batch 51: Loss:     2.2922 Validation Accuracy: 0.137400\n",
      "Epoch  1, MNIST Batch 52: Loss:     2.2932 Validation Accuracy: 0.142200\n",
      "Epoch  1, MNIST Batch 53: Loss:     2.2968 Validation Accuracy: 0.140800\n",
      "Epoch  1, MNIST Batch 54: Loss:     2.2957 Validation Accuracy: 0.136400\n",
      "Epoch  1, MNIST Batch 55: Loss:     2.2923 Validation Accuracy: 0.130600\n",
      "Epoch  1, MNIST Batch 56: Loss:     2.2955 Validation Accuracy: 0.128800\n",
      "Epoch  1, MNIST Batch 57: Loss:     2.2901 Validation Accuracy: 0.124400\n",
      "Epoch  1, MNIST Batch 58: Loss:     2.2914 Validation Accuracy: 0.122800\n",
      "Epoch  1, MNIST Batch 59: Loss:     2.2880 Validation Accuracy: 0.124600\n",
      "Epoch  1, MNIST Batch 60: Loss:     2.2913 Validation Accuracy: 0.126000\n",
      "Epoch  1, MNIST Batch 61: Loss:     2.2876 Validation Accuracy: 0.132200\n",
      "Epoch  1, MNIST Batch 62: Loss:     2.2859 Validation Accuracy: 0.139200\n",
      "Epoch  1, MNIST Batch 63: Loss:     2.2905 Validation Accuracy: 0.148200\n",
      "Epoch  1, MNIST Batch 64: Loss:     2.2848 Validation Accuracy: 0.150600\n",
      "Epoch  1, MNIST Batch 65: Loss:     2.2832 Validation Accuracy: 0.148600\n",
      "Epoch  1, MNIST Batch 66: Loss:     2.2804 Validation Accuracy: 0.137200\n",
      "Epoch  1, MNIST Batch 67: Loss:     2.2780 Validation Accuracy: 0.124000\n",
      "Epoch  1, MNIST Batch 68: Loss:     2.2742 Validation Accuracy: 0.112800\n",
      "Epoch  1, MNIST Batch 69: Loss:     2.2795 Validation Accuracy: 0.109000\n",
      "Epoch  1, MNIST Batch 70: Loss:     2.2821 Validation Accuracy: 0.109400\n",
      "Epoch  1, MNIST Batch 71: Loss:     2.2800 Validation Accuracy: 0.109200\n",
      "Epoch  1, MNIST Batch 72: Loss:     2.2816 Validation Accuracy: 0.110800\n",
      "Epoch  1, MNIST Batch 73: Loss:     2.2723 Validation Accuracy: 0.110600\n",
      "Epoch  1, MNIST Batch 74: Loss:     2.2818 Validation Accuracy: 0.110800\n",
      "Epoch  1, MNIST Batch 75: Loss:     2.2707 Validation Accuracy: 0.110400\n",
      "Epoch  1, MNIST Batch 76: Loss:     2.2798 Validation Accuracy: 0.112400\n",
      "Epoch  1, MNIST Batch 77: Loss:     2.2745 Validation Accuracy: 0.117600\n",
      "Epoch  1, MNIST Batch 78: Loss:     2.2797 Validation Accuracy: 0.139800\n",
      "Epoch  1, MNIST Batch 79: Loss:     2.2713 Validation Accuracy: 0.163600\n",
      "Epoch  1, MNIST Batch 80: Loss:     2.2492 Validation Accuracy: 0.161800\n",
      "Epoch  1, MNIST Batch 81: Loss:     2.2562 Validation Accuracy: 0.136800\n",
      "Epoch  1, MNIST Batch 82: Loss:     2.2670 Validation Accuracy: 0.131600\n",
      "Epoch  1, MNIST Batch 83: Loss:     2.2770 Validation Accuracy: 0.148600\n",
      "Epoch  1, MNIST Batch 84: Loss:     2.2557 Validation Accuracy: 0.177600\n",
      "Epoch  1, MNIST Batch 85: Loss:     2.2600 Validation Accuracy: 0.199800\n",
      "Epoch  1, MNIST Batch 86: Loss:     2.2519 Validation Accuracy: 0.200000\n",
      "Epoch  1, MNIST Batch 87: Loss:     2.2543 Validation Accuracy: 0.193800\n",
      "Epoch  1, MNIST Batch 88: Loss:     2.2580 Validation Accuracy: 0.186000\n",
      "Epoch  1, MNIST Batch 89: Loss:     2.2615 Validation Accuracy: 0.193400\n",
      "Epoch  1, MNIST Batch 90: Loss:     2.2433 Validation Accuracy: 0.209600\n",
      "Epoch  1, MNIST Batch 91: Loss:     2.2485 Validation Accuracy: 0.228400\n",
      "Epoch  1, MNIST Batch 92: Loss:     2.2421 Validation Accuracy: 0.242800\n",
      "Epoch  1, MNIST Batch 93: Loss:     2.2271 Validation Accuracy: 0.237200\n",
      "Epoch  1, MNIST Batch 94: Loss:     2.2354 Validation Accuracy: 0.221600\n",
      "Epoch  1, MNIST Batch 95: Loss:     2.2462 Validation Accuracy: 0.224600\n",
      "Epoch  1, MNIST Batch 96: Loss:     2.2196 Validation Accuracy: 0.213600\n",
      "Epoch  1, MNIST Batch 97: Loss:     2.2126 Validation Accuracy: 0.221200\n",
      "Epoch  1, MNIST Batch 98: Loss:     2.2320 Validation Accuracy: 0.237000\n",
      "Epoch  1, MNIST Batch 99: Loss:     2.2202 Validation Accuracy: 0.238200\n",
      "Epoch  1, MNIST Batch 100: Loss:     2.2099 Validation Accuracy: 0.238000\n",
      "Epoch  1, MNIST Batch 101: Loss:     2.2179 Validation Accuracy: 0.263400\n",
      "Epoch  1, MNIST Batch 102: Loss:     2.1899 Validation Accuracy: 0.259800\n",
      "Epoch  1, MNIST Batch 103: Loss:     2.2187 Validation Accuracy: 0.265800\n",
      "Epoch  1, MNIST Batch 104: Loss:     2.2284 Validation Accuracy: 0.270600\n",
      "Epoch  1, MNIST Batch 105: Loss:     2.2261 Validation Accuracy: 0.271400\n",
      "Epoch  1, MNIST Batch 106: Loss:     2.2270 Validation Accuracy: 0.282800\n",
      "Epoch  1, MNIST Batch 107: Loss:     2.2151 Validation Accuracy: 0.277200\n",
      "Epoch  1, MNIST Batch 108: Loss:     2.2062 Validation Accuracy: 0.261400\n",
      "Epoch  1, MNIST Batch 109: Loss:     2.2122 Validation Accuracy: 0.266200\n",
      "Epoch  1, MNIST Batch 110: Loss:     2.1886 Validation Accuracy: 0.272800\n",
      "Epoch  1, MNIST Batch 111: Loss:     2.1704 Validation Accuracy: 0.285200\n",
      "Epoch  1, MNIST Batch 112: Loss:     2.1888 Validation Accuracy: 0.284400\n",
      "Epoch  1, MNIST Batch 113: Loss:     2.1657 Validation Accuracy: 0.293800\n",
      "Epoch  1, MNIST Batch 114: Loss:     2.2141 Validation Accuracy: 0.310400\n",
      "Epoch  1, MNIST Batch 115: Loss:     2.1737 Validation Accuracy: 0.322800\n",
      "Epoch  1, MNIST Batch 116: Loss:     2.1706 Validation Accuracy: 0.319800\n",
      "Epoch  1, MNIST Batch 117: Loss:     2.1877 Validation Accuracy: 0.293600\n",
      "Epoch  1, MNIST Batch 118: Loss:     2.2193 Validation Accuracy: 0.307000\n",
      "Epoch  1, MNIST Batch 119: Loss:     2.1871 Validation Accuracy: 0.334200\n",
      "Epoch  1, MNIST Batch 120: Loss:     2.2069 Validation Accuracy: 0.335200\n",
      "Epoch  1, MNIST Batch 121: Loss:     2.1742 Validation Accuracy: 0.338600\n",
      "Epoch  1, MNIST Batch 122: Loss:     2.1807 Validation Accuracy: 0.314000\n",
      "Epoch  1, MNIST Batch 123: Loss:     2.1905 Validation Accuracy: 0.312600\n",
      "Epoch  1, MNIST Batch 124: Loss:     2.1843 Validation Accuracy: 0.339800\n",
      "Epoch  1, MNIST Batch 125: Loss:     2.1536 Validation Accuracy: 0.344400\n",
      "Epoch  1, MNIST Batch 126: Loss:     2.1768 Validation Accuracy: 0.341400\n",
      "Epoch  1, MNIST Batch 127: Loss:     2.1375 Validation Accuracy: 0.348800\n",
      "Epoch  1, MNIST Batch 128: Loss:     2.1436 Validation Accuracy: 0.337200\n",
      "Epoch  1, MNIST Batch 129: Loss:     2.1353 Validation Accuracy: 0.328400\n",
      "Epoch  1, MNIST Batch 130: Loss:     2.1459 Validation Accuracy: 0.349200\n",
      "Epoch  1, MNIST Batch 131: Loss:     2.1428 Validation Accuracy: 0.354800\n",
      "Epoch  1, MNIST Batch 132: Loss:     2.1325 Validation Accuracy: 0.357800\n",
      "Epoch  1, MNIST Batch 133: Loss:     2.1777 Validation Accuracy: 0.358800\n",
      "Epoch  1, MNIST Batch 134: Loss:     2.1263 Validation Accuracy: 0.355200\n",
      "Epoch  1, MNIST Batch 135: Loss:     2.1381 Validation Accuracy: 0.353800\n",
      "Epoch  1, MNIST Batch 136: Loss:     2.1289 Validation Accuracy: 0.360200\n",
      "Epoch  1, MNIST Batch 137: Loss:     2.1216 Validation Accuracy: 0.361400\n",
      "Epoch  1, MNIST Batch 138: Loss:     2.1600 Validation Accuracy: 0.360000\n",
      "Epoch  1, MNIST Batch 139: Loss:     2.1192 Validation Accuracy: 0.363800\n",
      "Epoch  1, MNIST Batch 140: Loss:     2.1525 Validation Accuracy: 0.362200\n",
      "Epoch  1, MNIST Batch 141: Loss:     2.1341 Validation Accuracy: 0.362600\n",
      "Epoch  1, MNIST Batch 142: Loss:     2.1127 Validation Accuracy: 0.367400\n",
      "Epoch  1, MNIST Batch 143: Loss:     2.1215 Validation Accuracy: 0.368400\n",
      "Epoch  1, MNIST Batch 144: Loss:     2.1654 Validation Accuracy: 0.368200\n",
      "Epoch  1, MNIST Batch 145: Loss:     2.0918 Validation Accuracy: 0.368600\n",
      "Epoch  1, MNIST Batch 146: Loss:     2.1044 Validation Accuracy: 0.351400\n",
      "Epoch  1, MNIST Batch 147: Loss:     2.0949 Validation Accuracy: 0.355800\n",
      "Epoch  1, MNIST Batch 148: Loss:     2.0992 Validation Accuracy: 0.370800\n",
      "Epoch  1, MNIST Batch 149: Loss:     2.1213 Validation Accuracy: 0.358800\n",
      "Epoch  1, MNIST Batch 150: Loss:     2.1358 Validation Accuracy: 0.363600\n",
      "Epoch  1, MNIST Batch 151: Loss:     2.0944 Validation Accuracy: 0.374800\n",
      "Epoch  1, MNIST Batch 152: Loss:     2.1464 Validation Accuracy: 0.372600\n",
      "Epoch  1, MNIST Batch 153: Loss:     2.1046 Validation Accuracy: 0.371800\n",
      "Epoch  1, MNIST Batch 154: Loss:     2.0682 Validation Accuracy: 0.372800\n",
      "Epoch  1, MNIST Batch 155: Loss:     2.0990 Validation Accuracy: 0.376000\n",
      "Epoch  1, MNIST Batch 156: Loss:     2.1519 Validation Accuracy: 0.376800\n",
      "Epoch  1, MNIST Batch 157: Loss:     2.0990 Validation Accuracy: 0.375200\n",
      "Epoch  1, MNIST Batch 158: Loss:     2.0907 Validation Accuracy: 0.376000\n",
      "Epoch  1, MNIST Batch 159: Loss:     2.0501 Validation Accuracy: 0.377000\n",
      "Epoch  1, MNIST Batch 160: Loss:     2.0866 Validation Accuracy: 0.376600\n",
      "Epoch  1, MNIST Batch 161: Loss:     2.0651 Validation Accuracy: 0.371600\n",
      "Epoch  1, MNIST Batch 162: Loss:     2.1321 Validation Accuracy: 0.374600\n",
      "Epoch  1, MNIST Batch 163: Loss:     2.1423 Validation Accuracy: 0.377600\n",
      "Epoch  1, MNIST Batch 164: Loss:     2.0771 Validation Accuracy: 0.376000\n",
      "Epoch  1, MNIST Batch 165: Loss:     2.0762 Validation Accuracy: 0.377800\n",
      "Epoch  1, MNIST Batch 166: Loss:     2.0686 Validation Accuracy: 0.378200\n",
      "Epoch  1, MNIST Batch 167: Loss:     2.1160 Validation Accuracy: 0.378400\n",
      "Epoch  1, MNIST Batch 168: Loss:     2.0845 Validation Accuracy: 0.379000\n",
      "Epoch  1, MNIST Batch 169: Loss:     2.1043 Validation Accuracy: 0.379200\n",
      "Epoch  1, MNIST Batch 170: Loss:     2.1018 Validation Accuracy: 0.378200\n",
      "Epoch  1, MNIST Batch 171: Loss:     2.1536 Validation Accuracy: 0.379400\n",
      "Epoch  1, MNIST Batch 172: Loss:     2.0927 Validation Accuracy: 0.379600\n",
      "Epoch  1, MNIST Batch 173: Loss:     2.1038 Validation Accuracy: 0.379600\n",
      "Epoch  1, MNIST Batch 174: Loss:     2.0776 Validation Accuracy: 0.379800\n",
      "Epoch  1, MNIST Batch 175: Loss:     2.0682 Validation Accuracy: 0.379600\n",
      "Epoch  1, MNIST Batch 176: Loss:     2.0899 Validation Accuracy: 0.373200\n",
      "Epoch  1, MNIST Batch 177: Loss:     2.0823 Validation Accuracy: 0.378000\n",
      "Epoch  1, MNIST Batch 178: Loss:     2.0800 Validation Accuracy: 0.380800\n",
      "Epoch  1, MNIST Batch 179: Loss:     2.1220 Validation Accuracy: 0.380800\n",
      "Epoch  1, MNIST Batch 180: Loss:     2.1004 Validation Accuracy: 0.380000\n",
      "Epoch  1, MNIST Batch 181: Loss:     2.1164 Validation Accuracy: 0.378400\n",
      "Epoch  1, MNIST Batch 182: Loss:     2.0770 Validation Accuracy: 0.379000\n",
      "Epoch  1, MNIST Batch 183: Loss:     2.0533 Validation Accuracy: 0.383000\n",
      "Epoch  1, MNIST Batch 184: Loss:     2.0650 Validation Accuracy: 0.380400\n",
      "Epoch  1, MNIST Batch 185: Loss:     2.0671 Validation Accuracy: 0.380800\n",
      "Epoch  1, MNIST Batch 186: Loss:     2.1070 Validation Accuracy: 0.383000\n",
      "Epoch  1, MNIST Batch 187: Loss:     2.0814 Validation Accuracy: 0.382200\n",
      "Epoch  1, MNIST Batch 188: Loss:     2.0401 Validation Accuracy: 0.381000\n",
      "Epoch  1, MNIST Batch 189: Loss:     2.1505 Validation Accuracy: 0.381600\n",
      "Epoch  1, MNIST Batch 190: Loss:     2.0770 Validation Accuracy: 0.383000\n",
      "Epoch  1, MNIST Batch 191: Loss:     2.0729 Validation Accuracy: 0.382400\n",
      "Epoch  1, MNIST Batch 192: Loss:     2.0429 Validation Accuracy: 0.381800\n",
      "Epoch  1, MNIST Batch 193: Loss:     2.0591 Validation Accuracy: 0.384200\n",
      "Epoch  1, MNIST Batch 194: Loss:     2.0854 Validation Accuracy: 0.386600\n",
      "Epoch  1, MNIST Batch 195: Loss:     2.0967 Validation Accuracy: 0.384600\n",
      "Epoch  1, MNIST Batch 196: Loss:     2.0977 Validation Accuracy: 0.388600\n",
      "Epoch  1, MNIST Batch 197: Loss:     2.0124 Validation Accuracy: 0.388200\n",
      "Epoch  1, MNIST Batch 198: Loss:     2.0678 Validation Accuracy: 0.375400\n",
      "Epoch  1, MNIST Batch 199: Loss:     2.0508 Validation Accuracy: 0.378200\n",
      "Epoch  1, MNIST Batch 200: Loss:     2.0911 Validation Accuracy: 0.392400\n",
      "Epoch  1, MNIST Batch 201: Loss:     2.0573 Validation Accuracy: 0.397200\n",
      "Epoch  1, MNIST Batch 202: Loss:     2.1124 Validation Accuracy: 0.396400\n",
      "Epoch  1, MNIST Batch 203: Loss:     2.0729 Validation Accuracy: 0.399600\n",
      "Epoch  1, MNIST Batch 204: Loss:     2.0519 Validation Accuracy: 0.398200\n",
      "Epoch  1, MNIST Batch 205: Loss:     2.0431 Validation Accuracy: 0.404800\n",
      "Epoch  1, MNIST Batch 206: Loss:     2.0290 Validation Accuracy: 0.413200\n",
      "Epoch  1, MNIST Batch 207: Loss:     2.0264 Validation Accuracy: 0.419200\n",
      "Epoch  1, MNIST Batch 208: Loss:     2.1233 Validation Accuracy: 0.417200\n",
      "Epoch  1, MNIST Batch 209: Loss:     2.1077 Validation Accuracy: 0.411200\n",
      "Epoch  1, MNIST Batch 210: Loss:     2.0478 Validation Accuracy: 0.420200\n",
      "Epoch  1, MNIST Batch 211: Loss:     2.0446 Validation Accuracy: 0.426600\n",
      "Epoch  1, MNIST Batch 212: Loss:     2.0545 Validation Accuracy: 0.426000\n",
      "Epoch  1, MNIST Batch 213: Loss:     2.0440 Validation Accuracy: 0.427400\n",
      "Epoch  2, MNIST Batch 0: Loss:     2.0932 Validation Accuracy: 0.411400\n",
      "Epoch  2, MNIST Batch 1: Loss:     2.0118 Validation Accuracy: 0.411000\n",
      "Epoch  2, MNIST Batch 2: Loss:     2.0380 Validation Accuracy: 0.428400\n",
      "Epoch  2, MNIST Batch 3: Loss:     2.0053 Validation Accuracy: 0.432000\n",
      "Epoch  2, MNIST Batch 4: Loss:     2.0649 Validation Accuracy: 0.439400\n",
      "Epoch  2, MNIST Batch 5: Loss:     2.0347 Validation Accuracy: 0.436600\n",
      "Epoch  2, MNIST Batch 6: Loss:     2.0641 Validation Accuracy: 0.435800\n",
      "Epoch  2, MNIST Batch 7: Loss:     2.0515 Validation Accuracy: 0.440800\n",
      "Epoch  2, MNIST Batch 8: Loss:     2.0427 Validation Accuracy: 0.435400\n",
      "Epoch  2, MNIST Batch 9: Loss:     2.0843 Validation Accuracy: 0.439200\n",
      "Epoch  2, MNIST Batch 10: Loss:     2.0803 Validation Accuracy: 0.437800\n",
      "Epoch  2, MNIST Batch 11: Loss:     2.0694 Validation Accuracy: 0.423400\n",
      "Epoch  2, MNIST Batch 12: Loss:     2.0615 Validation Accuracy: 0.423600\n",
      "Epoch  2, MNIST Batch 13: Loss:     2.0638 Validation Accuracy: 0.437800\n",
      "Epoch  2, MNIST Batch 14: Loss:     2.0285 Validation Accuracy: 0.442600\n",
      "Epoch  2, MNIST Batch 15: Loss:     2.0559 Validation Accuracy: 0.442000\n",
      "Epoch  2, MNIST Batch 16: Loss:     2.0004 Validation Accuracy: 0.434200\n",
      "Epoch  2, MNIST Batch 17: Loss:     2.0714 Validation Accuracy: 0.427400\n",
      "Epoch  2, MNIST Batch 18: Loss:     2.0450 Validation Accuracy: 0.431400\n",
      "Epoch  2, MNIST Batch 19: Loss:     2.0329 Validation Accuracy: 0.441400\n",
      "Epoch  2, MNIST Batch 20: Loss:     2.0709 Validation Accuracy: 0.434000\n",
      "Epoch  2, MNIST Batch 21: Loss:     2.0341 Validation Accuracy: 0.426200\n",
      "Epoch  2, MNIST Batch 22: Loss:     2.0431 Validation Accuracy: 0.426800\n",
      "Epoch  2, MNIST Batch 23: Loss:     2.0803 Validation Accuracy: 0.426600\n",
      "Epoch  2, MNIST Batch 24: Loss:     2.0432 Validation Accuracy: 0.435000\n",
      "Epoch  2, MNIST Batch 25: Loss:     2.0583 Validation Accuracy: 0.441600\n",
      "Epoch  2, MNIST Batch 26: Loss:     2.0763 Validation Accuracy: 0.440200\n",
      "Epoch  2, MNIST Batch 27: Loss:     2.0523 Validation Accuracy: 0.435400\n",
      "Epoch  2, MNIST Batch 28: Loss:     2.0173 Validation Accuracy: 0.440400\n",
      "Epoch  2, MNIST Batch 29: Loss:     2.0314 Validation Accuracy: 0.441000\n",
      "Epoch  2, MNIST Batch 30: Loss:     2.0768 Validation Accuracy: 0.436200\n",
      "Epoch  2, MNIST Batch 31: Loss:     2.0975 Validation Accuracy: 0.434600\n",
      "Epoch  2, MNIST Batch 32: Loss:     2.0572 Validation Accuracy: 0.439400\n",
      "Epoch  2, MNIST Batch 33: Loss:     2.0271 Validation Accuracy: 0.447200\n",
      "Epoch  2, MNIST Batch 34: Loss:     2.0416 Validation Accuracy: 0.440600\n",
      "Epoch  2, MNIST Batch 35: Loss:     2.0754 Validation Accuracy: 0.428400\n",
      "Epoch  2, MNIST Batch 36: Loss:     2.0950 Validation Accuracy: 0.439600\n",
      "Epoch  2, MNIST Batch 37: Loss:     2.0208 Validation Accuracy: 0.444200\n",
      "Epoch  2, MNIST Batch 38: Loss:     2.0302 Validation Accuracy: 0.435800\n",
      "Epoch  2, MNIST Batch 39: Loss:     2.0376 Validation Accuracy: 0.442000\n",
      "Epoch  2, MNIST Batch 40: Loss:     2.0512 Validation Accuracy: 0.437200\n",
      "Epoch  2, MNIST Batch 41: Loss:     2.0278 Validation Accuracy: 0.434400\n",
      "Epoch  2, MNIST Batch 42: Loss:     2.0371 Validation Accuracy: 0.440400\n",
      "Epoch  2, MNIST Batch 43: Loss:     2.0551 Validation Accuracy: 0.448600\n",
      "Epoch  2, MNIST Batch 44: Loss:     2.0334 Validation Accuracy: 0.452200\n",
      "Epoch  2, MNIST Batch 45: Loss:     2.0243 Validation Accuracy: 0.451400\n",
      "Epoch  2, MNIST Batch 46: Loss:     2.0284 Validation Accuracy: 0.450000\n",
      "Epoch  2, MNIST Batch 47: Loss:     2.0383 Validation Accuracy: 0.451400\n",
      "Epoch  2, MNIST Batch 48: Loss:     2.0306 Validation Accuracy: 0.447200\n",
      "Epoch  2, MNIST Batch 49: Loss:     2.0087 Validation Accuracy: 0.451600\n",
      "Epoch  2, MNIST Batch 50: Loss:     2.0046 Validation Accuracy: 0.447400\n",
      "Epoch  2, MNIST Batch 51: Loss:     2.0883 Validation Accuracy: 0.448200\n",
      "Epoch  2, MNIST Batch 52: Loss:     2.0833 Validation Accuracy: 0.451200\n",
      "Epoch  2, MNIST Batch 53: Loss:     2.0184 Validation Accuracy: 0.445400\n",
      "Epoch  2, MNIST Batch 54: Loss:     2.0105 Validation Accuracy: 0.442400\n",
      "Epoch  2, MNIST Batch 55: Loss:     2.0065 Validation Accuracy: 0.450600\n",
      "Epoch  2, MNIST Batch 56: Loss:     2.0157 Validation Accuracy: 0.447000\n",
      "Epoch  2, MNIST Batch 57: Loss:     2.0647 Validation Accuracy: 0.449200\n",
      "Epoch  2, MNIST Batch 58: Loss:     2.0222 Validation Accuracy: 0.452800\n",
      "Epoch  2, MNIST Batch 59: Loss:     2.0638 Validation Accuracy: 0.454600\n",
      "Epoch  2, MNIST Batch 60: Loss:     2.0203 Validation Accuracy: 0.451400\n",
      "Epoch  2, MNIST Batch 61: Loss:     2.0505 Validation Accuracy: 0.453800\n",
      "Epoch  2, MNIST Batch 62: Loss:     2.0404 Validation Accuracy: 0.454200\n",
      "Epoch  2, MNIST Batch 63: Loss:     1.9896 Validation Accuracy: 0.454600\n",
      "Epoch  2, MNIST Batch 64: Loss:     2.0312 Validation Accuracy: 0.453200\n",
      "Epoch  2, MNIST Batch 65: Loss:     2.0573 Validation Accuracy: 0.454400\n",
      "Epoch  2, MNIST Batch 66: Loss:     2.0457 Validation Accuracy: 0.451000\n",
      "Epoch  2, MNIST Batch 67: Loss:     2.0054 Validation Accuracy: 0.453000\n",
      "Epoch  2, MNIST Batch 68: Loss:     2.0325 Validation Accuracy: 0.456200\n",
      "Epoch  2, MNIST Batch 69: Loss:     2.0220 Validation Accuracy: 0.456800\n",
      "Epoch  2, MNIST Batch 70: Loss:     2.0263 Validation Accuracy: 0.454000\n",
      "Epoch  2, MNIST Batch 71: Loss:     2.0579 Validation Accuracy: 0.451000\n",
      "Epoch  2, MNIST Batch 72: Loss:     2.0736 Validation Accuracy: 0.449600\n",
      "Epoch  2, MNIST Batch 73: Loss:     2.0341 Validation Accuracy: 0.449800\n",
      "Epoch  2, MNIST Batch 74: Loss:     1.9706 Validation Accuracy: 0.454600\n",
      "Epoch  2, MNIST Batch 75: Loss:     1.9956 Validation Accuracy: 0.456400\n",
      "Epoch  2, MNIST Batch 76: Loss:     1.9989 Validation Accuracy: 0.454200\n",
      "Epoch  2, MNIST Batch 77: Loss:     2.0243 Validation Accuracy: 0.444800\n",
      "Epoch  2, MNIST Batch 78: Loss:     2.0539 Validation Accuracy: 0.441600\n",
      "Epoch  2, MNIST Batch 79: Loss:     2.0285 Validation Accuracy: 0.448400\n",
      "Epoch  2, MNIST Batch 80: Loss:     2.0052 Validation Accuracy: 0.458000\n",
      "Epoch  2, MNIST Batch 81: Loss:     2.0385 Validation Accuracy: 0.456200\n",
      "Epoch  2, MNIST Batch 82: Loss:     2.0596 Validation Accuracy: 0.447400\n",
      "Epoch  2, MNIST Batch 83: Loss:     2.0241 Validation Accuracy: 0.439600\n",
      "Epoch  2, MNIST Batch 84: Loss:     2.0364 Validation Accuracy: 0.448000\n",
      "Epoch  2, MNIST Batch 85: Loss:     2.0262 Validation Accuracy: 0.446000\n",
      "Epoch  2, MNIST Batch 86: Loss:     2.0462 Validation Accuracy: 0.441000\n",
      "Epoch  2, MNIST Batch 87: Loss:     1.9976 Validation Accuracy: 0.455200\n",
      "Epoch  2, MNIST Batch 88: Loss:     2.0175 Validation Accuracy: 0.449200\n",
      "Epoch  2, MNIST Batch 89: Loss:     1.9906 Validation Accuracy: 0.437000\n",
      "Epoch  2, MNIST Batch 90: Loss:     2.0340 Validation Accuracy: 0.450400\n",
      "Epoch  2, MNIST Batch 91: Loss:     2.0055 Validation Accuracy: 0.467400\n",
      "Epoch  2, MNIST Batch 92: Loss:     1.9938 Validation Accuracy: 0.451800\n",
      "Epoch  2, MNIST Batch 93: Loss:     2.0477 Validation Accuracy: 0.448800\n",
      "Epoch  2, MNIST Batch 94: Loss:     1.9919 Validation Accuracy: 0.467200\n",
      "Epoch  2, MNIST Batch 95: Loss:     1.9973 Validation Accuracy: 0.463200\n",
      "Epoch  2, MNIST Batch 96: Loss:     2.0407 Validation Accuracy: 0.470200\n",
      "Epoch  2, MNIST Batch 97: Loss:     1.9497 Validation Accuracy: 0.501000\n",
      "Epoch  2, MNIST Batch 98: Loss:     2.0039 Validation Accuracy: 0.507400\n",
      "Epoch  2, MNIST Batch 99: Loss:     1.9591 Validation Accuracy: 0.506800\n",
      "Epoch  2, MNIST Batch 100: Loss:     1.9865 Validation Accuracy: 0.509800\n",
      "Epoch  2, MNIST Batch 101: Loss:     1.9628 Validation Accuracy: 0.511400\n",
      "Epoch  2, MNIST Batch 102: Loss:     1.9648 Validation Accuracy: 0.508600\n",
      "Epoch  2, MNIST Batch 103: Loss:     2.0106 Validation Accuracy: 0.497800\n",
      "Epoch  2, MNIST Batch 104: Loss:     1.9459 Validation Accuracy: 0.507600\n",
      "Epoch  2, MNIST Batch 105: Loss:     2.0133 Validation Accuracy: 0.514400\n",
      "Epoch  2, MNIST Batch 106: Loss:     2.0104 Validation Accuracy: 0.521800\n",
      "Epoch  2, MNIST Batch 107: Loss:     1.9650 Validation Accuracy: 0.519200\n",
      "Epoch  2, MNIST Batch 108: Loss:     1.9740 Validation Accuracy: 0.509000\n",
      "Epoch  2, MNIST Batch 109: Loss:     1.9863 Validation Accuracy: 0.524200\n",
      "Epoch  2, MNIST Batch 110: Loss:     2.0051 Validation Accuracy: 0.523600\n",
      "Epoch  2, MNIST Batch 111: Loss:     1.9718 Validation Accuracy: 0.518000\n",
      "Epoch  2, MNIST Batch 112: Loss:     1.9757 Validation Accuracy: 0.524200\n",
      "Epoch  2, MNIST Batch 113: Loss:     2.0001 Validation Accuracy: 0.527000\n",
      "Epoch  2, MNIST Batch 114: Loss:     1.9472 Validation Accuracy: 0.530200\n",
      "Epoch  2, MNIST Batch 115: Loss:     2.0082 Validation Accuracy: 0.530600\n",
      "Epoch  2, MNIST Batch 116: Loss:     1.9194 Validation Accuracy: 0.531600\n",
      "Epoch  2, MNIST Batch 117: Loss:     1.9644 Validation Accuracy: 0.533400\n",
      "Epoch  2, MNIST Batch 118: Loss:     1.9540 Validation Accuracy: 0.530400\n",
      "Epoch  2, MNIST Batch 119: Loss:     1.9914 Validation Accuracy: 0.523200\n",
      "Epoch  2, MNIST Batch 120: Loss:     1.9477 Validation Accuracy: 0.533200\n",
      "Epoch  2, MNIST Batch 121: Loss:     1.9763 Validation Accuracy: 0.524800\n",
      "Epoch  2, MNIST Batch 122: Loss:     1.9859 Validation Accuracy: 0.527400\n",
      "Epoch  2, MNIST Batch 123: Loss:     1.9336 Validation Accuracy: 0.534600\n",
      "Epoch  2, MNIST Batch 124: Loss:     1.9379 Validation Accuracy: 0.534600\n",
      "Epoch  2, MNIST Batch 125: Loss:     1.9968 Validation Accuracy: 0.532000\n",
      "Epoch  2, MNIST Batch 126: Loss:     1.9592 Validation Accuracy: 0.533200\n",
      "Epoch  2, MNIST Batch 127: Loss:     1.9816 Validation Accuracy: 0.535200\n",
      "Epoch  2, MNIST Batch 128: Loss:     1.9528 Validation Accuracy: 0.537400\n",
      "Epoch  2, MNIST Batch 129: Loss:     1.9371 Validation Accuracy: 0.533400\n",
      "Epoch  2, MNIST Batch 130: Loss:     2.0060 Validation Accuracy: 0.536800\n",
      "Epoch  2, MNIST Batch 131: Loss:     1.9912 Validation Accuracy: 0.539000\n",
      "Epoch  2, MNIST Batch 132: Loss:     1.9498 Validation Accuracy: 0.540000\n",
      "Epoch  2, MNIST Batch 133: Loss:     1.9550 Validation Accuracy: 0.537800\n",
      "Epoch  2, MNIST Batch 134: Loss:     1.9527 Validation Accuracy: 0.534600\n",
      "Epoch  2, MNIST Batch 135: Loss:     1.9348 Validation Accuracy: 0.540800\n",
      "Epoch  2, MNIST Batch 136: Loss:     1.9693 Validation Accuracy: 0.531200\n",
      "Epoch  2, MNIST Batch 137: Loss:     1.9924 Validation Accuracy: 0.524400\n",
      "Epoch  2, MNIST Batch 138: Loss:     1.9486 Validation Accuracy: 0.541800\n",
      "Epoch  2, MNIST Batch 139: Loss:     1.9649 Validation Accuracy: 0.530000\n",
      "Epoch  2, MNIST Batch 140: Loss:     1.9634 Validation Accuracy: 0.503800\n",
      "Epoch  2, MNIST Batch 141: Loss:     2.0010 Validation Accuracy: 0.532600\n",
      "Epoch  2, MNIST Batch 142: Loss:     1.9479 Validation Accuracy: 0.537400\n",
      "Epoch  2, MNIST Batch 143: Loss:     1.9646 Validation Accuracy: 0.530600\n",
      "Epoch  2, MNIST Batch 144: Loss:     1.9412 Validation Accuracy: 0.534600\n",
      "Epoch  2, MNIST Batch 145: Loss:     2.0034 Validation Accuracy: 0.544200\n",
      "Epoch  2, MNIST Batch 146: Loss:     1.9246 Validation Accuracy: 0.542800\n",
      "Epoch  2, MNIST Batch 147: Loss:     2.0067 Validation Accuracy: 0.540000\n",
      "Epoch  2, MNIST Batch 148: Loss:     1.9731 Validation Accuracy: 0.540000\n",
      "Epoch  2, MNIST Batch 149: Loss:     1.9314 Validation Accuracy: 0.544800\n",
      "Epoch  2, MNIST Batch 150: Loss:     1.9496 Validation Accuracy: 0.539600\n",
      "Epoch  2, MNIST Batch 151: Loss:     1.9224 Validation Accuracy: 0.533600\n",
      "Epoch  2, MNIST Batch 152: Loss:     1.9858 Validation Accuracy: 0.540600\n",
      "Epoch  2, MNIST Batch 153: Loss:     1.9644 Validation Accuracy: 0.539000\n",
      "Epoch  2, MNIST Batch 154: Loss:     1.9408 Validation Accuracy: 0.529600\n",
      "Epoch  2, MNIST Batch 155: Loss:     1.9497 Validation Accuracy: 0.547400\n",
      "Epoch  2, MNIST Batch 156: Loss:     1.9262 Validation Accuracy: 0.538600\n",
      "Epoch  2, MNIST Batch 157: Loss:     1.9710 Validation Accuracy: 0.539800\n",
      "Epoch  2, MNIST Batch 158: Loss:     1.9555 Validation Accuracy: 0.545800\n",
      "Epoch  2, MNIST Batch 159: Loss:     1.9309 Validation Accuracy: 0.542200\n",
      "Epoch  2, MNIST Batch 160: Loss:     1.9552 Validation Accuracy: 0.544200\n",
      "Epoch  2, MNIST Batch 161: Loss:     1.9291 Validation Accuracy: 0.545800\n",
      "Epoch  2, MNIST Batch 162: Loss:     1.9462 Validation Accuracy: 0.549200\n",
      "Epoch  2, MNIST Batch 163: Loss:     1.9362 Validation Accuracy: 0.544600\n",
      "Epoch  2, MNIST Batch 164: Loss:     1.9190 Validation Accuracy: 0.540800\n",
      "Epoch  2, MNIST Batch 165: Loss:     1.9456 Validation Accuracy: 0.547000\n",
      "Epoch  2, MNIST Batch 166: Loss:     1.9232 Validation Accuracy: 0.546000\n",
      "Epoch  2, MNIST Batch 167: Loss:     1.9578 Validation Accuracy: 0.539800\n",
      "Epoch  2, MNIST Batch 168: Loss:     1.9794 Validation Accuracy: 0.540400\n",
      "Epoch  2, MNIST Batch 169: Loss:     1.9742 Validation Accuracy: 0.548200\n",
      "Epoch  2, MNIST Batch 170: Loss:     1.9271 Validation Accuracy: 0.543000\n",
      "Epoch  2, MNIST Batch 171: Loss:     1.9611 Validation Accuracy: 0.537200\n",
      "Epoch  2, MNIST Batch 172: Loss:     1.8690 Validation Accuracy: 0.550400\n",
      "Epoch  2, MNIST Batch 173: Loss:     1.9479 Validation Accuracy: 0.550200\n",
      "Epoch  2, MNIST Batch 174: Loss:     1.9173 Validation Accuracy: 0.543000\n",
      "Epoch  2, MNIST Batch 175: Loss:     1.9328 Validation Accuracy: 0.547600\n",
      "Epoch  2, MNIST Batch 176: Loss:     1.9060 Validation Accuracy: 0.550400\n",
      "Epoch  2, MNIST Batch 177: Loss:     1.9694 Validation Accuracy: 0.542200\n",
      "Epoch  2, MNIST Batch 178: Loss:     1.9681 Validation Accuracy: 0.535400\n",
      "Epoch  2, MNIST Batch 179: Loss:     1.9321 Validation Accuracy: 0.542200\n",
      "Epoch  2, MNIST Batch 180: Loss:     1.9873 Validation Accuracy: 0.553200\n",
      "Epoch  2, MNIST Batch 181: Loss:     1.9575 Validation Accuracy: 0.548400\n",
      "Epoch  2, MNIST Batch 182: Loss:     1.8977 Validation Accuracy: 0.550000\n",
      "Epoch  2, MNIST Batch 183: Loss:     1.9344 Validation Accuracy: 0.554000\n",
      "Epoch  2, MNIST Batch 184: Loss:     1.9179 Validation Accuracy: 0.552200\n",
      "Epoch  2, MNIST Batch 185: Loss:     1.9449 Validation Accuracy: 0.552200\n",
      "Epoch  2, MNIST Batch 186: Loss:     1.9388 Validation Accuracy: 0.554200\n",
      "Epoch  2, MNIST Batch 187: Loss:     1.9364 Validation Accuracy: 0.546000\n",
      "Epoch  2, MNIST Batch 188: Loss:     1.9062 Validation Accuracy: 0.547400\n",
      "Epoch  2, MNIST Batch 189: Loss:     1.9432 Validation Accuracy: 0.551600\n",
      "Epoch  2, MNIST Batch 190: Loss:     1.9202 Validation Accuracy: 0.549000\n",
      "Epoch  2, MNIST Batch 191: Loss:     1.9076 Validation Accuracy: 0.553600\n",
      "Epoch  2, MNIST Batch 192: Loss:     1.9853 Validation Accuracy: 0.553200\n",
      "Epoch  2, MNIST Batch 193: Loss:     1.9500 Validation Accuracy: 0.551600\n",
      "Epoch  2, MNIST Batch 194: Loss:     1.9508 Validation Accuracy: 0.556600\n",
      "Epoch  2, MNIST Batch 195: Loss:     1.9206 Validation Accuracy: 0.551600\n",
      "Epoch  2, MNIST Batch 196: Loss:     1.9737 Validation Accuracy: 0.545600\n",
      "Epoch  2, MNIST Batch 197: Loss:     1.8682 Validation Accuracy: 0.553200\n",
      "Epoch  2, MNIST Batch 198: Loss:     1.9629 Validation Accuracy: 0.556600\n",
      "Epoch  2, MNIST Batch 199: Loss:     1.9312 Validation Accuracy: 0.543600\n",
      "Epoch  2, MNIST Batch 200: Loss:     1.9320 Validation Accuracy: 0.550400\n",
      "Epoch  2, MNIST Batch 201: Loss:     1.9922 Validation Accuracy: 0.557200\n",
      "Epoch  2, MNIST Batch 202: Loss:     1.9325 Validation Accuracy: 0.554800\n",
      "Epoch  2, MNIST Batch 203: Loss:     1.9230 Validation Accuracy: 0.546400\n",
      "Epoch  2, MNIST Batch 204: Loss:     1.9460 Validation Accuracy: 0.550600\n",
      "Epoch  2, MNIST Batch 205: Loss:     1.8775 Validation Accuracy: 0.557200\n",
      "Epoch  2, MNIST Batch 206: Loss:     1.9589 Validation Accuracy: 0.557800\n",
      "Epoch  2, MNIST Batch 207: Loss:     1.9056 Validation Accuracy: 0.557800\n",
      "Epoch  2, MNIST Batch 208: Loss:     1.9668 Validation Accuracy: 0.558600\n",
      "Epoch  2, MNIST Batch 209: Loss:     1.9335 Validation Accuracy: 0.558400\n",
      "Epoch  2, MNIST Batch 210: Loss:     1.8951 Validation Accuracy: 0.559400\n",
      "Epoch  2, MNIST Batch 211: Loss:     1.8982 Validation Accuracy: 0.559400\n",
      "Epoch  2, MNIST Batch 212: Loss:     1.9460 Validation Accuracy: 0.557400\n",
      "Epoch  2, MNIST Batch 213: Loss:     1.9163 Validation Accuracy: 0.558000\n",
      "Epoch  3, MNIST Batch 0: Loss:     1.9077 Validation Accuracy: 0.556000\n",
      "Epoch  3, MNIST Batch 1: Loss:     1.8985 Validation Accuracy: 0.559000\n",
      "Epoch  3, MNIST Batch 2: Loss:     1.9190 Validation Accuracy: 0.555400\n",
      "Epoch  3, MNIST Batch 3: Loss:     1.9252 Validation Accuracy: 0.552000\n",
      "Epoch  3, MNIST Batch 4: Loss:     1.9016 Validation Accuracy: 0.558600\n",
      "Epoch  3, MNIST Batch 5: Loss:     1.8943 Validation Accuracy: 0.558600\n",
      "Epoch  3, MNIST Batch 6: Loss:     1.9363 Validation Accuracy: 0.548800\n",
      "Epoch  3, MNIST Batch 7: Loss:     1.9089 Validation Accuracy: 0.548000\n",
      "Epoch  3, MNIST Batch 8: Loss:     1.8745 Validation Accuracy: 0.559000\n",
      "Epoch  3, MNIST Batch 9: Loss:     1.9616 Validation Accuracy: 0.543000\n",
      "Epoch  3, MNIST Batch 10: Loss:     1.9761 Validation Accuracy: 0.539800\n",
      "Epoch  3, MNIST Batch 11: Loss:     1.9151 Validation Accuracy: 0.553400\n",
      "Epoch  3, MNIST Batch 12: Loss:     1.9552 Validation Accuracy: 0.559400\n",
      "Epoch  3, MNIST Batch 13: Loss:     1.9283 Validation Accuracy: 0.550400\n",
      "Epoch  3, MNIST Batch 14: Loss:     1.9341 Validation Accuracy: 0.550200\n",
      "Epoch  3, MNIST Batch 15: Loss:     1.9418 Validation Accuracy: 0.560200\n",
      "Epoch  3, MNIST Batch 16: Loss:     1.9371 Validation Accuracy: 0.552200\n",
      "Epoch  3, MNIST Batch 17: Loss:     1.9301 Validation Accuracy: 0.543000\n",
      "Epoch  3, MNIST Batch 18: Loss:     1.9258 Validation Accuracy: 0.555600\n",
      "Epoch  3, MNIST Batch 19: Loss:     1.9462 Validation Accuracy: 0.558000\n",
      "Epoch  3, MNIST Batch 20: Loss:     1.9840 Validation Accuracy: 0.542200\n",
      "Epoch  3, MNIST Batch 21: Loss:     1.9806 Validation Accuracy: 0.537200\n",
      "Epoch  3, MNIST Batch 22: Loss:     1.8780 Validation Accuracy: 0.554000\n",
      "Epoch  3, MNIST Batch 23: Loss:     1.9035 Validation Accuracy: 0.561800\n",
      "Epoch  3, MNIST Batch 24: Loss:     1.9312 Validation Accuracy: 0.550400\n",
      "Epoch  3, MNIST Batch 25: Loss:     1.9521 Validation Accuracy: 0.545400\n",
      "Epoch  3, MNIST Batch 26: Loss:     1.8900 Validation Accuracy: 0.559400\n",
      "Epoch  3, MNIST Batch 27: Loss:     1.9143 Validation Accuracy: 0.555400\n",
      "Epoch  3, MNIST Batch 28: Loss:     1.9754 Validation Accuracy: 0.554000\n",
      "Epoch  3, MNIST Batch 29: Loss:     1.8941 Validation Accuracy: 0.562400\n",
      "Epoch  3, MNIST Batch 30: Loss:     1.9844 Validation Accuracy: 0.560800\n",
      "Epoch  3, MNIST Batch 31: Loss:     1.8646 Validation Accuracy: 0.556600\n",
      "Epoch  3, MNIST Batch 32: Loss:     1.9408 Validation Accuracy: 0.554400\n",
      "Epoch  3, MNIST Batch 33: Loss:     1.9235 Validation Accuracy: 0.555200\n",
      "Epoch  3, MNIST Batch 34: Loss:     1.8987 Validation Accuracy: 0.561600\n",
      "Epoch  3, MNIST Batch 35: Loss:     1.9447 Validation Accuracy: 0.560400\n",
      "Epoch  3, MNIST Batch 36: Loss:     1.9309 Validation Accuracy: 0.561800\n",
      "Epoch  3, MNIST Batch 37: Loss:     1.9506 Validation Accuracy: 0.562800\n",
      "Epoch  3, MNIST Batch 38: Loss:     1.9073 Validation Accuracy: 0.563200\n",
      "Epoch  3, MNIST Batch 39: Loss:     1.9307 Validation Accuracy: 0.553000\n",
      "Epoch  3, MNIST Batch 40: Loss:     1.8740 Validation Accuracy: 0.553800\n",
      "Epoch  3, MNIST Batch 41: Loss:     1.9559 Validation Accuracy: 0.558400\n",
      "Epoch  3, MNIST Batch 42: Loss:     1.9285 Validation Accuracy: 0.560800\n",
      "Epoch  3, MNIST Batch 43: Loss:     1.9277 Validation Accuracy: 0.560000\n",
      "Epoch  3, MNIST Batch 44: Loss:     1.9294 Validation Accuracy: 0.561000\n",
      "Epoch  3, MNIST Batch 45: Loss:     1.8994 Validation Accuracy: 0.565400\n",
      "Epoch  3, MNIST Batch 46: Loss:     1.9269 Validation Accuracy: 0.560800\n",
      "Epoch  3, MNIST Batch 47: Loss:     1.9657 Validation Accuracy: 0.552400\n",
      "Epoch  3, MNIST Batch 48: Loss:     1.9427 Validation Accuracy: 0.558600\n",
      "Epoch  3, MNIST Batch 49: Loss:     1.9246 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 50: Loss:     1.8900 Validation Accuracy: 0.557000\n",
      "Epoch  3, MNIST Batch 51: Loss:     1.9229 Validation Accuracy: 0.558200\n",
      "Epoch  3, MNIST Batch 52: Loss:     1.9118 Validation Accuracy: 0.563600\n",
      "Epoch  3, MNIST Batch 53: Loss:     1.9031 Validation Accuracy: 0.558600\n",
      "Epoch  3, MNIST Batch 54: Loss:     1.9066 Validation Accuracy: 0.560600\n",
      "Epoch  3, MNIST Batch 55: Loss:     1.9575 Validation Accuracy: 0.565600\n",
      "Epoch  3, MNIST Batch 56: Loss:     1.8813 Validation Accuracy: 0.565400\n",
      "Epoch  3, MNIST Batch 57: Loss:     1.9005 Validation Accuracy: 0.556000\n",
      "Epoch  3, MNIST Batch 58: Loss:     1.9335 Validation Accuracy: 0.555000\n",
      "Epoch  3, MNIST Batch 59: Loss:     1.9028 Validation Accuracy: 0.564400\n",
      "Epoch  3, MNIST Batch 60: Loss:     1.9100 Validation Accuracy: 0.565400\n",
      "Epoch  3, MNIST Batch 61: Loss:     1.9280 Validation Accuracy: 0.562200\n",
      "Epoch  3, MNIST Batch 62: Loss:     1.8726 Validation Accuracy: 0.565000\n",
      "Epoch  3, MNIST Batch 63: Loss:     1.9158 Validation Accuracy: 0.563600\n",
      "Epoch  3, MNIST Batch 64: Loss:     1.9004 Validation Accuracy: 0.563000\n",
      "Epoch  3, MNIST Batch 65: Loss:     1.8805 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 66: Loss:     1.8379 Validation Accuracy: 0.562200\n",
      "Epoch  3, MNIST Batch 67: Loss:     1.8731 Validation Accuracy: 0.560600\n",
      "Epoch  3, MNIST Batch 68: Loss:     1.8933 Validation Accuracy: 0.563600\n",
      "Epoch  3, MNIST Batch 69: Loss:     1.8887 Validation Accuracy: 0.566400\n",
      "Epoch  3, MNIST Batch 70: Loss:     1.9352 Validation Accuracy: 0.566000\n",
      "Epoch  3, MNIST Batch 71: Loss:     1.8724 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 72: Loss:     1.9384 Validation Accuracy: 0.561800\n",
      "Epoch  3, MNIST Batch 73: Loss:     1.9033 Validation Accuracy: 0.563200\n",
      "Epoch  3, MNIST Batch 74: Loss:     1.8823 Validation Accuracy: 0.565600\n",
      "Epoch  3, MNIST Batch 75: Loss:     1.9416 Validation Accuracy: 0.567200\n",
      "Epoch  3, MNIST Batch 76: Loss:     1.8952 Validation Accuracy: 0.566800\n",
      "Epoch  3, MNIST Batch 77: Loss:     1.9339 Validation Accuracy: 0.564800\n",
      "Epoch  3, MNIST Batch 78: Loss:     1.9490 Validation Accuracy: 0.562400\n",
      "Epoch  3, MNIST Batch 79: Loss:     1.9388 Validation Accuracy: 0.557400\n",
      "Epoch  3, MNIST Batch 80: Loss:     1.9477 Validation Accuracy: 0.554400\n",
      "Epoch  3, MNIST Batch 81: Loss:     1.9397 Validation Accuracy: 0.562400\n",
      "Epoch  3, MNIST Batch 82: Loss:     1.9347 Validation Accuracy: 0.567400\n",
      "Epoch  3, MNIST Batch 83: Loss:     1.9396 Validation Accuracy: 0.564400\n",
      "Epoch  3, MNIST Batch 84: Loss:     1.9250 Validation Accuracy: 0.558200\n",
      "Epoch  3, MNIST Batch 85: Loss:     1.8789 Validation Accuracy: 0.561200\n",
      "Epoch  3, MNIST Batch 86: Loss:     1.9209 Validation Accuracy: 0.563200\n",
      "Epoch  3, MNIST Batch 87: Loss:     1.9412 Validation Accuracy: 0.556400\n",
      "Epoch  3, MNIST Batch 88: Loss:     1.8551 Validation Accuracy: 0.566400\n",
      "Epoch  3, MNIST Batch 89: Loss:     1.9433 Validation Accuracy: 0.567600\n",
      "Epoch  3, MNIST Batch 90: Loss:     1.8527 Validation Accuracy: 0.556800\n",
      "Epoch  3, MNIST Batch 91: Loss:     1.9231 Validation Accuracy: 0.561000\n",
      "Epoch  3, MNIST Batch 92: Loss:     1.9247 Validation Accuracy: 0.563600\n",
      "Epoch  3, MNIST Batch 93: Loss:     1.9052 Validation Accuracy: 0.564400\n",
      "Epoch  3, MNIST Batch 94: Loss:     1.9493 Validation Accuracy: 0.563800\n",
      "Epoch  3, MNIST Batch 95: Loss:     1.9224 Validation Accuracy: 0.560600\n",
      "Epoch  3, MNIST Batch 96: Loss:     1.8975 Validation Accuracy: 0.562000\n",
      "Epoch  3, MNIST Batch 97: Loss:     1.9159 Validation Accuracy: 0.563600\n",
      "Epoch  3, MNIST Batch 98: Loss:     1.9148 Validation Accuracy: 0.563000\n",
      "Epoch  3, MNIST Batch 99: Loss:     1.8616 Validation Accuracy: 0.568000\n",
      "Epoch  3, MNIST Batch 100: Loss:     1.8926 Validation Accuracy: 0.564400\n",
      "Epoch  3, MNIST Batch 101: Loss:     1.8920 Validation Accuracy: 0.550800\n",
      "Epoch  3, MNIST Batch 102: Loss:     1.9439 Validation Accuracy: 0.556800\n",
      "Epoch  3, MNIST Batch 103: Loss:     1.9954 Validation Accuracy: 0.560800\n",
      "Epoch  3, MNIST Batch 104: Loss:     1.9411 Validation Accuracy: 0.562400\n",
      "Epoch  3, MNIST Batch 105: Loss:     1.9049 Validation Accuracy: 0.567800\n",
      "Epoch  3, MNIST Batch 106: Loss:     1.9107 Validation Accuracy: 0.568600\n",
      "Epoch  3, MNIST Batch 107: Loss:     1.9057 Validation Accuracy: 0.565200\n",
      "Epoch  3, MNIST Batch 108: Loss:     1.9388 Validation Accuracy: 0.564400\n",
      "Epoch  3, MNIST Batch 109: Loss:     1.9539 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 110: Loss:     1.8697 Validation Accuracy: 0.564600\n",
      "Epoch  3, MNIST Batch 111: Loss:     1.9044 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 112: Loss:     1.8771 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 113: Loss:     1.9590 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 114: Loss:     1.9542 Validation Accuracy: 0.565800\n",
      "Epoch  3, MNIST Batch 115: Loss:     1.8943 Validation Accuracy: 0.563200\n",
      "Epoch  3, MNIST Batch 116: Loss:     1.9105 Validation Accuracy: 0.569600\n",
      "Epoch  3, MNIST Batch 117: Loss:     1.9138 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 118: Loss:     1.9076 Validation Accuracy: 0.571200\n",
      "Epoch  3, MNIST Batch 119: Loss:     1.9368 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 120: Loss:     1.9136 Validation Accuracy: 0.570400\n",
      "Epoch  3, MNIST Batch 121: Loss:     1.8804 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 122: Loss:     1.9233 Validation Accuracy: 0.568400\n",
      "Epoch  3, MNIST Batch 123: Loss:     1.9501 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 124: Loss:     1.9291 Validation Accuracy: 0.568400\n",
      "Epoch  3, MNIST Batch 125: Loss:     1.8909 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 126: Loss:     1.9305 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 127: Loss:     1.9272 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 128: Loss:     1.9063 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 129: Loss:     1.8916 Validation Accuracy: 0.570000\n",
      "Epoch  3, MNIST Batch 130: Loss:     1.9182 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 131: Loss:     1.9030 Validation Accuracy: 0.567000\n",
      "Epoch  3, MNIST Batch 132: Loss:     1.9038 Validation Accuracy: 0.569000\n",
      "Epoch  3, MNIST Batch 133: Loss:     1.8779 Validation Accuracy: 0.568200\n",
      "Epoch  3, MNIST Batch 134: Loss:     1.9138 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 135: Loss:     1.9010 Validation Accuracy: 0.569000\n",
      "Epoch  3, MNIST Batch 136: Loss:     1.9449 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 137: Loss:     1.9080 Validation Accuracy: 0.571200\n",
      "Epoch  3, MNIST Batch 138: Loss:     1.9166 Validation Accuracy: 0.572600\n",
      "Epoch  3, MNIST Batch 139: Loss:     1.9098 Validation Accuracy: 0.570000\n",
      "Epoch  3, MNIST Batch 140: Loss:     1.9499 Validation Accuracy: 0.570200\n",
      "Epoch  3, MNIST Batch 141: Loss:     1.9074 Validation Accuracy: 0.569400\n",
      "Epoch  3, MNIST Batch 142: Loss:     1.9373 Validation Accuracy: 0.570200\n",
      "Epoch  3, MNIST Batch 143: Loss:     1.9669 Validation Accuracy: 0.573000\n",
      "Epoch  3, MNIST Batch 144: Loss:     1.8697 Validation Accuracy: 0.567600\n",
      "Epoch  3, MNIST Batch 145: Loss:     1.9472 Validation Accuracy: 0.563800\n",
      "Epoch  3, MNIST Batch 146: Loss:     1.9009 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 147: Loss:     1.8907 Validation Accuracy: 0.572000\n",
      "Epoch  3, MNIST Batch 148: Loss:     1.9138 Validation Accuracy: 0.572400\n",
      "Epoch  3, MNIST Batch 149: Loss:     1.8751 Validation Accuracy: 0.572200\n",
      "Epoch  3, MNIST Batch 150: Loss:     1.8959 Validation Accuracy: 0.572000\n",
      "Epoch  3, MNIST Batch 151: Loss:     1.8796 Validation Accuracy: 0.569600\n",
      "Epoch  3, MNIST Batch 152: Loss:     1.8976 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 153: Loss:     1.9098 Validation Accuracy: 0.571600\n",
      "Epoch  3, MNIST Batch 154: Loss:     1.8729 Validation Accuracy: 0.571200\n",
      "Epoch  3, MNIST Batch 155: Loss:     1.9127 Validation Accuracy: 0.571000\n",
      "Epoch  3, MNIST Batch 156: Loss:     1.9094 Validation Accuracy: 0.569000\n",
      "Epoch  3, MNIST Batch 157: Loss:     1.9130 Validation Accuracy: 0.568400\n",
      "Epoch  3, MNIST Batch 158: Loss:     1.9723 Validation Accuracy: 0.570200\n",
      "Epoch  3, MNIST Batch 159: Loss:     1.8742 Validation Accuracy: 0.569600\n",
      "Epoch  3, MNIST Batch 160: Loss:     1.8505 Validation Accuracy: 0.570800\n",
      "Epoch  3, MNIST Batch 161: Loss:     1.8804 Validation Accuracy: 0.570600\n",
      "Epoch  3, MNIST Batch 162: Loss:     1.9124 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 163: Loss:     1.9212 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 164: Loss:     1.8679 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 165: Loss:     1.9115 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 166: Loss:     1.9011 Validation Accuracy: 0.571400\n",
      "Epoch  3, MNIST Batch 167: Loss:     1.9239 Validation Accuracy: 0.573400\n",
      "Epoch  3, MNIST Batch 168: Loss:     1.8678 Validation Accuracy: 0.572800\n",
      "Epoch  3, MNIST Batch 169: Loss:     1.8883 Validation Accuracy: 0.573200\n",
      "Epoch  3, MNIST Batch 170: Loss:     1.9534 Validation Accuracy: 0.573800\n",
      "Epoch  3, MNIST Batch 171: Loss:     1.8868 Validation Accuracy: 0.573400\n",
      "Epoch  3, MNIST Batch 172: Loss:     1.9404 Validation Accuracy: 0.572200\n",
      "Epoch  3, MNIST Batch 173: Loss:     1.8998 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 174: Loss:     1.8792 Validation Accuracy: 0.571400\n",
      "Epoch  3, MNIST Batch 175: Loss:     1.9448 Validation Accuracy: 0.574200\n",
      "Epoch  3, MNIST Batch 176: Loss:     1.9041 Validation Accuracy: 0.574600\n",
      "Epoch  3, MNIST Batch 177: Loss:     1.9291 Validation Accuracy: 0.573800\n",
      "Epoch  3, MNIST Batch 178: Loss:     1.9174 Validation Accuracy: 0.571000\n",
      "Epoch  3, MNIST Batch 179: Loss:     1.8580 Validation Accuracy: 0.573000\n",
      "Epoch  3, MNIST Batch 180: Loss:     1.9410 Validation Accuracy: 0.572400\n",
      "Epoch  3, MNIST Batch 181: Loss:     1.9225 Validation Accuracy: 0.572800\n",
      "Epoch  3, MNIST Batch 182: Loss:     1.8832 Validation Accuracy: 0.573600\n",
      "Epoch  3, MNIST Batch 183: Loss:     1.8540 Validation Accuracy: 0.569800\n",
      "Epoch  3, MNIST Batch 184: Loss:     1.8775 Validation Accuracy: 0.571800\n",
      "Epoch  3, MNIST Batch 185: Loss:     1.8921 Validation Accuracy: 0.572200\n",
      "Epoch  3, MNIST Batch 186: Loss:     1.9334 Validation Accuracy: 0.569200\n",
      "Epoch  3, MNIST Batch 187: Loss:     1.9204 Validation Accuracy: 0.561200\n",
      "Epoch  3, MNIST Batch 188: Loss:     1.9099 Validation Accuracy: 0.571600\n",
      "Epoch  3, MNIST Batch 189: Loss:     1.8890 Validation Accuracy: 0.572800\n",
      "Epoch  3, MNIST Batch 190: Loss:     1.8807 Validation Accuracy: 0.565800\n",
      "Epoch  3, MNIST Batch 191: Loss:     1.8958 Validation Accuracy: 0.562200\n",
      "Epoch  3, MNIST Batch 192: Loss:     1.9158 Validation Accuracy: 0.571000\n",
      "Epoch  3, MNIST Batch 193: Loss:     1.8797 Validation Accuracy: 0.572200\n",
      "Epoch  3, MNIST Batch 194: Loss:     1.8922 Validation Accuracy: 0.566800\n",
      "Epoch  3, MNIST Batch 195: Loss:     1.9120 Validation Accuracy: 0.566000\n",
      "Epoch  3, MNIST Batch 196: Loss:     1.9455 Validation Accuracy: 0.569400\n",
      "Epoch  3, MNIST Batch 197: Loss:     1.9017 Validation Accuracy: 0.568600\n",
      "Epoch  3, MNIST Batch 198: Loss:     1.9016 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 199: Loss:     1.8750 Validation Accuracy: 0.571400\n",
      "Epoch  3, MNIST Batch 200: Loss:     1.8801 Validation Accuracy: 0.573600\n",
      "Epoch  3, MNIST Batch 201: Loss:     1.9472 Validation Accuracy: 0.568800\n",
      "Epoch  3, MNIST Batch 202: Loss:     1.8729 Validation Accuracy: 0.570200\n",
      "Epoch  3, MNIST Batch 203: Loss:     1.9142 Validation Accuracy: 0.572400\n",
      "Epoch  3, MNIST Batch 204: Loss:     1.9347 Validation Accuracy: 0.572400\n",
      "Epoch  3, MNIST Batch 205: Loss:     1.9051 Validation Accuracy: 0.571000\n",
      "Epoch  3, MNIST Batch 206: Loss:     1.9427 Validation Accuracy: 0.567400\n",
      "Epoch  3, MNIST Batch 207: Loss:     1.8927 Validation Accuracy: 0.568400\n",
      "Epoch  3, MNIST Batch 208: Loss:     1.8648 Validation Accuracy: 0.573000\n",
      "Epoch  3, MNIST Batch 209: Loss:     1.8945 Validation Accuracy: 0.565800\n",
      "Epoch  3, MNIST Batch 210: Loss:     1.8798 Validation Accuracy: 0.566200\n",
      "Epoch  3, MNIST Batch 211: Loss:     1.8816 Validation Accuracy: 0.574200\n",
      "Epoch  3, MNIST Batch 212: Loss:     1.9007 Validation Accuracy: 0.571200\n",
      "Epoch  3, MNIST Batch 213: Loss:     1.9071 Validation Accuracy: 0.567200\n",
      "Epoch  4, MNIST Batch 0: Loss:     1.9050 Validation Accuracy: 0.566200\n",
      "Epoch  4, MNIST Batch 1: Loss:     1.8418 Validation Accuracy: 0.573600\n",
      "Epoch  4, MNIST Batch 2: Loss:     1.8611 Validation Accuracy: 0.575000\n",
      "Epoch  4, MNIST Batch 3: Loss:     1.8850 Validation Accuracy: 0.569800\n",
      "Epoch  4, MNIST Batch 4: Loss:     1.8748 Validation Accuracy: 0.568000\n",
      "Epoch  4, MNIST Batch 5: Loss:     1.8990 Validation Accuracy: 0.571400\n",
      "Epoch  4, MNIST Batch 6: Loss:     1.9096 Validation Accuracy: 0.570800\n",
      "Epoch  4, MNIST Batch 7: Loss:     1.8706 Validation Accuracy: 0.573600\n",
      "Epoch  4, MNIST Batch 8: Loss:     1.9819 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 9: Loss:     1.9180 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 10: Loss:     1.9204 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 11: Loss:     1.8815 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 12: Loss:     1.8906 Validation Accuracy: 0.573600\n",
      "Epoch  4, MNIST Batch 13: Loss:     1.9307 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 14: Loss:     1.8925 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 15: Loss:     1.9106 Validation Accuracy: 0.575200\n",
      "Epoch  4, MNIST Batch 16: Loss:     1.8975 Validation Accuracy: 0.569200\n",
      "Epoch  4, MNIST Batch 17: Loss:     1.9005 Validation Accuracy: 0.564200\n",
      "Epoch  4, MNIST Batch 18: Loss:     1.8833 Validation Accuracy: 0.568600\n",
      "Epoch  4, MNIST Batch 19: Loss:     1.9315 Validation Accuracy: 0.574400\n",
      "Epoch  4, MNIST Batch 20: Loss:     1.9296 Validation Accuracy: 0.564200\n",
      "Epoch  4, MNIST Batch 21: Loss:     1.8898 Validation Accuracy: 0.561800\n",
      "Epoch  4, MNIST Batch 22: Loss:     1.8663 Validation Accuracy: 0.574400\n",
      "Epoch  4, MNIST Batch 23: Loss:     1.9546 Validation Accuracy: 0.568200\n",
      "Epoch  4, MNIST Batch 24: Loss:     1.9391 Validation Accuracy: 0.556000\n",
      "Epoch  4, MNIST Batch 25: Loss:     1.9124 Validation Accuracy: 0.571800\n",
      "Epoch  4, MNIST Batch 26: Loss:     1.9659 Validation Accuracy: 0.573600\n",
      "Epoch  4, MNIST Batch 27: Loss:     1.8967 Validation Accuracy: 0.568600\n",
      "Epoch  4, MNIST Batch 28: Loss:     1.8116 Validation Accuracy: 0.568600\n",
      "Epoch  4, MNIST Batch 29: Loss:     1.8874 Validation Accuracy: 0.572200\n",
      "Epoch  4, MNIST Batch 30: Loss:     1.9045 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 31: Loss:     1.9127 Validation Accuracy: 0.574000\n",
      "Epoch  4, MNIST Batch 32: Loss:     1.8495 Validation Accuracy: 0.570200\n",
      "Epoch  4, MNIST Batch 33: Loss:     1.9053 Validation Accuracy: 0.572600\n",
      "Epoch  4, MNIST Batch 34: Loss:     1.8878 Validation Accuracy: 0.574800\n",
      "Epoch  4, MNIST Batch 35: Loss:     1.8553 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 36: Loss:     1.8802 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 37: Loss:     1.8944 Validation Accuracy: 0.577200\n",
      "Epoch  4, MNIST Batch 38: Loss:     1.9332 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 39: Loss:     1.8691 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 40: Loss:     1.9278 Validation Accuracy: 0.577000\n",
      "Epoch  4, MNIST Batch 41: Loss:     1.8892 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 42: Loss:     1.9204 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 43: Loss:     1.9237 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 44: Loss:     1.8754 Validation Accuracy: 0.568600\n",
      "Epoch  4, MNIST Batch 45: Loss:     1.8834 Validation Accuracy: 0.571000\n",
      "Epoch  4, MNIST Batch 46: Loss:     1.8984 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 47: Loss:     1.8961 Validation Accuracy: 0.576400\n",
      "Epoch  4, MNIST Batch 48: Loss:     1.9218 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 49: Loss:     1.8610 Validation Accuracy: 0.576400\n",
      "Epoch  4, MNIST Batch 50: Loss:     1.9112 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 51: Loss:     1.9200 Validation Accuracy: 0.577400\n",
      "Epoch  4, MNIST Batch 52: Loss:     1.9254 Validation Accuracy: 0.577400\n",
      "Epoch  4, MNIST Batch 53: Loss:     1.9027 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 54: Loss:     1.9353 Validation Accuracy: 0.574000\n",
      "Epoch  4, MNIST Batch 55: Loss:     1.8928 Validation Accuracy: 0.574000\n",
      "Epoch  4, MNIST Batch 56: Loss:     1.9446 Validation Accuracy: 0.573800\n",
      "Epoch  4, MNIST Batch 57: Loss:     1.9135 Validation Accuracy: 0.574200\n",
      "Epoch  4, MNIST Batch 58: Loss:     1.8810 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 59: Loss:     1.9392 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 60: Loss:     1.9016 Validation Accuracy: 0.576600\n",
      "Epoch  4, MNIST Batch 61: Loss:     1.9005 Validation Accuracy: 0.576800\n",
      "Epoch  4, MNIST Batch 62: Loss:     1.9502 Validation Accuracy: 0.574400\n",
      "Epoch  4, MNIST Batch 63: Loss:     1.9379 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 64: Loss:     1.9331 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 65: Loss:     1.9150 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 66: Loss:     1.9009 Validation Accuracy: 0.574200\n",
      "Epoch  4, MNIST Batch 67: Loss:     1.8649 Validation Accuracy: 0.574600\n",
      "Epoch  4, MNIST Batch 68: Loss:     1.9055 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 69: Loss:     1.8853 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 70: Loss:     1.9155 Validation Accuracy: 0.577600\n",
      "Epoch  4, MNIST Batch 71: Loss:     1.8749 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 72: Loss:     1.9122 Validation Accuracy: 0.575000\n",
      "Epoch  4, MNIST Batch 73: Loss:     1.9047 Validation Accuracy: 0.573200\n",
      "Epoch  4, MNIST Batch 74: Loss:     1.8767 Validation Accuracy: 0.574800\n",
      "Epoch  4, MNIST Batch 75: Loss:     1.8846 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 76: Loss:     1.8739 Validation Accuracy: 0.569800\n",
      "Epoch  4, MNIST Batch 77: Loss:     1.8932 Validation Accuracy: 0.560200\n",
      "Epoch  4, MNIST Batch 78: Loss:     1.9088 Validation Accuracy: 0.565800\n",
      "Epoch  4, MNIST Batch 79: Loss:     1.9032 Validation Accuracy: 0.573400\n",
      "Epoch  4, MNIST Batch 80: Loss:     1.8914 Validation Accuracy: 0.575200\n",
      "Epoch  4, MNIST Batch 81: Loss:     1.8962 Validation Accuracy: 0.571000\n",
      "Epoch  4, MNIST Batch 82: Loss:     1.9127 Validation Accuracy: 0.575000\n",
      "Epoch  4, MNIST Batch 83: Loss:     1.9287 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 84: Loss:     1.8878 Validation Accuracy: 0.573800\n",
      "Epoch  4, MNIST Batch 85: Loss:     1.9232 Validation Accuracy: 0.569600\n",
      "Epoch  4, MNIST Batch 86: Loss:     1.8342 Validation Accuracy: 0.572200\n",
      "Epoch  4, MNIST Batch 87: Loss:     1.9275 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 88: Loss:     1.9333 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 89: Loss:     1.9401 Validation Accuracy: 0.568200\n",
      "Epoch  4, MNIST Batch 90: Loss:     1.9568 Validation Accuracy: 0.566400\n",
      "Epoch  4, MNIST Batch 91: Loss:     1.8842 Validation Accuracy: 0.574600\n",
      "Epoch  4, MNIST Batch 92: Loss:     1.9207 Validation Accuracy: 0.574800\n",
      "Epoch  4, MNIST Batch 93: Loss:     1.8292 Validation Accuracy: 0.568400\n",
      "Epoch  4, MNIST Batch 94: Loss:     1.9189 Validation Accuracy: 0.574600\n",
      "Epoch  4, MNIST Batch 95: Loss:     1.9006 Validation Accuracy: 0.577600\n",
      "Epoch  4, MNIST Batch 96: Loss:     1.8760 Validation Accuracy: 0.576400\n",
      "Epoch  4, MNIST Batch 97: Loss:     1.8863 Validation Accuracy: 0.571200\n",
      "Epoch  4, MNIST Batch 98: Loss:     1.9349 Validation Accuracy: 0.572600\n",
      "Epoch  4, MNIST Batch 99: Loss:     1.9236 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 100: Loss:     1.8756 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 101: Loss:     1.8666 Validation Accuracy: 0.566400\n",
      "Epoch  4, MNIST Batch 102: Loss:     1.8686 Validation Accuracy: 0.568400\n",
      "Epoch  4, MNIST Batch 103: Loss:     1.9729 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 104: Loss:     1.8469 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 105: Loss:     1.8903 Validation Accuracy: 0.566400\n",
      "Epoch  4, MNIST Batch 106: Loss:     1.9655 Validation Accuracy: 0.559200\n",
      "Epoch  4, MNIST Batch 107: Loss:     1.9193 Validation Accuracy: 0.570600\n",
      "Epoch  4, MNIST Batch 108: Loss:     1.8949 Validation Accuracy: 0.577200\n",
      "Epoch  4, MNIST Batch 109: Loss:     1.8591 Validation Accuracy: 0.569200\n",
      "Epoch  4, MNIST Batch 110: Loss:     1.9200 Validation Accuracy: 0.556000\n",
      "Epoch  4, MNIST Batch 111: Loss:     1.9322 Validation Accuracy: 0.569400\n",
      "Epoch  4, MNIST Batch 112: Loss:     1.8908 Validation Accuracy: 0.579400\n",
      "Epoch  4, MNIST Batch 113: Loss:     1.8671 Validation Accuracy: 0.572200\n",
      "Epoch  4, MNIST Batch 114: Loss:     1.8846 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 115: Loss:     1.9074 Validation Accuracy: 0.577200\n",
      "Epoch  4, MNIST Batch 116: Loss:     1.8596 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 117: Loss:     1.9160 Validation Accuracy: 0.579400\n",
      "Epoch  4, MNIST Batch 118: Loss:     1.9063 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 119: Loss:     1.8838 Validation Accuracy: 0.578000\n",
      "Epoch  4, MNIST Batch 120: Loss:     1.9413 Validation Accuracy: 0.578800\n",
      "Epoch  4, MNIST Batch 121: Loss:     1.9004 Validation Accuracy: 0.578800\n",
      "Epoch  4, MNIST Batch 122: Loss:     1.8980 Validation Accuracy: 0.579400\n",
      "Epoch  4, MNIST Batch 123: Loss:     1.8838 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 124: Loss:     1.8976 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 125: Loss:     1.9077 Validation Accuracy: 0.576400\n",
      "Epoch  4, MNIST Batch 126: Loss:     1.8829 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 127: Loss:     1.8839 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 128: Loss:     1.9184 Validation Accuracy: 0.575200\n",
      "Epoch  4, MNIST Batch 129: Loss:     1.9300 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 130: Loss:     1.9379 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 131: Loss:     1.8396 Validation Accuracy: 0.578800\n",
      "Epoch  4, MNIST Batch 132: Loss:     1.8836 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 133: Loss:     1.8850 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 134: Loss:     1.8918 Validation Accuracy: 0.577200\n",
      "Epoch  4, MNIST Batch 135: Loss:     1.9246 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 136: Loss:     1.8915 Validation Accuracy: 0.576200\n",
      "Epoch  4, MNIST Batch 137: Loss:     1.9466 Validation Accuracy: 0.570600\n",
      "Epoch  4, MNIST Batch 138: Loss:     1.9018 Validation Accuracy: 0.573800\n",
      "Epoch  4, MNIST Batch 139: Loss:     1.8572 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 140: Loss:     1.8562 Validation Accuracy: 0.576000\n",
      "Epoch  4, MNIST Batch 141: Loss:     1.9275 Validation Accuracy: 0.571200\n",
      "Epoch  4, MNIST Batch 142: Loss:     1.8915 Validation Accuracy: 0.573600\n",
      "Epoch  4, MNIST Batch 143: Loss:     1.8977 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 144: Loss:     1.8636 Validation Accuracy: 0.575400\n",
      "Epoch  4, MNIST Batch 145: Loss:     1.9474 Validation Accuracy: 0.577400\n",
      "Epoch  4, MNIST Batch 146: Loss:     1.9456 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 147: Loss:     1.9324 Validation Accuracy: 0.578800\n",
      "Epoch  4, MNIST Batch 148: Loss:     1.8738 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 149: Loss:     1.8916 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 150: Loss:     1.8846 Validation Accuracy: 0.576600\n",
      "Epoch  4, MNIST Batch 151: Loss:     1.9127 Validation Accuracy: 0.577600\n",
      "Epoch  4, MNIST Batch 152: Loss:     1.8751 Validation Accuracy: 0.579200\n",
      "Epoch  4, MNIST Batch 153: Loss:     1.9795 Validation Accuracy: 0.577000\n",
      "Epoch  4, MNIST Batch 154: Loss:     1.9225 Validation Accuracy: 0.576800\n",
      "Epoch  4, MNIST Batch 155: Loss:     1.8832 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 156: Loss:     1.9190 Validation Accuracy: 0.578000\n",
      "Epoch  4, MNIST Batch 157: Loss:     1.8715 Validation Accuracy: 0.579000\n",
      "Epoch  4, MNIST Batch 158: Loss:     1.8985 Validation Accuracy: 0.573000\n",
      "Epoch  4, MNIST Batch 159: Loss:     1.8378 Validation Accuracy: 0.572800\n",
      "Epoch  4, MNIST Batch 160: Loss:     1.9283 Validation Accuracy: 0.578000\n",
      "Epoch  4, MNIST Batch 161: Loss:     1.8897 Validation Accuracy: 0.580000\n",
      "Epoch  4, MNIST Batch 162: Loss:     1.8895 Validation Accuracy: 0.572600\n",
      "Epoch  4, MNIST Batch 163: Loss:     1.8422 Validation Accuracy: 0.575800\n",
      "Epoch  4, MNIST Batch 164: Loss:     1.8544 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 165: Loss:     1.8726 Validation Accuracy: 0.580000\n",
      "Epoch  4, MNIST Batch 166: Loss:     1.9008 Validation Accuracy: 0.579200\n",
      "Epoch  4, MNIST Batch 167: Loss:     1.8910 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 168: Loss:     1.8841 Validation Accuracy: 0.580600\n",
      "Epoch  4, MNIST Batch 169: Loss:     1.8853 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 170: Loss:     1.9036 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 171: Loss:     1.8836 Validation Accuracy: 0.580200\n",
      "Epoch  4, MNIST Batch 172: Loss:     1.8838 Validation Accuracy: 0.578800\n",
      "Epoch  4, MNIST Batch 173: Loss:     1.9417 Validation Accuracy: 0.576400\n",
      "Epoch  4, MNIST Batch 174: Loss:     1.8818 Validation Accuracy: 0.577600\n",
      "Epoch  4, MNIST Batch 175: Loss:     1.8900 Validation Accuracy: 0.579400\n",
      "Epoch  4, MNIST Batch 176: Loss:     1.8698 Validation Accuracy: 0.580000\n",
      "Epoch  4, MNIST Batch 177: Loss:     1.9413 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 178: Loss:     1.8783 Validation Accuracy: 0.578200\n",
      "Epoch  4, MNIST Batch 179: Loss:     1.8582 Validation Accuracy: 0.580000\n",
      "Epoch  4, MNIST Batch 180: Loss:     1.8667 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 181: Loss:     1.8807 Validation Accuracy: 0.580400\n",
      "Epoch  4, MNIST Batch 182: Loss:     1.9176 Validation Accuracy: 0.580000\n",
      "Epoch  4, MNIST Batch 183: Loss:     1.9139 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 184: Loss:     1.9010 Validation Accuracy: 0.581400\n",
      "Epoch  4, MNIST Batch 185: Loss:     1.8632 Validation Accuracy: 0.579000\n",
      "Epoch  4, MNIST Batch 186: Loss:     1.8918 Validation Accuracy: 0.576800\n",
      "Epoch  4, MNIST Batch 187: Loss:     1.9025 Validation Accuracy: 0.578400\n",
      "Epoch  4, MNIST Batch 188: Loss:     1.8480 Validation Accuracy: 0.581400\n",
      "Epoch  4, MNIST Batch 189: Loss:     1.9122 Validation Accuracy: 0.581000\n",
      "Epoch  4, MNIST Batch 190: Loss:     1.9059 Validation Accuracy: 0.580800\n",
      "Epoch  4, MNIST Batch 191: Loss:     1.8988 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 192: Loss:     1.9015 Validation Accuracy: 0.577400\n",
      "Epoch  4, MNIST Batch 193: Loss:     1.9126 Validation Accuracy: 0.578600\n",
      "Epoch  4, MNIST Batch 194: Loss:     1.8539 Validation Accuracy: 0.579800\n",
      "Epoch  4, MNIST Batch 195: Loss:     1.9033 Validation Accuracy: 0.563200\n",
      "Epoch  4, MNIST Batch 196: Loss:     1.9018 Validation Accuracy: 0.566200\n",
      "Epoch  4, MNIST Batch 197: Loss:     1.8870 Validation Accuracy: 0.575600\n",
      "Epoch  4, MNIST Batch 198: Loss:     1.8455 Validation Accuracy: 0.581200\n",
      "Epoch  4, MNIST Batch 199: Loss:     1.9085 Validation Accuracy: 0.569000\n",
      "Epoch  4, MNIST Batch 200: Loss:     1.9516 Validation Accuracy: 0.557600\n",
      "Epoch  4, MNIST Batch 201: Loss:     1.8936 Validation Accuracy: 0.570000\n",
      "Epoch  4, MNIST Batch 202: Loss:     1.9310 Validation Accuracy: 0.580600\n",
      "Epoch  4, MNIST Batch 203: Loss:     1.9364 Validation Accuracy: 0.573400\n",
      "Epoch  4, MNIST Batch 204: Loss:     1.9674 Validation Accuracy: 0.564400\n",
      "Epoch  4, MNIST Batch 205: Loss:     1.9597 Validation Accuracy: 0.570600\n",
      "Epoch  4, MNIST Batch 206: Loss:     1.9355 Validation Accuracy: 0.577800\n",
      "Epoch  4, MNIST Batch 207: Loss:     1.9126 Validation Accuracy: 0.573000\n",
      "Epoch  4, MNIST Batch 208: Loss:     1.8867 Validation Accuracy: 0.567200\n",
      "Epoch  4, MNIST Batch 209: Loss:     1.8786 Validation Accuracy: 0.569200\n",
      "Epoch  4, MNIST Batch 210: Loss:     1.9096 Validation Accuracy: 0.577000\n",
      "Epoch  4, MNIST Batch 211: Loss:     1.8715 Validation Accuracy: 0.579600\n",
      "Epoch  4, MNIST Batch 212: Loss:     1.8652 Validation Accuracy: 0.566800\n",
      "Epoch  4, MNIST Batch 213: Loss:     1.9612 Validation Accuracy: 0.565600\n",
      "Epoch  5, MNIST Batch 0: Loss:     1.8543 Validation Accuracy: 0.575200\n",
      "Epoch  5, MNIST Batch 1: Loss:     1.8504 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 2: Loss:     1.9275 Validation Accuracy: 0.566600\n",
      "Epoch  5, MNIST Batch 3: Loss:     1.8857 Validation Accuracy: 0.563600\n",
      "Epoch  5, MNIST Batch 4: Loss:     1.8879 Validation Accuracy: 0.573200\n",
      "Epoch  5, MNIST Batch 5: Loss:     1.8124 Validation Accuracy: 0.574200\n",
      "Epoch  5, MNIST Batch 6: Loss:     1.9243 Validation Accuracy: 0.563800\n",
      "Epoch  5, MNIST Batch 7: Loss:     1.9527 Validation Accuracy: 0.557000\n",
      "Epoch  5, MNIST Batch 8: Loss:     1.9460 Validation Accuracy: 0.572400\n",
      "Epoch  5, MNIST Batch 9: Loss:     1.8954 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 10: Loss:     1.9043 Validation Accuracy: 0.577800\n",
      "Epoch  5, MNIST Batch 11: Loss:     1.9022 Validation Accuracy: 0.571200\n",
      "Epoch  5, MNIST Batch 12: Loss:     1.8537 Validation Accuracy: 0.575200\n",
      "Epoch  5, MNIST Batch 13: Loss:     1.9052 Validation Accuracy: 0.576800\n",
      "Epoch  5, MNIST Batch 14: Loss:     1.9156 Validation Accuracy: 0.569400\n",
      "Epoch  5, MNIST Batch 15: Loss:     1.8883 Validation Accuracy: 0.569800\n",
      "Epoch  5, MNIST Batch 16: Loss:     1.9036 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 17: Loss:     1.8891 Validation Accuracy: 0.582000\n",
      "Epoch  5, MNIST Batch 18: Loss:     1.9034 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 19: Loss:     1.8799 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 20: Loss:     1.8716 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 21: Loss:     1.9027 Validation Accuracy: 0.579000\n",
      "Epoch  5, MNIST Batch 22: Loss:     1.9312 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 23: Loss:     1.9373 Validation Accuracy: 0.577800\n",
      "Epoch  5, MNIST Batch 24: Loss:     1.8401 Validation Accuracy: 0.576800\n",
      "Epoch  5, MNIST Batch 25: Loss:     1.9230 Validation Accuracy: 0.574800\n",
      "Epoch  5, MNIST Batch 26: Loss:     1.8782 Validation Accuracy: 0.573000\n",
      "Epoch  5, MNIST Batch 27: Loss:     1.9084 Validation Accuracy: 0.573800\n",
      "Epoch  5, MNIST Batch 28: Loss:     1.9239 Validation Accuracy: 0.575200\n",
      "Epoch  5, MNIST Batch 29: Loss:     1.9033 Validation Accuracy: 0.578000\n",
      "Epoch  5, MNIST Batch 30: Loss:     1.8784 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 31: Loss:     1.8854 Validation Accuracy: 0.577800\n",
      "Epoch  5, MNIST Batch 32: Loss:     1.8737 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 33: Loss:     1.8286 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 34: Loss:     1.8850 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 35: Loss:     1.9041 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 36: Loss:     1.8636 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 37: Loss:     1.9086 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 38: Loss:     1.9026 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 39: Loss:     1.9214 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 40: Loss:     1.8918 Validation Accuracy: 0.581400\n",
      "Epoch  5, MNIST Batch 41: Loss:     1.9252 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 42: Loss:     1.8886 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 43: Loss:     1.8744 Validation Accuracy: 0.581400\n",
      "Epoch  5, MNIST Batch 44: Loss:     1.8296 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 45: Loss:     1.8063 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 46: Loss:     1.9051 Validation Accuracy: 0.582600\n",
      "Epoch  5, MNIST Batch 47: Loss:     1.8478 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 48: Loss:     1.9024 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 49: Loss:     1.9123 Validation Accuracy: 0.578200\n",
      "Epoch  5, MNIST Batch 50: Loss:     1.8660 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 51: Loss:     1.8907 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 52: Loss:     1.9393 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 53: Loss:     1.9072 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 54: Loss:     1.8695 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 55: Loss:     1.9060 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 56: Loss:     1.8742 Validation Accuracy: 0.580400\n",
      "Epoch  5, MNIST Batch 57: Loss:     1.8984 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 58: Loss:     1.9387 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 59: Loss:     1.9432 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 60: Loss:     1.8640 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 61: Loss:     1.8916 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 62: Loss:     1.8895 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 63: Loss:     1.9025 Validation Accuracy: 0.579200\n",
      "Epoch  5, MNIST Batch 64: Loss:     1.8959 Validation Accuracy: 0.576200\n",
      "Epoch  5, MNIST Batch 65: Loss:     1.9084 Validation Accuracy: 0.576600\n",
      "Epoch  5, MNIST Batch 66: Loss:     1.8883 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 67: Loss:     1.9115 Validation Accuracy: 0.583600\n",
      "Epoch  5, MNIST Batch 68: Loss:     1.8748 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 69: Loss:     1.8718 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 70: Loss:     1.8450 Validation Accuracy: 0.583600\n",
      "Epoch  5, MNIST Batch 71: Loss:     1.8895 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 72: Loss:     1.9073 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 73: Loss:     1.9115 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 74: Loss:     1.9057 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 75: Loss:     1.8837 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 76: Loss:     1.8812 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 77: Loss:     1.8671 Validation Accuracy: 0.580400\n",
      "Epoch  5, MNIST Batch 78: Loss:     1.8415 Validation Accuracy: 0.582800\n",
      "Epoch  5, MNIST Batch 79: Loss:     1.8631 Validation Accuracy: 0.582000\n",
      "Epoch  5, MNIST Batch 80: Loss:     1.8979 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 81: Loss:     1.9025 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 82: Loss:     1.8719 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 83: Loss:     1.9066 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 84: Loss:     1.9046 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 85: Loss:     1.9272 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 86: Loss:     1.9073 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 87: Loss:     1.9046 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 88: Loss:     1.8357 Validation Accuracy: 0.583400\n",
      "Epoch  5, MNIST Batch 89: Loss:     1.9466 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 90: Loss:     1.9281 Validation Accuracy: 0.579200\n",
      "Epoch  5, MNIST Batch 91: Loss:     1.9076 Validation Accuracy: 0.579800\n",
      "Epoch  5, MNIST Batch 92: Loss:     1.9264 Validation Accuracy: 0.580400\n",
      "Epoch  5, MNIST Batch 93: Loss:     1.8606 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 94: Loss:     1.8481 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 95: Loss:     1.8880 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 96: Loss:     1.8863 Validation Accuracy: 0.582600\n",
      "Epoch  5, MNIST Batch 97: Loss:     1.8770 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 98: Loss:     1.8609 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 99: Loss:     1.8415 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 100: Loss:     1.8636 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 101: Loss:     1.9210 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 102: Loss:     1.8661 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 103: Loss:     1.8927 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 104: Loss:     1.8434 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 105: Loss:     1.9057 Validation Accuracy: 0.579600\n",
      "Epoch  5, MNIST Batch 106: Loss:     1.8844 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 107: Loss:     1.8870 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 108: Loss:     1.9128 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 109: Loss:     1.8907 Validation Accuracy: 0.576600\n",
      "Epoch  5, MNIST Batch 110: Loss:     1.9277 Validation Accuracy: 0.578800\n",
      "Epoch  5, MNIST Batch 111: Loss:     1.9125 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 112: Loss:     1.8977 Validation Accuracy: 0.580800\n",
      "Epoch  5, MNIST Batch 113: Loss:     1.9123 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 114: Loss:     1.8880 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 115: Loss:     1.9144 Validation Accuracy: 0.579200\n",
      "Epoch  5, MNIST Batch 116: Loss:     1.8889 Validation Accuracy: 0.579000\n",
      "Epoch  5, MNIST Batch 117: Loss:     1.9153 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 118: Loss:     1.9136 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 119: Loss:     1.9195 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 120: Loss:     1.9197 Validation Accuracy: 0.578800\n",
      "Epoch  5, MNIST Batch 121: Loss:     1.8512 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 122: Loss:     1.9093 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 123: Loss:     1.8983 Validation Accuracy: 0.575600\n",
      "Epoch  5, MNIST Batch 124: Loss:     1.8803 Validation Accuracy: 0.572600\n",
      "Epoch  5, MNIST Batch 125: Loss:     1.8840 Validation Accuracy: 0.581200\n",
      "Epoch  5, MNIST Batch 126: Loss:     1.8970 Validation Accuracy: 0.582000\n",
      "Epoch  5, MNIST Batch 127: Loss:     1.8889 Validation Accuracy: 0.578200\n",
      "Epoch  5, MNIST Batch 128: Loss:     1.8868 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 129: Loss:     1.8523 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 130: Loss:     1.8573 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 131: Loss:     1.8523 Validation Accuracy: 0.572000\n",
      "Epoch  5, MNIST Batch 132: Loss:     1.9268 Validation Accuracy: 0.570000\n",
      "Epoch  5, MNIST Batch 133: Loss:     1.8851 Validation Accuracy: 0.574600\n",
      "Epoch  5, MNIST Batch 134: Loss:     1.9142 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 135: Loss:     1.8955 Validation Accuracy: 0.578800\n",
      "Epoch  5, MNIST Batch 136: Loss:     1.8847 Validation Accuracy: 0.574800\n",
      "Epoch  5, MNIST Batch 137: Loss:     1.9201 Validation Accuracy: 0.578200\n",
      "Epoch  5, MNIST Batch 138: Loss:     1.9148 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 139: Loss:     1.9349 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 140: Loss:     1.9295 Validation Accuracy: 0.579400\n",
      "Epoch  5, MNIST Batch 141: Loss:     1.9385 Validation Accuracy: 0.577000\n",
      "Epoch  5, MNIST Batch 142: Loss:     1.8897 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 143: Loss:     1.8674 Validation Accuracy: 0.582200\n",
      "Epoch  5, MNIST Batch 144: Loss:     1.8475 Validation Accuracy: 0.583800\n",
      "Epoch  5, MNIST Batch 145: Loss:     1.9508 Validation Accuracy: 0.580600\n",
      "Epoch  5, MNIST Batch 146: Loss:     1.8480 Validation Accuracy: 0.578200\n",
      "Epoch  5, MNIST Batch 147: Loss:     1.9034 Validation Accuracy: 0.577600\n",
      "Epoch  5, MNIST Batch 148: Loss:     1.9147 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 149: Loss:     1.8794 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 150: Loss:     1.9394 Validation Accuracy: 0.576200\n",
      "Epoch  5, MNIST Batch 151: Loss:     1.8879 Validation Accuracy: 0.574800\n",
      "Epoch  5, MNIST Batch 152: Loss:     1.8868 Validation Accuracy: 0.578600\n",
      "Epoch  5, MNIST Batch 153: Loss:     1.9008 Validation Accuracy: 0.584200\n",
      "Epoch  5, MNIST Batch 154: Loss:     1.8268 Validation Accuracy: 0.579800\n",
      "Epoch  5, MNIST Batch 155: Loss:     1.9220 Validation Accuracy: 0.572000\n",
      "Epoch  5, MNIST Batch 156: Loss:     1.9621 Validation Accuracy: 0.571200\n",
      "Epoch  5, MNIST Batch 157: Loss:     1.9407 Validation Accuracy: 0.577000\n",
      "Epoch  5, MNIST Batch 158: Loss:     1.8496 Validation Accuracy: 0.583000\n",
      "Epoch  5, MNIST Batch 159: Loss:     1.9330 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 160: Loss:     1.8862 Validation Accuracy: 0.574400\n",
      "Epoch  5, MNIST Batch 161: Loss:     1.9675 Validation Accuracy: 0.573600\n",
      "Epoch  5, MNIST Batch 162: Loss:     1.8758 Validation Accuracy: 0.580400\n",
      "Epoch  5, MNIST Batch 163: Loss:     1.9318 Validation Accuracy: 0.581800\n",
      "Epoch  5, MNIST Batch 164: Loss:     1.8445 Validation Accuracy: 0.575600\n",
      "Epoch  5, MNIST Batch 165: Loss:     1.8858 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 166: Loss:     1.8992 Validation Accuracy: 0.582600\n",
      "Epoch  5, MNIST Batch 167: Loss:     1.8631 Validation Accuracy: 0.574000\n",
      "Epoch  5, MNIST Batch 168: Loss:     1.8996 Validation Accuracy: 0.571200\n",
      "Epoch  5, MNIST Batch 169: Loss:     1.9097 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 170: Loss:     1.8967 Validation Accuracy: 0.584400\n",
      "Epoch  5, MNIST Batch 171: Loss:     1.9065 Validation Accuracy: 0.579800\n",
      "Epoch  5, MNIST Batch 172: Loss:     1.8706 Validation Accuracy: 0.576000\n",
      "Epoch  5, MNIST Batch 173: Loss:     1.9047 Validation Accuracy: 0.579000\n",
      "Epoch  5, MNIST Batch 174: Loss:     1.8543 Validation Accuracy: 0.581400\n",
      "Epoch  5, MNIST Batch 175: Loss:     1.8527 Validation Accuracy: 0.576200\n",
      "Epoch  5, MNIST Batch 176: Loss:     1.9245 Validation Accuracy: 0.577000\n",
      "Epoch  5, MNIST Batch 177: Loss:     1.9224 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 178: Loss:     1.8678 Validation Accuracy: 0.582800\n",
      "Epoch  5, MNIST Batch 179: Loss:     1.8886 Validation Accuracy: 0.584400\n",
      "Epoch  5, MNIST Batch 180: Loss:     1.8681 Validation Accuracy: 0.581000\n",
      "Epoch  5, MNIST Batch 181: Loss:     1.8777 Validation Accuracy: 0.578000\n",
      "Epoch  5, MNIST Batch 182: Loss:     1.8755 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 183: Loss:     1.9101 Validation Accuracy: 0.583200\n",
      "Epoch  5, MNIST Batch 184: Loss:     1.8743 Validation Accuracy: 0.580200\n",
      "Epoch  5, MNIST Batch 185: Loss:     1.9254 Validation Accuracy: 0.577000\n",
      "Epoch  5, MNIST Batch 186: Loss:     1.9572 Validation Accuracy: 0.578800\n",
      "Epoch  5, MNIST Batch 187: Loss:     1.8880 Validation Accuracy: 0.585000\n",
      "Epoch  5, MNIST Batch 188: Loss:     1.8966 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 189: Loss:     1.9258 Validation Accuracy: 0.578800\n",
      "Epoch  5, MNIST Batch 190: Loss:     1.8415 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 191: Loss:     1.8919 Validation Accuracy: 0.583000\n",
      "Epoch  5, MNIST Batch 192: Loss:     1.8935 Validation Accuracy: 0.577800\n",
      "Epoch  5, MNIST Batch 193: Loss:     1.8493 Validation Accuracy: 0.582000\n",
      "Epoch  5, MNIST Batch 194: Loss:     1.8857 Validation Accuracy: 0.582600\n",
      "Epoch  5, MNIST Batch 195: Loss:     1.8844 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 196: Loss:     1.9485 Validation Accuracy: 0.582400\n",
      "Epoch  5, MNIST Batch 197: Loss:     1.9110 Validation Accuracy: 0.583800\n",
      "Epoch  5, MNIST Batch 198: Loss:     1.8920 Validation Accuracy: 0.583600\n",
      "Epoch  5, MNIST Batch 199: Loss:     1.9297 Validation Accuracy: 0.583600\n",
      "Epoch  5, MNIST Batch 200: Loss:     1.8761 Validation Accuracy: 0.582800\n",
      "Epoch  5, MNIST Batch 201: Loss:     1.9132 Validation Accuracy: 0.580400\n",
      "Epoch  5, MNIST Batch 202: Loss:     1.9089 Validation Accuracy: 0.578000\n",
      "Epoch  5, MNIST Batch 203: Loss:     1.8686 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 204: Loss:     1.7941 Validation Accuracy: 0.581600\n",
      "Epoch  5, MNIST Batch 205: Loss:     1.8670 Validation Accuracy: 0.580000\n",
      "Epoch  5, MNIST Batch 206: Loss:     1.9092 Validation Accuracy: 0.578400\n",
      "Epoch  5, MNIST Batch 207: Loss:     1.9293 Validation Accuracy: 0.581400\n",
      "Epoch  5, MNIST Batch 208: Loss:     1.9041 Validation Accuracy: 0.579800\n",
      "Epoch  5, MNIST Batch 209: Loss:     1.8789 Validation Accuracy: 0.568800\n",
      "Epoch  5, MNIST Batch 210: Loss:     1.9147 Validation Accuracy: 0.563600\n",
      "Epoch  5, MNIST Batch 211: Loss:     1.9116 Validation Accuracy: 0.574800\n",
      "Epoch  5, MNIST Batch 212: Loss:     1.8678 Validation Accuracy: 0.584600\n",
      "Epoch  5, MNIST Batch 213: Loss:     1.8664 Validation Accuracy: 0.577800\n",
      "Epoch  6, MNIST Batch 0: Loss:     1.9256 Validation Accuracy: 0.568400\n",
      "Epoch  6, MNIST Batch 1: Loss:     1.9197 Validation Accuracy: 0.559800\n",
      "Epoch  6, MNIST Batch 2: Loss:     1.8866 Validation Accuracy: 0.577800\n",
      "Epoch  6, MNIST Batch 3: Loss:     1.9086 Validation Accuracy: 0.582200\n",
      "Epoch  6, MNIST Batch 4: Loss:     1.8967 Validation Accuracy: 0.574600\n",
      "Epoch  6, MNIST Batch 5: Loss:     1.8947 Validation Accuracy: 0.565000\n",
      "Epoch  6, MNIST Batch 6: Loss:     1.8825 Validation Accuracy: 0.572800\n",
      "Epoch  6, MNIST Batch 7: Loss:     1.8456 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 8: Loss:     1.9083 Validation Accuracy: 0.578800\n",
      "Epoch  6, MNIST Batch 9: Loss:     1.9178 Validation Accuracy: 0.566600\n",
      "Epoch  6, MNIST Batch 10: Loss:     1.8752 Validation Accuracy: 0.562600\n",
      "Epoch  6, MNIST Batch 11: Loss:     1.9032 Validation Accuracy: 0.579800\n",
      "Epoch  6, MNIST Batch 12: Loss:     1.8353 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 13: Loss:     1.9212 Validation Accuracy: 0.577000\n",
      "Epoch  6, MNIST Batch 14: Loss:     1.8624 Validation Accuracy: 0.576200\n",
      "Epoch  6, MNIST Batch 15: Loss:     1.9097 Validation Accuracy: 0.580000\n",
      "Epoch  6, MNIST Batch 16: Loss:     1.8681 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 17: Loss:     1.8855 Validation Accuracy: 0.582000\n",
      "Epoch  6, MNIST Batch 18: Loss:     1.9272 Validation Accuracy: 0.580400\n",
      "Epoch  6, MNIST Batch 19: Loss:     1.8747 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 20: Loss:     1.8830 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 21: Loss:     1.9609 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 22: Loss:     1.8632 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 23: Loss:     1.8886 Validation Accuracy: 0.580600\n",
      "Epoch  6, MNIST Batch 24: Loss:     1.8799 Validation Accuracy: 0.577600\n",
      "Epoch  6, MNIST Batch 25: Loss:     1.8311 Validation Accuracy: 0.578800\n",
      "Epoch  6, MNIST Batch 26: Loss:     1.8889 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 27: Loss:     1.8643 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 28: Loss:     1.8966 Validation Accuracy: 0.577400\n",
      "Epoch  6, MNIST Batch 29: Loss:     1.9128 Validation Accuracy: 0.574600\n",
      "Epoch  6, MNIST Batch 30: Loss:     1.8820 Validation Accuracy: 0.578800\n",
      "Epoch  6, MNIST Batch 31: Loss:     1.8789 Validation Accuracy: 0.582600\n",
      "Epoch  6, MNIST Batch 32: Loss:     1.9259 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 33: Loss:     1.8376 Validation Accuracy: 0.575800\n",
      "Epoch  6, MNIST Batch 34: Loss:     1.8972 Validation Accuracy: 0.574000\n",
      "Epoch  6, MNIST Batch 35: Loss:     1.9158 Validation Accuracy: 0.579200\n",
      "Epoch  6, MNIST Batch 36: Loss:     1.8770 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 37: Loss:     1.9166 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 38: Loss:     1.8842 Validation Accuracy: 0.577600\n",
      "Epoch  6, MNIST Batch 39: Loss:     1.8661 Validation Accuracy: 0.575000\n",
      "Epoch  6, MNIST Batch 40: Loss:     1.9104 Validation Accuracy: 0.577400\n",
      "Epoch  6, MNIST Batch 41: Loss:     1.8520 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 42: Loss:     1.9157 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 43: Loss:     1.8278 Validation Accuracy: 0.582200\n",
      "Epoch  6, MNIST Batch 44: Loss:     1.9732 Validation Accuracy: 0.581000\n",
      "Epoch  6, MNIST Batch 45: Loss:     1.8734 Validation Accuracy: 0.582200\n",
      "Epoch  6, MNIST Batch 46: Loss:     1.9160 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 47: Loss:     1.9100 Validation Accuracy: 0.580400\n",
      "Epoch  6, MNIST Batch 48: Loss:     1.9075 Validation Accuracy: 0.574800\n",
      "Epoch  6, MNIST Batch 49: Loss:     1.8961 Validation Accuracy: 0.579600\n",
      "Epoch  6, MNIST Batch 50: Loss:     1.8520 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 51: Loss:     1.8992 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 52: Loss:     1.9018 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 53: Loss:     1.9018 Validation Accuracy: 0.582000\n",
      "Epoch  6, MNIST Batch 54: Loss:     1.8743 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 55: Loss:     1.9170 Validation Accuracy: 0.581400\n",
      "Epoch  6, MNIST Batch 56: Loss:     1.9633 Validation Accuracy: 0.580800\n",
      "Epoch  6, MNIST Batch 57: Loss:     1.8809 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 58: Loss:     1.8750 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 59: Loss:     1.8454 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 60: Loss:     1.9100 Validation Accuracy: 0.582600\n",
      "Epoch  6, MNIST Batch 61: Loss:     1.9261 Validation Accuracy: 0.581400\n",
      "Epoch  6, MNIST Batch 62: Loss:     1.8973 Validation Accuracy: 0.581800\n",
      "Epoch  6, MNIST Batch 63: Loss:     1.9325 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 64: Loss:     1.9217 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 65: Loss:     1.8413 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 66: Loss:     1.8826 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 67: Loss:     1.8809 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 68: Loss:     1.8731 Validation Accuracy: 0.584600\n",
      "Epoch  6, MNIST Batch 69: Loss:     1.9002 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 70: Loss:     1.8448 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 71: Loss:     1.9100 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 72: Loss:     1.8824 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 73: Loss:     1.9296 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 74: Loss:     1.8765 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 75: Loss:     1.8576 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 76: Loss:     1.8153 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 77: Loss:     1.9558 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 78: Loss:     1.9087 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 79: Loss:     1.8951 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 80: Loss:     1.8769 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 81: Loss:     1.8488 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 82: Loss:     1.8300 Validation Accuracy: 0.585400\n",
      "Epoch  6, MNIST Batch 83: Loss:     1.8659 Validation Accuracy: 0.585000\n",
      "Epoch  6, MNIST Batch 84: Loss:     1.8795 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 85: Loss:     1.8563 Validation Accuracy: 0.579400\n",
      "Epoch  6, MNIST Batch 86: Loss:     1.8793 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 87: Loss:     1.8745 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 88: Loss:     1.8812 Validation Accuracy: 0.579800\n",
      "Epoch  6, MNIST Batch 89: Loss:     1.8749 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 90: Loss:     1.9065 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 91: Loss:     1.8706 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 92: Loss:     1.8940 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 93: Loss:     1.8702 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 94: Loss:     1.8654 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 95: Loss:     1.8625 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 96: Loss:     1.8973 Validation Accuracy: 0.580200\n",
      "Epoch  6, MNIST Batch 97: Loss:     1.8986 Validation Accuracy: 0.580000\n",
      "Epoch  6, MNIST Batch 98: Loss:     1.8975 Validation Accuracy: 0.581800\n",
      "Epoch  6, MNIST Batch 99: Loss:     1.9333 Validation Accuracy: 0.584600\n",
      "Epoch  6, MNIST Batch 100: Loss:     1.8910 Validation Accuracy: 0.584000\n",
      "Epoch  6, MNIST Batch 101: Loss:     1.9168 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 102: Loss:     1.8533 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 103: Loss:     1.8895 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 104: Loss:     1.9119 Validation Accuracy: 0.580200\n",
      "Epoch  6, MNIST Batch 105: Loss:     1.8652 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 106: Loss:     1.9301 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 107: Loss:     1.9557 Validation Accuracy: 0.585400\n",
      "Epoch  6, MNIST Batch 108: Loss:     1.9028 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 109: Loss:     1.9257 Validation Accuracy: 0.576600\n",
      "Epoch  6, MNIST Batch 110: Loss:     1.9167 Validation Accuracy: 0.577000\n",
      "Epoch  6, MNIST Batch 111: Loss:     1.9561 Validation Accuracy: 0.578200\n",
      "Epoch  6, MNIST Batch 112: Loss:     1.9041 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 113: Loss:     1.8470 Validation Accuracy: 0.580800\n",
      "Epoch  6, MNIST Batch 114: Loss:     1.9162 Validation Accuracy: 0.569800\n",
      "Epoch  6, MNIST Batch 115: Loss:     1.9077 Validation Accuracy: 0.566800\n",
      "Epoch  6, MNIST Batch 116: Loss:     1.8689 Validation Accuracy: 0.581000\n",
      "Epoch  6, MNIST Batch 117: Loss:     1.9125 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 118: Loss:     1.8995 Validation Accuracy: 0.570400\n",
      "Epoch  6, MNIST Batch 119: Loss:     1.9060 Validation Accuracy: 0.561400\n",
      "Epoch  6, MNIST Batch 120: Loss:     1.9415 Validation Accuracy: 0.578200\n",
      "Epoch  6, MNIST Batch 121: Loss:     1.8358 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 122: Loss:     1.8862 Validation Accuracy: 0.559200\n",
      "Epoch  6, MNIST Batch 123: Loss:     1.9484 Validation Accuracy: 0.551000\n",
      "Epoch  6, MNIST Batch 124: Loss:     1.8499 Validation Accuracy: 0.581200\n",
      "Epoch  6, MNIST Batch 125: Loss:     1.9484 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 126: Loss:     1.9026 Validation Accuracy: 0.570600\n",
      "Epoch  6, MNIST Batch 127: Loss:     1.9072 Validation Accuracy: 0.564200\n",
      "Epoch  6, MNIST Batch 128: Loss:     1.9169 Validation Accuracy: 0.573200\n",
      "Epoch  6, MNIST Batch 129: Loss:     1.9306 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 130: Loss:     1.8571 Validation Accuracy: 0.578200\n",
      "Epoch  6, MNIST Batch 131: Loss:     1.8738 Validation Accuracy: 0.556600\n",
      "Epoch  6, MNIST Batch 132: Loss:     1.8759 Validation Accuracy: 0.564800\n",
      "Epoch  6, MNIST Batch 133: Loss:     1.8590 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 134: Loss:     1.9136 Validation Accuracy: 0.582000\n",
      "Epoch  6, MNIST Batch 135: Loss:     1.9104 Validation Accuracy: 0.563600\n",
      "Epoch  6, MNIST Batch 136: Loss:     1.9538 Validation Accuracy: 0.547000\n",
      "Epoch  6, MNIST Batch 137: Loss:     1.9211 Validation Accuracy: 0.553600\n",
      "Epoch  6, MNIST Batch 138: Loss:     1.8441 Validation Accuracy: 0.573600\n",
      "Epoch  6, MNIST Batch 139: Loss:     1.8810 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 140: Loss:     1.8659 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 141: Loss:     1.8902 Validation Accuracy: 0.574800\n",
      "Epoch  6, MNIST Batch 142: Loss:     1.9215 Validation Accuracy: 0.574400\n",
      "Epoch  6, MNIST Batch 143: Loss:     1.8641 Validation Accuracy: 0.578200\n",
      "Epoch  6, MNIST Batch 144: Loss:     1.8913 Validation Accuracy: 0.577800\n",
      "Epoch  6, MNIST Batch 145: Loss:     1.8775 Validation Accuracy: 0.579000\n",
      "Epoch  6, MNIST Batch 146: Loss:     1.9134 Validation Accuracy: 0.578000\n",
      "Epoch  6, MNIST Batch 147: Loss:     1.9273 Validation Accuracy: 0.580800\n",
      "Epoch  6, MNIST Batch 148: Loss:     1.8802 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 149: Loss:     1.8480 Validation Accuracy: 0.584600\n",
      "Epoch  6, MNIST Batch 150: Loss:     1.8827 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 151: Loss:     1.8646 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 152: Loss:     1.8620 Validation Accuracy: 0.583400\n",
      "Epoch  6, MNIST Batch 153: Loss:     1.9127 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 154: Loss:     1.8564 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 155: Loss:     1.8642 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 156: Loss:     1.9105 Validation Accuracy: 0.584600\n",
      "Epoch  6, MNIST Batch 157: Loss:     1.8533 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 158: Loss:     1.8796 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 159: Loss:     1.8758 Validation Accuracy: 0.585000\n",
      "Epoch  6, MNIST Batch 160: Loss:     1.9532 Validation Accuracy: 0.585400\n",
      "Epoch  6, MNIST Batch 161: Loss:     1.8746 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 162: Loss:     1.9204 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 163: Loss:     1.8995 Validation Accuracy: 0.583600\n",
      "Epoch  6, MNIST Batch 164: Loss:     1.9312 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 165: Loss:     1.9467 Validation Accuracy: 0.581400\n",
      "Epoch  6, MNIST Batch 166: Loss:     1.8761 Validation Accuracy: 0.579200\n",
      "Epoch  6, MNIST Batch 167: Loss:     1.9258 Validation Accuracy: 0.581800\n",
      "Epoch  6, MNIST Batch 168: Loss:     1.9008 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 169: Loss:     1.8872 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 170: Loss:     1.8733 Validation Accuracy: 0.579800\n",
      "Epoch  6, MNIST Batch 171: Loss:     1.8564 Validation Accuracy: 0.575600\n",
      "Epoch  6, MNIST Batch 172: Loss:     1.9020 Validation Accuracy: 0.577200\n",
      "Epoch  6, MNIST Batch 173: Loss:     1.8874 Validation Accuracy: 0.581600\n",
      "Epoch  6, MNIST Batch 174: Loss:     1.9052 Validation Accuracy: 0.585000\n",
      "Epoch  6, MNIST Batch 175: Loss:     1.8669 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 176: Loss:     1.9483 Validation Accuracy: 0.580600\n",
      "Epoch  6, MNIST Batch 177: Loss:     1.8658 Validation Accuracy: 0.580200\n",
      "Epoch  6, MNIST Batch 178: Loss:     1.8526 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 179: Loss:     1.8463 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 180: Loss:     1.9341 Validation Accuracy: 0.583000\n",
      "Epoch  6, MNIST Batch 181: Loss:     1.8513 Validation Accuracy: 0.582800\n",
      "Epoch  6, MNIST Batch 182: Loss:     1.8710 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 183: Loss:     1.9370 Validation Accuracy: 0.584800\n",
      "Epoch  6, MNIST Batch 184: Loss:     1.8630 Validation Accuracy: 0.582200\n",
      "Epoch  6, MNIST Batch 185: Loss:     1.8728 Validation Accuracy: 0.582400\n",
      "Epoch  6, MNIST Batch 186: Loss:     1.8825 Validation Accuracy: 0.581800\n",
      "Epoch  6, MNIST Batch 187: Loss:     1.8849 Validation Accuracy: 0.582200\n",
      "Epoch  6, MNIST Batch 188: Loss:     1.8949 Validation Accuracy: 0.583200\n",
      "Epoch  6, MNIST Batch 189: Loss:     1.8921 Validation Accuracy: 0.583800\n",
      "Epoch  6, MNIST Batch 190: Loss:     1.8827 Validation Accuracy: 0.585400\n",
      "Epoch  6, MNIST Batch 191: Loss:     1.8752 Validation Accuracy: 0.585800\n",
      "Epoch  6, MNIST Batch 192: Loss:     1.8649 Validation Accuracy: 0.585200\n",
      "Epoch  6, MNIST Batch 193: Loss:     1.9019 Validation Accuracy: 0.586400\n",
      "Epoch  6, MNIST Batch 194: Loss:     1.8692 Validation Accuracy: 0.586600\n",
      "Epoch  6, MNIST Batch 195: Loss:     1.8988 Validation Accuracy: 0.586600\n",
      "Epoch  6, MNIST Batch 196: Loss:     1.8823 Validation Accuracy: 0.585600\n",
      "Epoch  6, MNIST Batch 197: Loss:     1.8711 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 198: Loss:     1.8480 Validation Accuracy: 0.584200\n",
      "Epoch  6, MNIST Batch 199: Loss:     1.8574 Validation Accuracy: 0.584400\n",
      "Epoch  6, MNIST Batch 200: Loss:     1.8928 Validation Accuracy: 0.585800\n",
      "Epoch  6, MNIST Batch 201: Loss:     1.9073 Validation Accuracy: 0.585600\n",
      "Epoch  6, MNIST Batch 202: Loss:     1.8442 Validation Accuracy: 0.586400\n",
      "Epoch  6, MNIST Batch 203: Loss:     1.8603 Validation Accuracy: 0.586200\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './numbers_network_model'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            batch_features = batch[0].reshape((-1, 28, 28, 1))\n",
    "            batch_labels = batch[1]\n",
    "            train_neural_network(sess, optimizer, batch_features, batch_labels)\n",
    "            \n",
    "            print_training_stats(sess, epoch, i, \n",
    "                                 batch_features, batch_labels, \n",
    "                                 mnist.validation.images.reshape((-1, 28, 28, 1)), mnist.validation.labels,\n",
    "                                 cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testing the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Testing helpers\n",
    "\n",
    "def display_image_predictions(features, labels, predictions, n_classes):\n",
    "   \n",
    "    label_names = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=3)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "        axies[image_i][0].imshow(feature.reshape((feature.shape[0],feature.shape[1])))\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./numbers_network_model\n",
      "Testing Accuracy: 0.09685496794871795\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAAJ/CAYAAADRS4SdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6ad3c0d68>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 391
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    test_features = mnist.test.images.reshape((-1, 28, 28, 1))\n",
    "    test_labels = mnist.test.labels\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Getting Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for i in range(mnist.test.num_examples//batch_size):\n",
    "            batch = mnist.test.next_batch(batch_size)\n",
    "            test_feature_batch = batch[0].reshape((-1, 28, 28, 1))\n",
    "            test_label_batch = batch[1]\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch })\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions, 10)\n",
    "\n",
    "test_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
