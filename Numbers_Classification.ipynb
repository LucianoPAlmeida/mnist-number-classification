{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualizing an image data set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkNTfAMTH3ba7J46EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fced29c2be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "label = mnist.train.labels[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(inputs, keep_prob):\n",
    "    conv = tf.layers.conv2d(inputs, 32, (5,5), padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    conv = tf.layers.max_pooling2d(conv,(2,2), (2,2), padding='same')\n",
    "\n",
    "    conv = tf.layers.conv2d(conv, 64, (5,5), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    conv = tf.layers.max_pooling2d(conv,(2,2), (2,2), padding='same')\n",
    "        \n",
    "    conv = tf.contrib.layers.flatten(conv)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 1024, activation_fn=tf.nn.relu)\n",
    "        \n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "\n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10, activation_fn=None)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='x')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='y')\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Network training hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 512\n",
    "keep_probability = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Training helper functions    \n",
    "\n",
    "def train_neural_network(session, optimizer, feature_batch, label_batch):\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability\n",
    "    })\n",
    "    \n",
    "def print_training_stats(session, epoch, batch_i, feature_batch, label_batch, validation_feature, validation_label, cost, accuracy):\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x: validation_feature,\n",
    "                y: validation_label,\n",
    "                keep_prob: 1.0 })\n",
    "    print('Epoch {:>2}, MNIST Batch {}: Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch + 1, batch_i, loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, MNIST Batch 0: Loss:     2.3007 Validation Accuracy: 0.160000\n",
      "Epoch  1, MNIST Batch 1: Loss:     2.2933 Validation Accuracy: 0.174800\n",
      "Epoch  1, MNIST Batch 2: Loss:     2.2924 Validation Accuracy: 0.184800\n",
      "Epoch  1, MNIST Batch 3: Loss:     2.2857 Validation Accuracy: 0.194600\n",
      "Epoch  1, MNIST Batch 4: Loss:     2.2834 Validation Accuracy: 0.205600\n",
      "Epoch  1, MNIST Batch 5: Loss:     2.2871 Validation Accuracy: 0.216000\n",
      "Epoch  1, MNIST Batch 6: Loss:     2.2838 Validation Accuracy: 0.226000\n",
      "Epoch  1, MNIST Batch 7: Loss:     2.2795 Validation Accuracy: 0.235600\n",
      "Epoch  1, MNIST Batch 8: Loss:     2.2737 Validation Accuracy: 0.244000\n",
      "Epoch  1, MNIST Batch 9: Loss:     2.2718 Validation Accuracy: 0.255400\n",
      "Epoch  1, MNIST Batch 10: Loss:     2.2711 Validation Accuracy: 0.266600\n",
      "Epoch  1, MNIST Batch 11: Loss:     2.2629 Validation Accuracy: 0.282800\n",
      "Epoch  1, MNIST Batch 12: Loss:     2.2632 Validation Accuracy: 0.302600\n",
      "Epoch  1, MNIST Batch 13: Loss:     2.2626 Validation Accuracy: 0.323600\n",
      "Epoch  1, MNIST Batch 14: Loss:     2.2576 Validation Accuracy: 0.348600\n",
      "Epoch  1, MNIST Batch 15: Loss:     2.2515 Validation Accuracy: 0.369600\n",
      "Epoch  1, MNIST Batch 16: Loss:     2.2509 Validation Accuracy: 0.387200\n",
      "Epoch  1, MNIST Batch 17: Loss:     2.2523 Validation Accuracy: 0.408200\n",
      "Epoch  1, MNIST Batch 18: Loss:     2.2422 Validation Accuracy: 0.429000\n",
      "Epoch  1, MNIST Batch 19: Loss:     2.2434 Validation Accuracy: 0.450000\n",
      "Epoch  1, MNIST Batch 20: Loss:     2.2383 Validation Accuracy: 0.466600\n",
      "Epoch  1, MNIST Batch 21: Loss:     2.2373 Validation Accuracy: 0.485000\n",
      "Epoch  1, MNIST Batch 22: Loss:     2.2337 Validation Accuracy: 0.501000\n",
      "Epoch  1, MNIST Batch 23: Loss:     2.2288 Validation Accuracy: 0.515000\n",
      "Epoch  1, MNIST Batch 24: Loss:     2.2273 Validation Accuracy: 0.528400\n",
      "Epoch  1, MNIST Batch 25: Loss:     2.2236 Validation Accuracy: 0.541800\n",
      "Epoch  1, MNIST Batch 26: Loss:     2.2220 Validation Accuracy: 0.552400\n",
      "Epoch  1, MNIST Batch 27: Loss:     2.2224 Validation Accuracy: 0.558400\n",
      "Epoch  1, MNIST Batch 28: Loss:     2.2144 Validation Accuracy: 0.568800\n",
      "Epoch  1, MNIST Batch 29: Loss:     2.2122 Validation Accuracy: 0.577000\n",
      "Epoch  1, MNIST Batch 30: Loss:     2.2136 Validation Accuracy: 0.586200\n",
      "Epoch  1, MNIST Batch 31: Loss:     2.2020 Validation Accuracy: 0.592800\n",
      "Epoch  1, MNIST Batch 32: Loss:     2.2037 Validation Accuracy: 0.600800\n",
      "Epoch  1, MNIST Batch 33: Loss:     2.2037 Validation Accuracy: 0.605800\n",
      "Epoch  1, MNIST Batch 34: Loss:     2.2010 Validation Accuracy: 0.612000\n",
      "Epoch  1, MNIST Batch 35: Loss:     2.1949 Validation Accuracy: 0.616200\n",
      "Epoch  1, MNIST Batch 36: Loss:     2.1926 Validation Accuracy: 0.619400\n",
      "Epoch  1, MNIST Batch 37: Loss:     2.1892 Validation Accuracy: 0.623600\n",
      "Epoch  1, MNIST Batch 38: Loss:     2.1816 Validation Accuracy: 0.628600\n",
      "Epoch  1, MNIST Batch 39: Loss:     2.1827 Validation Accuracy: 0.631800\n",
      "Epoch  1, MNIST Batch 40: Loss:     2.1684 Validation Accuracy: 0.634200\n",
      "Epoch  1, MNIST Batch 41: Loss:     2.1765 Validation Accuracy: 0.637200\n",
      "Epoch  1, MNIST Batch 42: Loss:     2.1746 Validation Accuracy: 0.641000\n",
      "Epoch  1, MNIST Batch 43: Loss:     2.1656 Validation Accuracy: 0.642000\n",
      "Epoch  1, MNIST Batch 44: Loss:     2.1638 Validation Accuracy: 0.643600\n",
      "Epoch  1, MNIST Batch 45: Loss:     2.1604 Validation Accuracy: 0.643600\n",
      "Epoch  1, MNIST Batch 46: Loss:     2.1552 Validation Accuracy: 0.643400\n",
      "Epoch  1, MNIST Batch 47: Loss:     2.1497 Validation Accuracy: 0.647800\n",
      "Epoch  1, MNIST Batch 48: Loss:     2.1585 Validation Accuracy: 0.651000\n",
      "Epoch  1, MNIST Batch 49: Loss:     2.1489 Validation Accuracy: 0.653800\n",
      "Epoch  1, MNIST Batch 50: Loss:     2.1443 Validation Accuracy: 0.657000\n",
      "Epoch  1, MNIST Batch 51: Loss:     2.1408 Validation Accuracy: 0.661600\n",
      "Epoch  1, MNIST Batch 52: Loss:     2.1315 Validation Accuracy: 0.665200\n",
      "Epoch  1, MNIST Batch 53: Loss:     2.1279 Validation Accuracy: 0.667000\n",
      "Epoch  1, MNIST Batch 54: Loss:     2.1368 Validation Accuracy: 0.670600\n",
      "Epoch  1, MNIST Batch 55: Loss:     2.1248 Validation Accuracy: 0.673600\n",
      "Epoch  1, MNIST Batch 56: Loss:     2.1282 Validation Accuracy: 0.676800\n",
      "Epoch  1, MNIST Batch 57: Loss:     2.1124 Validation Accuracy: 0.678600\n",
      "Epoch  1, MNIST Batch 58: Loss:     2.1182 Validation Accuracy: 0.680000\n",
      "Epoch  1, MNIST Batch 59: Loss:     2.1150 Validation Accuracy: 0.682200\n",
      "Epoch  1, MNIST Batch 60: Loss:     2.1065 Validation Accuracy: 0.684600\n",
      "Epoch  1, MNIST Batch 61: Loss:     2.0894 Validation Accuracy: 0.689400\n",
      "Epoch  1, MNIST Batch 62: Loss:     2.0876 Validation Accuracy: 0.692200\n",
      "Epoch  1, MNIST Batch 63: Loss:     2.0969 Validation Accuracy: 0.696000\n",
      "Epoch  1, MNIST Batch 64: Loss:     2.0843 Validation Accuracy: 0.699600\n",
      "Epoch  1, MNIST Batch 65: Loss:     2.0832 Validation Accuracy: 0.703600\n",
      "Epoch  1, MNIST Batch 66: Loss:     2.0801 Validation Accuracy: 0.707400\n",
      "Epoch  1, MNIST Batch 67: Loss:     2.0742 Validation Accuracy: 0.713000\n",
      "Epoch  1, MNIST Batch 68: Loss:     2.0608 Validation Accuracy: 0.716400\n",
      "Epoch  1, MNIST Batch 69: Loss:     2.0771 Validation Accuracy: 0.720200\n",
      "Epoch  1, MNIST Batch 70: Loss:     2.0542 Validation Accuracy: 0.722000\n",
      "Epoch  1, MNIST Batch 71: Loss:     2.0592 Validation Accuracy: 0.725600\n",
      "Epoch  1, MNIST Batch 72: Loss:     2.0464 Validation Accuracy: 0.727600\n",
      "Epoch  1, MNIST Batch 73: Loss:     2.0493 Validation Accuracy: 0.730800\n",
      "Epoch  1, MNIST Batch 74: Loss:     2.0456 Validation Accuracy: 0.734600\n",
      "Epoch  1, MNIST Batch 75: Loss:     2.0398 Validation Accuracy: 0.735800\n",
      "Epoch  1, MNIST Batch 76: Loss:     2.0337 Validation Accuracy: 0.737400\n",
      "Epoch  1, MNIST Batch 77: Loss:     2.0251 Validation Accuracy: 0.738000\n",
      "Epoch  1, MNIST Batch 78: Loss:     2.0039 Validation Accuracy: 0.740400\n",
      "Epoch  1, MNIST Batch 79: Loss:     2.0185 Validation Accuracy: 0.742400\n",
      "Epoch  1, MNIST Batch 80: Loss:     1.9947 Validation Accuracy: 0.743200\n",
      "Epoch  1, MNIST Batch 81: Loss:     2.0178 Validation Accuracy: 0.744600\n",
      "Epoch  1, MNIST Batch 82: Loss:     2.0026 Validation Accuracy: 0.746000\n",
      "Epoch  1, MNIST Batch 83: Loss:     1.9957 Validation Accuracy: 0.747400\n",
      "Epoch  1, MNIST Batch 84: Loss:     1.9979 Validation Accuracy: 0.749800\n",
      "Epoch  1, MNIST Batch 85: Loss:     1.9905 Validation Accuracy: 0.752400\n",
      "Epoch  1, MNIST Batch 86: Loss:     1.9776 Validation Accuracy: 0.755800\n",
      "Epoch  1, MNIST Batch 87: Loss:     1.9756 Validation Accuracy: 0.758000\n",
      "Epoch  1, MNIST Batch 88: Loss:     1.9555 Validation Accuracy: 0.758400\n",
      "Epoch  1, MNIST Batch 89: Loss:     1.9628 Validation Accuracy: 0.759800\n",
      "Epoch  1, MNIST Batch 90: Loss:     1.9636 Validation Accuracy: 0.761800\n",
      "Epoch  1, MNIST Batch 91: Loss:     1.9525 Validation Accuracy: 0.763800\n",
      "Epoch  1, MNIST Batch 92: Loss:     1.9702 Validation Accuracy: 0.767200\n",
      "Epoch  1, MNIST Batch 93: Loss:     1.9255 Validation Accuracy: 0.768200\n",
      "Epoch  1, MNIST Batch 94: Loss:     1.9203 Validation Accuracy: 0.770400\n",
      "Epoch  1, MNIST Batch 95: Loss:     1.9366 Validation Accuracy: 0.771600\n",
      "Epoch  1, MNIST Batch 96: Loss:     1.9388 Validation Accuracy: 0.773600\n",
      "Epoch  1, MNIST Batch 97: Loss:     1.9144 Validation Accuracy: 0.773200\n",
      "Epoch  1, MNIST Batch 98: Loss:     1.9142 Validation Accuracy: 0.774400\n",
      "Epoch  1, MNIST Batch 99: Loss:     1.9084 Validation Accuracy: 0.776200\n",
      "Epoch  1, MNIST Batch 100: Loss:     1.8942 Validation Accuracy: 0.777000\n",
      "Epoch  1, MNIST Batch 101: Loss:     1.8921 Validation Accuracy: 0.778400\n",
      "Epoch  1, MNIST Batch 102: Loss:     1.8973 Validation Accuracy: 0.780600\n",
      "Epoch  1, MNIST Batch 103: Loss:     1.8958 Validation Accuracy: 0.781600\n",
      "Epoch  1, MNIST Batch 104: Loss:     1.8690 Validation Accuracy: 0.781400\n",
      "Epoch  1, MNIST Batch 105: Loss:     1.8659 Validation Accuracy: 0.781800\n",
      "Epoch  1, MNIST Batch 106: Loss:     1.8587 Validation Accuracy: 0.781400\n",
      "Epoch  2, MNIST Batch 0: Loss:     1.8607 Validation Accuracy: 0.781400\n",
      "Epoch  2, MNIST Batch 1: Loss:     1.8542 Validation Accuracy: 0.781800\n",
      "Epoch  2, MNIST Batch 2: Loss:     1.8376 Validation Accuracy: 0.779800\n",
      "Epoch  2, MNIST Batch 3: Loss:     1.8658 Validation Accuracy: 0.779200\n",
      "Epoch  2, MNIST Batch 4: Loss:     1.8364 Validation Accuracy: 0.779600\n",
      "Epoch  2, MNIST Batch 5: Loss:     1.8240 Validation Accuracy: 0.780600\n",
      "Epoch  2, MNIST Batch 6: Loss:     1.8278 Validation Accuracy: 0.782200\n",
      "Epoch  2, MNIST Batch 7: Loss:     1.8212 Validation Accuracy: 0.782800\n",
      "Epoch  2, MNIST Batch 8: Loss:     1.8129 Validation Accuracy: 0.782200\n",
      "Epoch  2, MNIST Batch 9: Loss:     1.7917 Validation Accuracy: 0.783400\n",
      "Epoch  2, MNIST Batch 10: Loss:     1.8065 Validation Accuracy: 0.784800\n",
      "Epoch  2, MNIST Batch 11: Loss:     1.7900 Validation Accuracy: 0.784600\n",
      "Epoch  2, MNIST Batch 12: Loss:     1.7830 Validation Accuracy: 0.783200\n",
      "Epoch  2, MNIST Batch 13: Loss:     1.7940 Validation Accuracy: 0.783400\n",
      "Epoch  2, MNIST Batch 14: Loss:     1.7666 Validation Accuracy: 0.782400\n",
      "Epoch  2, MNIST Batch 15: Loss:     1.7712 Validation Accuracy: 0.779400\n",
      "Epoch  2, MNIST Batch 16: Loss:     1.7477 Validation Accuracy: 0.779800\n",
      "Epoch  2, MNIST Batch 17: Loss:     1.7534 Validation Accuracy: 0.780200\n",
      "Epoch  2, MNIST Batch 18: Loss:     1.7594 Validation Accuracy: 0.780800\n",
      "Epoch  2, MNIST Batch 19: Loss:     1.7283 Validation Accuracy: 0.783400\n",
      "Epoch  2, MNIST Batch 20: Loss:     1.7219 Validation Accuracy: 0.784200\n",
      "Epoch  2, MNIST Batch 21: Loss:     1.7302 Validation Accuracy: 0.786400\n",
      "Epoch  2, MNIST Batch 22: Loss:     1.7191 Validation Accuracy: 0.786600\n",
      "Epoch  2, MNIST Batch 23: Loss:     1.6885 Validation Accuracy: 0.788200\n",
      "Epoch  2, MNIST Batch 24: Loss:     1.7222 Validation Accuracy: 0.789000\n",
      "Epoch  2, MNIST Batch 25: Loss:     1.6804 Validation Accuracy: 0.789600\n",
      "Epoch  2, MNIST Batch 26: Loss:     1.6941 Validation Accuracy: 0.792400\n",
      "Epoch  2, MNIST Batch 27: Loss:     1.6744 Validation Accuracy: 0.795600\n",
      "Epoch  2, MNIST Batch 28: Loss:     1.6532 Validation Accuracy: 0.796200\n",
      "Epoch  2, MNIST Batch 29: Loss:     1.6754 Validation Accuracy: 0.797800\n",
      "Epoch  2, MNIST Batch 30: Loss:     1.6581 Validation Accuracy: 0.796200\n",
      "Epoch  2, MNIST Batch 31: Loss:     1.6702 Validation Accuracy: 0.795000\n",
      "Epoch  2, MNIST Batch 32: Loss:     1.6406 Validation Accuracy: 0.794200\n",
      "Epoch  2, MNIST Batch 33: Loss:     1.6257 Validation Accuracy: 0.791200\n",
      "Epoch  2, MNIST Batch 34: Loss:     1.6255 Validation Accuracy: 0.790200\n",
      "Epoch  2, MNIST Batch 35: Loss:     1.6376 Validation Accuracy: 0.788800\n",
      "Epoch  2, MNIST Batch 36: Loss:     1.6171 Validation Accuracy: 0.788200\n",
      "Epoch  2, MNIST Batch 37: Loss:     1.6071 Validation Accuracy: 0.788200\n",
      "Epoch  2, MNIST Batch 38: Loss:     1.6110 Validation Accuracy: 0.786200\n",
      "Epoch  2, MNIST Batch 39: Loss:     1.5842 Validation Accuracy: 0.785600\n",
      "Epoch  2, MNIST Batch 40: Loss:     1.5924 Validation Accuracy: 0.787200\n",
      "Epoch  2, MNIST Batch 41: Loss:     1.5497 Validation Accuracy: 0.787800\n",
      "Epoch  2, MNIST Batch 42: Loss:     1.5655 Validation Accuracy: 0.787400\n",
      "Epoch  2, MNIST Batch 43: Loss:     1.5606 Validation Accuracy: 0.788600\n",
      "Epoch  2, MNIST Batch 44: Loss:     1.5599 Validation Accuracy: 0.790200\n",
      "Epoch  2, MNIST Batch 45: Loss:     1.5589 Validation Accuracy: 0.791200\n",
      "Epoch  2, MNIST Batch 46: Loss:     1.5491 Validation Accuracy: 0.792400\n",
      "Epoch  2, MNIST Batch 47: Loss:     1.5675 Validation Accuracy: 0.794400\n",
      "Epoch  2, MNIST Batch 48: Loss:     1.4949 Validation Accuracy: 0.796400\n",
      "Epoch  2, MNIST Batch 49: Loss:     1.5132 Validation Accuracy: 0.797800\n",
      "Epoch  2, MNIST Batch 50: Loss:     1.5076 Validation Accuracy: 0.798600\n",
      "Epoch  2, MNIST Batch 51: Loss:     1.5023 Validation Accuracy: 0.799600\n",
      "Epoch  2, MNIST Batch 52: Loss:     1.5049 Validation Accuracy: 0.802400\n",
      "Epoch  2, MNIST Batch 53: Loss:     1.4465 Validation Accuracy: 0.803000\n",
      "Epoch  2, MNIST Batch 54: Loss:     1.4991 Validation Accuracy: 0.803000\n",
      "Epoch  2, MNIST Batch 55: Loss:     1.5096 Validation Accuracy: 0.803800\n",
      "Epoch  2, MNIST Batch 56: Loss:     1.4529 Validation Accuracy: 0.804600\n",
      "Epoch  2, MNIST Batch 57: Loss:     1.4530 Validation Accuracy: 0.805400\n",
      "Epoch  2, MNIST Batch 58: Loss:     1.4535 Validation Accuracy: 0.806000\n",
      "Epoch  2, MNIST Batch 59: Loss:     1.4541 Validation Accuracy: 0.807200\n",
      "Epoch  2, MNIST Batch 60: Loss:     1.4486 Validation Accuracy: 0.806600\n",
      "Epoch  2, MNIST Batch 61: Loss:     1.4202 Validation Accuracy: 0.807000\n",
      "Epoch  2, MNIST Batch 62: Loss:     1.4456 Validation Accuracy: 0.806200\n",
      "Epoch  2, MNIST Batch 63: Loss:     1.4210 Validation Accuracy: 0.806600\n",
      "Epoch  2, MNIST Batch 64: Loss:     1.4011 Validation Accuracy: 0.805800\n",
      "Epoch  2, MNIST Batch 65: Loss:     1.3898 Validation Accuracy: 0.807200\n",
      "Epoch  2, MNIST Batch 66: Loss:     1.4323 Validation Accuracy: 0.806800\n",
      "Epoch  2, MNIST Batch 67: Loss:     1.3592 Validation Accuracy: 0.808600\n",
      "Epoch  2, MNIST Batch 68: Loss:     1.4075 Validation Accuracy: 0.809400\n",
      "Epoch  2, MNIST Batch 69: Loss:     1.3918 Validation Accuracy: 0.809800\n",
      "Epoch  2, MNIST Batch 70: Loss:     1.3672 Validation Accuracy: 0.809800\n",
      "Epoch  2, MNIST Batch 71: Loss:     1.3780 Validation Accuracy: 0.811800\n",
      "Epoch  2, MNIST Batch 72: Loss:     1.3620 Validation Accuracy: 0.811800\n",
      "Epoch  2, MNIST Batch 73: Loss:     1.3814 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 74: Loss:     1.3345 Validation Accuracy: 0.813400\n",
      "Epoch  2, MNIST Batch 75: Loss:     1.3683 Validation Accuracy: 0.814200\n",
      "Epoch  2, MNIST Batch 76: Loss:     1.3226 Validation Accuracy: 0.817400\n",
      "Epoch  2, MNIST Batch 77: Loss:     1.3466 Validation Accuracy: 0.817800\n",
      "Epoch  2, MNIST Batch 78: Loss:     1.3226 Validation Accuracy: 0.819600\n",
      "Epoch  2, MNIST Batch 79: Loss:     1.3100 Validation Accuracy: 0.819000\n",
      "Epoch  2, MNIST Batch 80: Loss:     1.2854 Validation Accuracy: 0.820200\n",
      "Epoch  2, MNIST Batch 81: Loss:     1.2881 Validation Accuracy: 0.819800\n",
      "Epoch  2, MNIST Batch 82: Loss:     1.3236 Validation Accuracy: 0.820800\n",
      "Epoch  2, MNIST Batch 83: Loss:     1.2906 Validation Accuracy: 0.821000\n",
      "Epoch  2, MNIST Batch 84: Loss:     1.2898 Validation Accuracy: 0.820600\n",
      "Epoch  2, MNIST Batch 85: Loss:     1.2681 Validation Accuracy: 0.819600\n",
      "Epoch  2, MNIST Batch 86: Loss:     1.2680 Validation Accuracy: 0.819200\n",
      "Epoch  2, MNIST Batch 87: Loss:     1.2700 Validation Accuracy: 0.817400\n",
      "Epoch  2, MNIST Batch 88: Loss:     1.2336 Validation Accuracy: 0.816400\n",
      "Epoch  2, MNIST Batch 89: Loss:     1.2699 Validation Accuracy: 0.814800\n",
      "Epoch  2, MNIST Batch 90: Loss:     1.2385 Validation Accuracy: 0.814600\n",
      "Epoch  2, MNIST Batch 91: Loss:     1.2582 Validation Accuracy: 0.814800\n",
      "Epoch  2, MNIST Batch 92: Loss:     1.2412 Validation Accuracy: 0.814400\n",
      "Epoch  2, MNIST Batch 93: Loss:     1.2307 Validation Accuracy: 0.814400\n",
      "Epoch  2, MNIST Batch 94: Loss:     1.1888 Validation Accuracy: 0.814400\n",
      "Epoch  2, MNIST Batch 95: Loss:     1.2168 Validation Accuracy: 0.814000\n",
      "Epoch  2, MNIST Batch 96: Loss:     1.2108 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 97: Loss:     1.2165 Validation Accuracy: 0.813600\n",
      "Epoch  2, MNIST Batch 98: Loss:     1.2439 Validation Accuracy: 0.813000\n",
      "Epoch  2, MNIST Batch 99: Loss:     1.1560 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 100: Loss:     1.2156 Validation Accuracy: 0.815400\n",
      "Epoch  2, MNIST Batch 101: Loss:     1.1427 Validation Accuracy: 0.816800\n",
      "Epoch  2, MNIST Batch 102: Loss:     1.1703 Validation Accuracy: 0.817200\n",
      "Epoch  2, MNIST Batch 103: Loss:     1.1934 Validation Accuracy: 0.816800\n",
      "Epoch  2, MNIST Batch 104: Loss:     1.1509 Validation Accuracy: 0.818200\n",
      "Epoch  2, MNIST Batch 105: Loss:     1.1820 Validation Accuracy: 0.820200\n",
      "Epoch  2, MNIST Batch 106: Loss:     1.1137 Validation Accuracy: 0.820200\n",
      "Epoch  3, MNIST Batch 0: Loss:     1.1021 Validation Accuracy: 0.818800\n",
      "Epoch  3, MNIST Batch 1: Loss:     1.1218 Validation Accuracy: 0.819000\n",
      "Epoch  3, MNIST Batch 2: Loss:     1.1136 Validation Accuracy: 0.819600\n",
      "Epoch  3, MNIST Batch 3: Loss:     1.1221 Validation Accuracy: 0.818200\n",
      "Epoch  3, MNIST Batch 4: Loss:     1.1319 Validation Accuracy: 0.817200\n",
      "Epoch  3, MNIST Batch 5: Loss:     1.1678 Validation Accuracy: 0.817400\n",
      "Epoch  3, MNIST Batch 6: Loss:     1.0710 Validation Accuracy: 0.817400\n",
      "Epoch  3, MNIST Batch 7: Loss:     1.1069 Validation Accuracy: 0.817200\n",
      "Epoch  3, MNIST Batch 8: Loss:     1.0629 Validation Accuracy: 0.819000\n",
      "Epoch  3, MNIST Batch 9: Loss:     1.0887 Validation Accuracy: 0.818600\n",
      "Epoch  3, MNIST Batch 10: Loss:     1.0812 Validation Accuracy: 0.820200\n",
      "Epoch  3, MNIST Batch 11: Loss:     1.0618 Validation Accuracy: 0.820400\n",
      "Epoch  3, MNIST Batch 12: Loss:     1.0782 Validation Accuracy: 0.820800\n",
      "Epoch  3, MNIST Batch 13: Loss:     1.0902 Validation Accuracy: 0.821600\n",
      "Epoch  3, MNIST Batch 14: Loss:     1.0398 Validation Accuracy: 0.822800\n",
      "Epoch  3, MNIST Batch 15: Loss:     1.0610 Validation Accuracy: 0.824200\n",
      "Epoch  3, MNIST Batch 16: Loss:     1.0601 Validation Accuracy: 0.824400\n",
      "Epoch  3, MNIST Batch 17: Loss:     1.0520 Validation Accuracy: 0.824400\n",
      "Epoch  3, MNIST Batch 18: Loss:     1.0510 Validation Accuracy: 0.825400\n",
      "Epoch  3, MNIST Batch 19: Loss:     1.0455 Validation Accuracy: 0.826400\n",
      "Epoch  3, MNIST Batch 20: Loss:     1.0405 Validation Accuracy: 0.827200\n",
      "Epoch  3, MNIST Batch 21: Loss:     1.0238 Validation Accuracy: 0.827600\n",
      "Epoch  3, MNIST Batch 22: Loss:     1.0150 Validation Accuracy: 0.829000\n",
      "Epoch  3, MNIST Batch 23: Loss:     1.0243 Validation Accuracy: 0.830000\n",
      "Epoch  3, MNIST Batch 24: Loss:     1.0142 Validation Accuracy: 0.831600\n",
      "Epoch  3, MNIST Batch 25: Loss:     1.0179 Validation Accuracy: 0.832000\n",
      "Epoch  3, MNIST Batch 26: Loss:     1.0062 Validation Accuracy: 0.833000\n",
      "Epoch  3, MNIST Batch 27: Loss:     1.0382 Validation Accuracy: 0.832000\n",
      "Epoch  3, MNIST Batch 28: Loss:     0.9966 Validation Accuracy: 0.832400\n",
      "Epoch  3, MNIST Batch 29: Loss:     0.9880 Validation Accuracy: 0.832000\n",
      "Epoch  3, MNIST Batch 30: Loss:     1.0175 Validation Accuracy: 0.831600\n",
      "Epoch  3, MNIST Batch 31: Loss:     0.9636 Validation Accuracy: 0.831600\n",
      "Epoch  3, MNIST Batch 32: Loss:     1.0061 Validation Accuracy: 0.832200\n",
      "Epoch  3, MNIST Batch 33: Loss:     0.9132 Validation Accuracy: 0.833200\n",
      "Epoch  3, MNIST Batch 34: Loss:     0.9806 Validation Accuracy: 0.832800\n",
      "Epoch  3, MNIST Batch 35: Loss:     0.9949 Validation Accuracy: 0.833600\n",
      "Epoch  3, MNIST Batch 36: Loss:     0.8996 Validation Accuracy: 0.833400\n",
      "Epoch  3, MNIST Batch 37: Loss:     0.9191 Validation Accuracy: 0.833400\n",
      "Epoch  3, MNIST Batch 38: Loss:     0.9564 Validation Accuracy: 0.834800\n",
      "Epoch  3, MNIST Batch 39: Loss:     0.9498 Validation Accuracy: 0.835000\n",
      "Epoch  3, MNIST Batch 40: Loss:     0.9218 Validation Accuracy: 0.836200\n",
      "Epoch  3, MNIST Batch 41: Loss:     0.9215 Validation Accuracy: 0.836200\n",
      "Epoch  3, MNIST Batch 42: Loss:     0.9239 Validation Accuracy: 0.835800\n",
      "Epoch  3, MNIST Batch 43: Loss:     0.9678 Validation Accuracy: 0.835800\n",
      "Epoch  3, MNIST Batch 44: Loss:     0.8914 Validation Accuracy: 0.835200\n",
      "Epoch  3, MNIST Batch 45: Loss:     0.9218 Validation Accuracy: 0.834800\n",
      "Epoch  3, MNIST Batch 46: Loss:     0.9069 Validation Accuracy: 0.835400\n",
      "Epoch  3, MNIST Batch 47: Loss:     0.9040 Validation Accuracy: 0.835600\n",
      "Epoch  3, MNIST Batch 48: Loss:     0.9124 Validation Accuracy: 0.835600\n",
      "Epoch  3, MNIST Batch 49: Loss:     0.8614 Validation Accuracy: 0.835200\n",
      "Epoch  3, MNIST Batch 50: Loss:     0.9235 Validation Accuracy: 0.835800\n",
      "Epoch  3, MNIST Batch 51: Loss:     0.8640 Validation Accuracy: 0.835600\n",
      "Epoch  3, MNIST Batch 52: Loss:     0.9032 Validation Accuracy: 0.835400\n",
      "Epoch  3, MNIST Batch 53: Loss:     0.8844 Validation Accuracy: 0.835000\n",
      "Epoch  3, MNIST Batch 54: Loss:     0.9058 Validation Accuracy: 0.835200\n",
      "Epoch  3, MNIST Batch 55: Loss:     0.8389 Validation Accuracy: 0.834400\n",
      "Epoch  3, MNIST Batch 56: Loss:     0.8812 Validation Accuracy: 0.834800\n",
      "Epoch  3, MNIST Batch 57: Loss:     0.8830 Validation Accuracy: 0.835000\n",
      "Epoch  3, MNIST Batch 58: Loss:     0.8728 Validation Accuracy: 0.835800\n",
      "Epoch  3, MNIST Batch 59: Loss:     0.8861 Validation Accuracy: 0.837600\n",
      "Epoch  3, MNIST Batch 60: Loss:     0.8212 Validation Accuracy: 0.839000\n",
      "Epoch  3, MNIST Batch 61: Loss:     0.8489 Validation Accuracy: 0.839200\n",
      "Epoch  3, MNIST Batch 62: Loss:     0.8434 Validation Accuracy: 0.841000\n",
      "Epoch  3, MNIST Batch 63: Loss:     0.8387 Validation Accuracy: 0.841600\n",
      "Epoch  3, MNIST Batch 64: Loss:     0.8057 Validation Accuracy: 0.842200\n",
      "Epoch  3, MNIST Batch 65: Loss:     0.8426 Validation Accuracy: 0.842000\n",
      "Epoch  3, MNIST Batch 66: Loss:     0.8399 Validation Accuracy: 0.841400\n",
      "Epoch  3, MNIST Batch 67: Loss:     0.7945 Validation Accuracy: 0.841800\n",
      "Epoch  3, MNIST Batch 68: Loss:     0.8333 Validation Accuracy: 0.842200\n",
      "Epoch  3, MNIST Batch 69: Loss:     0.8058 Validation Accuracy: 0.841800\n",
      "Epoch  3, MNIST Batch 70: Loss:     0.8044 Validation Accuracy: 0.842800\n",
      "Epoch  3, MNIST Batch 71: Loss:     0.8327 Validation Accuracy: 0.844600\n",
      "Epoch  3, MNIST Batch 72: Loss:     0.8086 Validation Accuracy: 0.845200\n",
      "Epoch  3, MNIST Batch 73: Loss:     0.8561 Validation Accuracy: 0.845800\n",
      "Epoch  3, MNIST Batch 74: Loss:     0.8078 Validation Accuracy: 0.847200\n",
      "Epoch  3, MNIST Batch 75: Loss:     0.8124 Validation Accuracy: 0.847600\n",
      "Epoch  3, MNIST Batch 76: Loss:     0.7990 Validation Accuracy: 0.848800\n",
      "Epoch  3, MNIST Batch 77: Loss:     0.7656 Validation Accuracy: 0.849600\n",
      "Epoch  3, MNIST Batch 78: Loss:     0.7753 Validation Accuracy: 0.849400\n",
      "Epoch  3, MNIST Batch 79: Loss:     0.7273 Validation Accuracy: 0.849400\n",
      "Epoch  3, MNIST Batch 80: Loss:     0.7764 Validation Accuracy: 0.850400\n",
      "Epoch  3, MNIST Batch 81: Loss:     0.7988 Validation Accuracy: 0.850600\n",
      "Epoch  3, MNIST Batch 82: Loss:     0.7627 Validation Accuracy: 0.850400\n",
      "Epoch  3, MNIST Batch 83: Loss:     0.7861 Validation Accuracy: 0.851000\n",
      "Epoch  3, MNIST Batch 84: Loss:     0.7521 Validation Accuracy: 0.850600\n",
      "Epoch  3, MNIST Batch 85: Loss:     0.7724 Validation Accuracy: 0.851000\n",
      "Epoch  3, MNIST Batch 86: Loss:     0.7359 Validation Accuracy: 0.850800\n",
      "Epoch  3, MNIST Batch 87: Loss:     0.7590 Validation Accuracy: 0.851000\n",
      "Epoch  3, MNIST Batch 88: Loss:     0.7773 Validation Accuracy: 0.851800\n",
      "Epoch  3, MNIST Batch 89: Loss:     0.7705 Validation Accuracy: 0.851000\n",
      "Epoch  3, MNIST Batch 90: Loss:     0.7959 Validation Accuracy: 0.851200\n",
      "Epoch  3, MNIST Batch 91: Loss:     0.7546 Validation Accuracy: 0.851400\n",
      "Epoch  3, MNIST Batch 92: Loss:     0.7576 Validation Accuracy: 0.852000\n",
      "Epoch  3, MNIST Batch 93: Loss:     0.7793 Validation Accuracy: 0.853000\n",
      "Epoch  3, MNIST Batch 94: Loss:     0.7469 Validation Accuracy: 0.854400\n",
      "Epoch  3, MNIST Batch 95: Loss:     0.7508 Validation Accuracy: 0.855400\n",
      "Epoch  3, MNIST Batch 96: Loss:     0.7207 Validation Accuracy: 0.855800\n",
      "Epoch  3, MNIST Batch 97: Loss:     0.6998 Validation Accuracy: 0.856800\n",
      "Epoch  3, MNIST Batch 98: Loss:     0.7618 Validation Accuracy: 0.856400\n",
      "Epoch  3, MNIST Batch 99: Loss:     0.7741 Validation Accuracy: 0.856200\n",
      "Epoch  3, MNIST Batch 100: Loss:     0.7511 Validation Accuracy: 0.856400\n",
      "Epoch  3, MNIST Batch 101: Loss:     0.6905 Validation Accuracy: 0.856600\n",
      "Epoch  3, MNIST Batch 102: Loss:     0.7109 Validation Accuracy: 0.857200\n",
      "Epoch  3, MNIST Batch 103: Loss:     0.6848 Validation Accuracy: 0.857800\n",
      "Epoch  3, MNIST Batch 104: Loss:     0.6993 Validation Accuracy: 0.857800\n",
      "Epoch  3, MNIST Batch 105: Loss:     0.7362 Validation Accuracy: 0.857400\n",
      "Epoch  3, MNIST Batch 106: Loss:     0.6843 Validation Accuracy: 0.858800\n",
      "Epoch  4, MNIST Batch 0: Loss:     0.7369 Validation Accuracy: 0.858400\n",
      "Epoch  4, MNIST Batch 1: Loss:     0.7278 Validation Accuracy: 0.857600\n",
      "Epoch  4, MNIST Batch 2: Loss:     0.7243 Validation Accuracy: 0.858000\n",
      "Epoch  4, MNIST Batch 3: Loss:     0.6918 Validation Accuracy: 0.856600\n",
      "Epoch  4, MNIST Batch 4: Loss:     0.7042 Validation Accuracy: 0.856400\n",
      "Epoch  4, MNIST Batch 5: Loss:     0.6736 Validation Accuracy: 0.855000\n",
      "Epoch  4, MNIST Batch 6: Loss:     0.6888 Validation Accuracy: 0.854800\n",
      "Epoch  4, MNIST Batch 7: Loss:     0.7112 Validation Accuracy: 0.855000\n",
      "Epoch  4, MNIST Batch 8: Loss:     0.6440 Validation Accuracy: 0.855000\n",
      "Epoch  4, MNIST Batch 9: Loss:     0.6640 Validation Accuracy: 0.854600\n",
      "Epoch  4, MNIST Batch 10: Loss:     0.6566 Validation Accuracy: 0.854800\n",
      "Epoch  4, MNIST Batch 11: Loss:     0.6685 Validation Accuracy: 0.855600\n",
      "Epoch  4, MNIST Batch 12: Loss:     0.6799 Validation Accuracy: 0.854600\n",
      "Epoch  4, MNIST Batch 13: Loss:     0.6897 Validation Accuracy: 0.855400\n",
      "Epoch  4, MNIST Batch 14: Loss:     0.6885 Validation Accuracy: 0.856400\n",
      "Epoch  4, MNIST Batch 15: Loss:     0.6804 Validation Accuracy: 0.858000\n",
      "Epoch  4, MNIST Batch 16: Loss:     0.6493 Validation Accuracy: 0.859000\n",
      "Epoch  4, MNIST Batch 17: Loss:     0.6508 Validation Accuracy: 0.859200\n",
      "Epoch  4, MNIST Batch 18: Loss:     0.6322 Validation Accuracy: 0.860200\n",
      "Epoch  4, MNIST Batch 19: Loss:     0.6411 Validation Accuracy: 0.860400\n",
      "Epoch  4, MNIST Batch 20: Loss:     0.6422 Validation Accuracy: 0.860400\n",
      "Epoch  4, MNIST Batch 21: Loss:     0.6518 Validation Accuracy: 0.861000\n",
      "Epoch  4, MNIST Batch 22: Loss:     0.6140 Validation Accuracy: 0.861200\n",
      "Epoch  4, MNIST Batch 23: Loss:     0.6661 Validation Accuracy: 0.861800\n",
      "Epoch  4, MNIST Batch 24: Loss:     0.6202 Validation Accuracy: 0.862400\n",
      "Epoch  4, MNIST Batch 25: Loss:     0.6435 Validation Accuracy: 0.862600\n",
      "Epoch  4, MNIST Batch 26: Loss:     0.6571 Validation Accuracy: 0.862600\n",
      "Epoch  4, MNIST Batch 27: Loss:     0.6783 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 28: Loss:     0.6359 Validation Accuracy: 0.863400\n",
      "Epoch  4, MNIST Batch 29: Loss:     0.6339 Validation Accuracy: 0.863600\n",
      "Epoch  4, MNIST Batch 30: Loss:     0.6422 Validation Accuracy: 0.863800\n",
      "Epoch  4, MNIST Batch 31: Loss:     0.6671 Validation Accuracy: 0.864200\n",
      "Epoch  4, MNIST Batch 32: Loss:     0.6823 Validation Accuracy: 0.864600\n",
      "Epoch  4, MNIST Batch 33: Loss:     0.6607 Validation Accuracy: 0.864400\n",
      "Epoch  4, MNIST Batch 34: Loss:     0.6074 Validation Accuracy: 0.864200\n",
      "Epoch  4, MNIST Batch 35: Loss:     0.6081 Validation Accuracy: 0.864200\n",
      "Epoch  4, MNIST Batch 36: Loss:     0.6075 Validation Accuracy: 0.864000\n",
      "Epoch  4, MNIST Batch 37: Loss:     0.5974 Validation Accuracy: 0.863400\n",
      "Epoch  4, MNIST Batch 38: Loss:     0.6425 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 39: Loss:     0.6608 Validation Accuracy: 0.863200\n",
      "Epoch  4, MNIST Batch 40: Loss:     0.6383 Validation Accuracy: 0.863200\n",
      "Epoch  4, MNIST Batch 41: Loss:     0.6261 Validation Accuracy: 0.863000\n",
      "Epoch  4, MNIST Batch 42: Loss:     0.6148 Validation Accuracy: 0.863600\n",
      "Epoch  4, MNIST Batch 43: Loss:     0.6155 Validation Accuracy: 0.864200\n",
      "Epoch  4, MNIST Batch 44: Loss:     0.6069 Validation Accuracy: 0.865200\n",
      "Epoch  4, MNIST Batch 45: Loss:     0.5912 Validation Accuracy: 0.865600\n",
      "Epoch  4, MNIST Batch 46: Loss:     0.5699 Validation Accuracy: 0.866400\n",
      "Epoch  4, MNIST Batch 47: Loss:     0.5884 Validation Accuracy: 0.866400\n",
      "Epoch  4, MNIST Batch 48: Loss:     0.6041 Validation Accuracy: 0.867400\n",
      "Epoch  4, MNIST Batch 49: Loss:     0.5985 Validation Accuracy: 0.867800\n",
      "Epoch  4, MNIST Batch 50: Loss:     0.6411 Validation Accuracy: 0.868400\n",
      "Epoch  4, MNIST Batch 51: Loss:     0.5942 Validation Accuracy: 0.868600\n",
      "Epoch  4, MNIST Batch 52: Loss:     0.6014 Validation Accuracy: 0.868800\n",
      "Epoch  4, MNIST Batch 53: Loss:     0.5942 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 54: Loss:     0.6091 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 55: Loss:     0.6010 Validation Accuracy: 0.869000\n",
      "Epoch  4, MNIST Batch 56: Loss:     0.5906 Validation Accuracy: 0.869200\n",
      "Epoch  4, MNIST Batch 57: Loss:     0.5168 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 58: Loss:     0.5656 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 59: Loss:     0.5868 Validation Accuracy: 0.870400\n",
      "Epoch  4, MNIST Batch 60: Loss:     0.6415 Validation Accuracy: 0.870400\n",
      "Epoch  4, MNIST Batch 61: Loss:     0.5819 Validation Accuracy: 0.870200\n",
      "Epoch  4, MNIST Batch 62: Loss:     0.6095 Validation Accuracy: 0.870600\n",
      "Epoch  4, MNIST Batch 63: Loss:     0.5968 Validation Accuracy: 0.869600\n",
      "Epoch  4, MNIST Batch 64: Loss:     0.5628 Validation Accuracy: 0.869800\n",
      "Epoch  4, MNIST Batch 65: Loss:     0.5625 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 66: Loss:     0.6215 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 67: Loss:     0.5886 Validation Accuracy: 0.869400\n",
      "Epoch  4, MNIST Batch 68: Loss:     0.5809 Validation Accuracy: 0.870200\n",
      "Epoch  4, MNIST Batch 69: Loss:     0.5644 Validation Accuracy: 0.870400\n",
      "Epoch  4, MNIST Batch 70: Loss:     0.6307 Validation Accuracy: 0.869800\n",
      "Epoch  4, MNIST Batch 71: Loss:     0.5790 Validation Accuracy: 0.870600\n",
      "Epoch  4, MNIST Batch 72: Loss:     0.5805 Validation Accuracy: 0.870400\n",
      "Epoch  4, MNIST Batch 73: Loss:     0.5574 Validation Accuracy: 0.871200\n",
      "Epoch  4, MNIST Batch 74: Loss:     0.5495 Validation Accuracy: 0.871400\n",
      "Epoch  4, MNIST Batch 75: Loss:     0.5714 Validation Accuracy: 0.871400\n",
      "Epoch  4, MNIST Batch 76: Loss:     0.5838 Validation Accuracy: 0.871200\n",
      "Epoch  4, MNIST Batch 77: Loss:     0.5343 Validation Accuracy: 0.871600\n",
      "Epoch  4, MNIST Batch 78: Loss:     0.5845 Validation Accuracy: 0.872400\n",
      "Epoch  4, MNIST Batch 79: Loss:     0.5776 Validation Accuracy: 0.872200\n",
      "Epoch  4, MNIST Batch 80: Loss:     0.5500 Validation Accuracy: 0.873000\n",
      "Epoch  4, MNIST Batch 81: Loss:     0.5457 Validation Accuracy: 0.873400\n",
      "Epoch  4, MNIST Batch 82: Loss:     0.5373 Validation Accuracy: 0.873600\n",
      "Epoch  4, MNIST Batch 83: Loss:     0.6158 Validation Accuracy: 0.873400\n",
      "Epoch  4, MNIST Batch 84: Loss:     0.5086 Validation Accuracy: 0.874800\n",
      "Epoch  4, MNIST Batch 85: Loss:     0.5380 Validation Accuracy: 0.875600\n",
      "Epoch  4, MNIST Batch 86: Loss:     0.5657 Validation Accuracy: 0.876200\n",
      "Epoch  4, MNIST Batch 87: Loss:     0.5092 Validation Accuracy: 0.877000\n",
      "Epoch  4, MNIST Batch 88: Loss:     0.4816 Validation Accuracy: 0.877800\n",
      "Epoch  4, MNIST Batch 89: Loss:     0.5275 Validation Accuracy: 0.878400\n",
      "Epoch  4, MNIST Batch 90: Loss:     0.5636 Validation Accuracy: 0.878200\n",
      "Epoch  4, MNIST Batch 91: Loss:     0.5106 Validation Accuracy: 0.877400\n",
      "Epoch  4, MNIST Batch 92: Loss:     0.5984 Validation Accuracy: 0.877600\n",
      "Epoch  4, MNIST Batch 93: Loss:     0.5068 Validation Accuracy: 0.878000\n",
      "Epoch  4, MNIST Batch 94: Loss:     0.5797 Validation Accuracy: 0.878200\n",
      "Epoch  4, MNIST Batch 95: Loss:     0.5240 Validation Accuracy: 0.877800\n",
      "Epoch  4, MNIST Batch 96: Loss:     0.5409 Validation Accuracy: 0.878200\n",
      "Epoch  4, MNIST Batch 97: Loss:     0.5208 Validation Accuracy: 0.878400\n",
      "Epoch  4, MNIST Batch 98: Loss:     0.5471 Validation Accuracy: 0.878400\n",
      "Epoch  4, MNIST Batch 99: Loss:     0.5060 Validation Accuracy: 0.878800\n",
      "Epoch  4, MNIST Batch 100: Loss:     0.4990 Validation Accuracy: 0.878400\n",
      "Epoch  4, MNIST Batch 101: Loss:     0.5290 Validation Accuracy: 0.877800\n",
      "Epoch  4, MNIST Batch 102: Loss:     0.5269 Validation Accuracy: 0.878400\n",
      "Epoch  4, MNIST Batch 103: Loss:     0.5675 Validation Accuracy: 0.879200\n",
      "Epoch  4, MNIST Batch 104: Loss:     0.5910 Validation Accuracy: 0.879200\n",
      "Epoch  4, MNIST Batch 105: Loss:     0.5588 Validation Accuracy: 0.879400\n",
      "Epoch  4, MNIST Batch 106: Loss:     0.4903 Validation Accuracy: 0.880200\n",
      "Epoch  5, MNIST Batch 0: Loss:     0.5177 Validation Accuracy: 0.880000\n",
      "Epoch  5, MNIST Batch 1: Loss:     0.5099 Validation Accuracy: 0.880400\n",
      "Epoch  5, MNIST Batch 2: Loss:     0.5393 Validation Accuracy: 0.880200\n",
      "Epoch  5, MNIST Batch 3: Loss:     0.5680 Validation Accuracy: 0.880800\n",
      "Epoch  5, MNIST Batch 4: Loss:     0.5120 Validation Accuracy: 0.881000\n",
      "Epoch  5, MNIST Batch 5: Loss:     0.5016 Validation Accuracy: 0.881000\n",
      "Epoch  5, MNIST Batch 6: Loss:     0.5065 Validation Accuracy: 0.881200\n",
      "Epoch  5, MNIST Batch 7: Loss:     0.4950 Validation Accuracy: 0.882200\n",
      "Epoch  5, MNIST Batch 8: Loss:     0.4889 Validation Accuracy: 0.882200\n",
      "Epoch  5, MNIST Batch 9: Loss:     0.5356 Validation Accuracy: 0.882600\n",
      "Epoch  5, MNIST Batch 10: Loss:     0.5019 Validation Accuracy: 0.883800\n",
      "Epoch  5, MNIST Batch 11: Loss:     0.5061 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 12: Loss:     0.5529 Validation Accuracy: 0.884000\n",
      "Epoch  5, MNIST Batch 13: Loss:     0.4533 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 14: Loss:     0.4959 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 15: Loss:     0.4733 Validation Accuracy: 0.884000\n",
      "Epoch  5, MNIST Batch 16: Loss:     0.5206 Validation Accuracy: 0.884000\n",
      "Epoch  5, MNIST Batch 17: Loss:     0.4796 Validation Accuracy: 0.884800\n",
      "Epoch  5, MNIST Batch 18: Loss:     0.5174 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 19: Loss:     0.5235 Validation Accuracy: 0.884000\n",
      "Epoch  5, MNIST Batch 20: Loss:     0.4966 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 21: Loss:     0.5057 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 22: Loss:     0.4892 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 23: Loss:     0.4747 Validation Accuracy: 0.883600\n",
      "Epoch  5, MNIST Batch 24: Loss:     0.5166 Validation Accuracy: 0.883600\n",
      "Epoch  5, MNIST Batch 25: Loss:     0.5022 Validation Accuracy: 0.883400\n",
      "Epoch  5, MNIST Batch 26: Loss:     0.4936 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 27: Loss:     0.5078 Validation Accuracy: 0.884600\n",
      "Epoch  5, MNIST Batch 28: Loss:     0.4091 Validation Accuracy: 0.883600\n",
      "Epoch  5, MNIST Batch 29: Loss:     0.4733 Validation Accuracy: 0.883800\n",
      "Epoch  5, MNIST Batch 30: Loss:     0.5334 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 31: Loss:     0.4516 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 32: Loss:     0.5044 Validation Accuracy: 0.884400\n",
      "Epoch  5, MNIST Batch 33: Loss:     0.5189 Validation Accuracy: 0.883800\n",
      "Epoch  5, MNIST Batch 34: Loss:     0.4603 Validation Accuracy: 0.884200\n",
      "Epoch  5, MNIST Batch 35: Loss:     0.4547 Validation Accuracy: 0.884800\n",
      "Epoch  5, MNIST Batch 36: Loss:     0.4551 Validation Accuracy: 0.884600\n",
      "Epoch  5, MNIST Batch 37: Loss:     0.4423 Validation Accuracy: 0.885000\n",
      "Epoch  5, MNIST Batch 38: Loss:     0.5299 Validation Accuracy: 0.885000\n",
      "Epoch  5, MNIST Batch 39: Loss:     0.4622 Validation Accuracy: 0.885800\n",
      "Epoch  5, MNIST Batch 40: Loss:     0.4768 Validation Accuracy: 0.886000\n",
      "Epoch  5, MNIST Batch 41: Loss:     0.4902 Validation Accuracy: 0.886400\n",
      "Epoch  5, MNIST Batch 42: Loss:     0.4618 Validation Accuracy: 0.887000\n",
      "Epoch  5, MNIST Batch 43: Loss:     0.4876 Validation Accuracy: 0.886800\n",
      "Epoch  5, MNIST Batch 44: Loss:     0.4473 Validation Accuracy: 0.887200\n",
      "Epoch  5, MNIST Batch 45: Loss:     0.4612 Validation Accuracy: 0.888400\n",
      "Epoch  5, MNIST Batch 46: Loss:     0.4273 Validation Accuracy: 0.889600\n",
      "Epoch  5, MNIST Batch 47: Loss:     0.4913 Validation Accuracy: 0.889800\n",
      "Epoch  5, MNIST Batch 48: Loss:     0.4515 Validation Accuracy: 0.888000\n",
      "Epoch  5, MNIST Batch 49: Loss:     0.4570 Validation Accuracy: 0.888000\n",
      "Epoch  5, MNIST Batch 50: Loss:     0.4507 Validation Accuracy: 0.887800\n",
      "Epoch  5, MNIST Batch 51: Loss:     0.4553 Validation Accuracy: 0.887400\n",
      "Epoch  5, MNIST Batch 52: Loss:     0.4951 Validation Accuracy: 0.887800\n",
      "Epoch  5, MNIST Batch 53: Loss:     0.4605 Validation Accuracy: 0.888400\n",
      "Epoch  5, MNIST Batch 54: Loss:     0.4155 Validation Accuracy: 0.888600\n",
      "Epoch  5, MNIST Batch 55: Loss:     0.4010 Validation Accuracy: 0.887600\n",
      "Epoch  5, MNIST Batch 56: Loss:     0.5004 Validation Accuracy: 0.888000\n",
      "Epoch  5, MNIST Batch 57: Loss:     0.4384 Validation Accuracy: 0.887800\n",
      "Epoch  5, MNIST Batch 58: Loss:     0.5001 Validation Accuracy: 0.889000\n",
      "Epoch  5, MNIST Batch 59: Loss:     0.4868 Validation Accuracy: 0.889200\n",
      "Epoch  5, MNIST Batch 60: Loss:     0.4821 Validation Accuracy: 0.889000\n",
      "Epoch  5, MNIST Batch 61: Loss:     0.4520 Validation Accuracy: 0.890000\n",
      "Epoch  5, MNIST Batch 62: Loss:     0.4487 Validation Accuracy: 0.891400\n",
      "Epoch  5, MNIST Batch 63: Loss:     0.4613 Validation Accuracy: 0.891800\n",
      "Epoch  5, MNIST Batch 64: Loss:     0.5223 Validation Accuracy: 0.891200\n",
      "Epoch  5, MNIST Batch 65: Loss:     0.4364 Validation Accuracy: 0.891400\n",
      "Epoch  5, MNIST Batch 66: Loss:     0.4818 Validation Accuracy: 0.893000\n",
      "Epoch  5, MNIST Batch 67: Loss:     0.4366 Validation Accuracy: 0.892200\n",
      "Epoch  5, MNIST Batch 68: Loss:     0.4466 Validation Accuracy: 0.893000\n",
      "Epoch  5, MNIST Batch 69: Loss:     0.4445 Validation Accuracy: 0.892800\n",
      "Epoch  5, MNIST Batch 70: Loss:     0.4700 Validation Accuracy: 0.892400\n",
      "Epoch  5, MNIST Batch 71: Loss:     0.4575 Validation Accuracy: 0.892000\n",
      "Epoch  5, MNIST Batch 72: Loss:     0.4221 Validation Accuracy: 0.892400\n",
      "Epoch  5, MNIST Batch 73: Loss:     0.4488 Validation Accuracy: 0.893000\n",
      "Epoch  5, MNIST Batch 74: Loss:     0.4308 Validation Accuracy: 0.892400\n",
      "Epoch  5, MNIST Batch 75: Loss:     0.4693 Validation Accuracy: 0.892200\n",
      "Epoch  5, MNIST Batch 76: Loss:     0.4413 Validation Accuracy: 0.892400\n",
      "Epoch  5, MNIST Batch 77: Loss:     0.4734 Validation Accuracy: 0.892600\n",
      "Epoch  5, MNIST Batch 78: Loss:     0.4618 Validation Accuracy: 0.893600\n",
      "Epoch  5, MNIST Batch 79: Loss:     0.4529 Validation Accuracy: 0.893600\n",
      "Epoch  5, MNIST Batch 80: Loss:     0.4435 Validation Accuracy: 0.894000\n",
      "Epoch  5, MNIST Batch 81: Loss:     0.4685 Validation Accuracy: 0.894200\n",
      "Epoch  5, MNIST Batch 82: Loss:     0.4464 Validation Accuracy: 0.894800\n",
      "Epoch  5, MNIST Batch 83: Loss:     0.4259 Validation Accuracy: 0.894200\n",
      "Epoch  5, MNIST Batch 84: Loss:     0.4467 Validation Accuracy: 0.894400\n",
      "Epoch  5, MNIST Batch 85: Loss:     0.4124 Validation Accuracy: 0.894200\n",
      "Epoch  5, MNIST Batch 86: Loss:     0.4283 Validation Accuracy: 0.894200\n",
      "Epoch  5, MNIST Batch 87: Loss:     0.4665 Validation Accuracy: 0.894600\n",
      "Epoch  5, MNIST Batch 88: Loss:     0.3684 Validation Accuracy: 0.896000\n",
      "Epoch  5, MNIST Batch 89: Loss:     0.4207 Validation Accuracy: 0.896800\n",
      "Epoch  5, MNIST Batch 90: Loss:     0.4482 Validation Accuracy: 0.897200\n",
      "Epoch  5, MNIST Batch 91: Loss:     0.4148 Validation Accuracy: 0.897200\n",
      "Epoch  5, MNIST Batch 92: Loss:     0.4367 Validation Accuracy: 0.897600\n",
      "Epoch  5, MNIST Batch 93: Loss:     0.4204 Validation Accuracy: 0.897000\n",
      "Epoch  5, MNIST Batch 94: Loss:     0.4136 Validation Accuracy: 0.897400\n",
      "Epoch  5, MNIST Batch 95: Loss:     0.4686 Validation Accuracy: 0.897200\n",
      "Epoch  5, MNIST Batch 96: Loss:     0.4314 Validation Accuracy: 0.896800\n",
      "Epoch  5, MNIST Batch 97: Loss:     0.4161 Validation Accuracy: 0.897600\n",
      "Epoch  5, MNIST Batch 98: Loss:     0.4526 Validation Accuracy: 0.897800\n",
      "Epoch  5, MNIST Batch 99: Loss:     0.4034 Validation Accuracy: 0.897400\n",
      "Epoch  5, MNIST Batch 100: Loss:     0.4382 Validation Accuracy: 0.898000\n",
      "Epoch  5, MNIST Batch 101: Loss:     0.4432 Validation Accuracy: 0.897800\n",
      "Epoch  5, MNIST Batch 102: Loss:     0.4619 Validation Accuracy: 0.898000\n",
      "Epoch  5, MNIST Batch 103: Loss:     0.4579 Validation Accuracy: 0.898600\n",
      "Epoch  5, MNIST Batch 104: Loss:     0.3875 Validation Accuracy: 0.898400\n",
      "Epoch  5, MNIST Batch 105: Loss:     0.4063 Validation Accuracy: 0.898600\n",
      "Epoch  5, MNIST Batch 106: Loss:     0.3959 Validation Accuracy: 0.898600\n",
      "Epoch  6, MNIST Batch 0: Loss:     0.4082 Validation Accuracy: 0.899200\n",
      "Epoch  6, MNIST Batch 1: Loss:     0.4272 Validation Accuracy: 0.899000\n",
      "Epoch  6, MNIST Batch 2: Loss:     0.4166 Validation Accuracy: 0.898800\n",
      "Epoch  6, MNIST Batch 3: Loss:     0.4182 Validation Accuracy: 0.898200\n",
      "Epoch  6, MNIST Batch 4: Loss:     0.4196 Validation Accuracy: 0.898000\n",
      "Epoch  6, MNIST Batch 5: Loss:     0.4081 Validation Accuracy: 0.897800\n",
      "Epoch  6, MNIST Batch 6: Loss:     0.4140 Validation Accuracy: 0.897800\n",
      "Epoch  6, MNIST Batch 7: Loss:     0.3853 Validation Accuracy: 0.898000\n",
      "Epoch  6, MNIST Batch 8: Loss:     0.4063 Validation Accuracy: 0.898000\n",
      "Epoch  6, MNIST Batch 9: Loss:     0.3674 Validation Accuracy: 0.898000\n",
      "Epoch  6, MNIST Batch 10: Loss:     0.4076 Validation Accuracy: 0.898600\n",
      "Epoch  6, MNIST Batch 11: Loss:     0.4189 Validation Accuracy: 0.900000\n",
      "Epoch  6, MNIST Batch 12: Loss:     0.4037 Validation Accuracy: 0.899800\n",
      "Epoch  6, MNIST Batch 13: Loss:     0.4356 Validation Accuracy: 0.900200\n",
      "Epoch  6, MNIST Batch 14: Loss:     0.4276 Validation Accuracy: 0.900200\n",
      "Epoch  6, MNIST Batch 15: Loss:     0.4252 Validation Accuracy: 0.900800\n",
      "Epoch  6, MNIST Batch 16: Loss:     0.4084 Validation Accuracy: 0.901000\n",
      "Epoch  6, MNIST Batch 17: Loss:     0.4130 Validation Accuracy: 0.901000\n",
      "Epoch  6, MNIST Batch 18: Loss:     0.4328 Validation Accuracy: 0.901200\n",
      "Epoch  6, MNIST Batch 19: Loss:     0.3754 Validation Accuracy: 0.902200\n",
      "Epoch  6, MNIST Batch 20: Loss:     0.4449 Validation Accuracy: 0.903000\n",
      "Epoch  6, MNIST Batch 21: Loss:     0.3934 Validation Accuracy: 0.902600\n",
      "Epoch  6, MNIST Batch 22: Loss:     0.4212 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 23: Loss:     0.4129 Validation Accuracy: 0.903400\n",
      "Epoch  6, MNIST Batch 24: Loss:     0.3896 Validation Accuracy: 0.903600\n",
      "Epoch  6, MNIST Batch 25: Loss:     0.3600 Validation Accuracy: 0.903000\n",
      "Epoch  6, MNIST Batch 26: Loss:     0.4202 Validation Accuracy: 0.904000\n",
      "Epoch  6, MNIST Batch 27: Loss:     0.3890 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 28: Loss:     0.3745 Validation Accuracy: 0.904200\n",
      "Epoch  6, MNIST Batch 29: Loss:     0.4718 Validation Accuracy: 0.904400\n",
      "Epoch  6, MNIST Batch 30: Loss:     0.4382 Validation Accuracy: 0.904000\n",
      "Epoch  6, MNIST Batch 31: Loss:     0.3267 Validation Accuracy: 0.904400\n",
      "Epoch  6, MNIST Batch 32: Loss:     0.4214 Validation Accuracy: 0.904600\n",
      "Epoch  6, MNIST Batch 33: Loss:     0.4060 Validation Accuracy: 0.904000\n",
      "Epoch  6, MNIST Batch 34: Loss:     0.3666 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 35: Loss:     0.3574 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 36: Loss:     0.4126 Validation Accuracy: 0.902800\n",
      "Epoch  6, MNIST Batch 37: Loss:     0.4296 Validation Accuracy: 0.904200\n",
      "Epoch  6, MNIST Batch 38: Loss:     0.3983 Validation Accuracy: 0.904400\n",
      "Epoch  6, MNIST Batch 39: Loss:     0.3952 Validation Accuracy: 0.904200\n",
      "Epoch  6, MNIST Batch 40: Loss:     0.3953 Validation Accuracy: 0.904400\n",
      "Epoch  6, MNIST Batch 41: Loss:     0.4413 Validation Accuracy: 0.903600\n",
      "Epoch  6, MNIST Batch 42: Loss:     0.3833 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 43: Loss:     0.3102 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 44: Loss:     0.3541 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 45: Loss:     0.3523 Validation Accuracy: 0.902800\n",
      "Epoch  6, MNIST Batch 46: Loss:     0.3576 Validation Accuracy: 0.903400\n",
      "Epoch  6, MNIST Batch 47: Loss:     0.3739 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 48: Loss:     0.4083 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 49: Loss:     0.3425 Validation Accuracy: 0.903200\n",
      "Epoch  6, MNIST Batch 50: Loss:     0.4900 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 51: Loss:     0.3826 Validation Accuracy: 0.903600\n",
      "Epoch  6, MNIST Batch 52: Loss:     0.3998 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 53: Loss:     0.3833 Validation Accuracy: 0.903800\n",
      "Epoch  6, MNIST Batch 54: Loss:     0.3893 Validation Accuracy: 0.904200\n",
      "Epoch  6, MNIST Batch 55: Loss:     0.3709 Validation Accuracy: 0.904400\n",
      "Epoch  6, MNIST Batch 56: Loss:     0.3880 Validation Accuracy: 0.904600\n",
      "Epoch  6, MNIST Batch 57: Loss:     0.3869 Validation Accuracy: 0.905200\n",
      "Epoch  6, MNIST Batch 58: Loss:     0.4483 Validation Accuracy: 0.905000\n",
      "Epoch  6, MNIST Batch 59: Loss:     0.4339 Validation Accuracy: 0.904800\n",
      "Epoch  6, MNIST Batch 60: Loss:     0.3899 Validation Accuracy: 0.905600\n",
      "Epoch  6, MNIST Batch 61: Loss:     0.3566 Validation Accuracy: 0.905000\n",
      "Epoch  6, MNIST Batch 62: Loss:     0.4233 Validation Accuracy: 0.906200\n",
      "Epoch  6, MNIST Batch 63: Loss:     0.3799 Validation Accuracy: 0.906800\n",
      "Epoch  6, MNIST Batch 64: Loss:     0.4104 Validation Accuracy: 0.906600\n",
      "Epoch  6, MNIST Batch 65: Loss:     0.3809 Validation Accuracy: 0.908200\n",
      "Epoch  6, MNIST Batch 66: Loss:     0.3370 Validation Accuracy: 0.908400\n",
      "Epoch  6, MNIST Batch 67: Loss:     0.3178 Validation Accuracy: 0.908400\n",
      "Epoch  6, MNIST Batch 68: Loss:     0.3818 Validation Accuracy: 0.909200\n",
      "Epoch  6, MNIST Batch 69: Loss:     0.3697 Validation Accuracy: 0.909000\n",
      "Epoch  6, MNIST Batch 70: Loss:     0.3509 Validation Accuracy: 0.910000\n",
      "Epoch  6, MNIST Batch 71: Loss:     0.3387 Validation Accuracy: 0.909800\n",
      "Epoch  6, MNIST Batch 72: Loss:     0.4061 Validation Accuracy: 0.909600\n",
      "Epoch  6, MNIST Batch 73: Loss:     0.3697 Validation Accuracy: 0.910600\n",
      "Epoch  6, MNIST Batch 74: Loss:     0.3426 Validation Accuracy: 0.911000\n",
      "Epoch  6, MNIST Batch 75: Loss:     0.3808 Validation Accuracy: 0.911200\n",
      "Epoch  6, MNIST Batch 76: Loss:     0.4359 Validation Accuracy: 0.911000\n",
      "Epoch  6, MNIST Batch 77: Loss:     0.3649 Validation Accuracy: 0.910800\n",
      "Epoch  6, MNIST Batch 78: Loss:     0.3728 Validation Accuracy: 0.910400\n",
      "Epoch  6, MNIST Batch 79: Loss:     0.3684 Validation Accuracy: 0.909400\n",
      "Epoch  6, MNIST Batch 80: Loss:     0.3963 Validation Accuracy: 0.909000\n",
      "Epoch  6, MNIST Batch 81: Loss:     0.3531 Validation Accuracy: 0.909200\n",
      "Epoch  6, MNIST Batch 82: Loss:     0.3575 Validation Accuracy: 0.908800\n",
      "Epoch  6, MNIST Batch 83: Loss:     0.3896 Validation Accuracy: 0.909200\n",
      "Epoch  6, MNIST Batch 84: Loss:     0.3255 Validation Accuracy: 0.909000\n",
      "Epoch  6, MNIST Batch 85: Loss:     0.4255 Validation Accuracy: 0.909000\n",
      "Epoch  6, MNIST Batch 86: Loss:     0.4164 Validation Accuracy: 0.909200\n",
      "Epoch  6, MNIST Batch 87: Loss:     0.4251 Validation Accuracy: 0.909600\n",
      "Epoch  6, MNIST Batch 88: Loss:     0.3556 Validation Accuracy: 0.909000\n",
      "Epoch  6, MNIST Batch 89: Loss:     0.3465 Validation Accuracy: 0.909400\n",
      "Epoch  6, MNIST Batch 90: Loss:     0.3997 Validation Accuracy: 0.909600\n",
      "Epoch  6, MNIST Batch 91: Loss:     0.4017 Validation Accuracy: 0.909800\n",
      "Epoch  6, MNIST Batch 92: Loss:     0.4377 Validation Accuracy: 0.910600\n",
      "Epoch  6, MNIST Batch 93: Loss:     0.3812 Validation Accuracy: 0.910600\n",
      "Epoch  6, MNIST Batch 94: Loss:     0.3624 Validation Accuracy: 0.910600\n",
      "Epoch  6, MNIST Batch 95: Loss:     0.3483 Validation Accuracy: 0.910200\n",
      "Epoch  6, MNIST Batch 96: Loss:     0.3962 Validation Accuracy: 0.910600\n",
      "Epoch  6, MNIST Batch 97: Loss:     0.3705 Validation Accuracy: 0.911200\n",
      "Epoch  6, MNIST Batch 98: Loss:     0.4069 Validation Accuracy: 0.911800\n",
      "Epoch  6, MNIST Batch 99: Loss:     0.3682 Validation Accuracy: 0.911800\n",
      "Epoch  6, MNIST Batch 100: Loss:     0.3743 Validation Accuracy: 0.910800\n",
      "Epoch  6, MNIST Batch 101: Loss:     0.3781 Validation Accuracy: 0.910800\n",
      "Epoch  6, MNIST Batch 102: Loss:     0.3889 Validation Accuracy: 0.911400\n",
      "Epoch  6, MNIST Batch 103: Loss:     0.3259 Validation Accuracy: 0.911600\n",
      "Epoch  6, MNIST Batch 104: Loss:     0.3740 Validation Accuracy: 0.911800\n",
      "Epoch  6, MNIST Batch 105: Loss:     0.3664 Validation Accuracy: 0.911200\n",
      "Epoch  6, MNIST Batch 106: Loss:     0.3566 Validation Accuracy: 0.911400\n",
      "Epoch  7, MNIST Batch 0: Loss:     0.3539 Validation Accuracy: 0.912200\n",
      "Epoch  7, MNIST Batch 1: Loss:     0.3674 Validation Accuracy: 0.913000\n",
      "Epoch  7, MNIST Batch 2: Loss:     0.3811 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 3: Loss:     0.3249 Validation Accuracy: 0.913000\n",
      "Epoch  7, MNIST Batch 4: Loss:     0.3001 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 5: Loss:     0.3579 Validation Accuracy: 0.912800\n",
      "Epoch  7, MNIST Batch 6: Loss:     0.3708 Validation Accuracy: 0.912600\n",
      "Epoch  7, MNIST Batch 7: Loss:     0.3835 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 8: Loss:     0.4136 Validation Accuracy: 0.913400\n",
      "Epoch  7, MNIST Batch 9: Loss:     0.3548 Validation Accuracy: 0.913800\n",
      "Epoch  7, MNIST Batch 10: Loss:     0.3796 Validation Accuracy: 0.913600\n",
      "Epoch  7, MNIST Batch 11: Loss:     0.3696 Validation Accuracy: 0.913000\n",
      "Epoch  7, MNIST Batch 12: Loss:     0.3322 Validation Accuracy: 0.912200\n",
      "Epoch  7, MNIST Batch 13: Loss:     0.3920 Validation Accuracy: 0.911800\n",
      "Epoch  7, MNIST Batch 14: Loss:     0.4338 Validation Accuracy: 0.912000\n",
      "Epoch  7, MNIST Batch 15: Loss:     0.3205 Validation Accuracy: 0.912400\n",
      "Epoch  7, MNIST Batch 16: Loss:     0.3495 Validation Accuracy: 0.911800\n",
      "Epoch  7, MNIST Batch 17: Loss:     0.3440 Validation Accuracy: 0.912800\n",
      "Epoch  7, MNIST Batch 18: Loss:     0.3391 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 19: Loss:     0.3438 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 20: Loss:     0.3556 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 21: Loss:     0.3617 Validation Accuracy: 0.913800\n",
      "Epoch  7, MNIST Batch 22: Loss:     0.3377 Validation Accuracy: 0.913800\n",
      "Epoch  7, MNIST Batch 23: Loss:     0.3304 Validation Accuracy: 0.914200\n",
      "Epoch  7, MNIST Batch 24: Loss:     0.3668 Validation Accuracy: 0.915200\n",
      "Epoch  7, MNIST Batch 25: Loss:     0.3212 Validation Accuracy: 0.915400\n",
      "Epoch  7, MNIST Batch 26: Loss:     0.3536 Validation Accuracy: 0.914800\n",
      "Epoch  7, MNIST Batch 27: Loss:     0.3639 Validation Accuracy: 0.914200\n",
      "Epoch  7, MNIST Batch 28: Loss:     0.3332 Validation Accuracy: 0.914600\n",
      "Epoch  7, MNIST Batch 29: Loss:     0.3238 Validation Accuracy: 0.913600\n",
      "Epoch  7, MNIST Batch 30: Loss:     0.3512 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 31: Loss:     0.3423 Validation Accuracy: 0.913200\n",
      "Epoch  7, MNIST Batch 32: Loss:     0.3938 Validation Accuracy: 0.913400\n",
      "Epoch  7, MNIST Batch 33: Loss:     0.3638 Validation Accuracy: 0.914000\n",
      "Epoch  7, MNIST Batch 34: Loss:     0.3349 Validation Accuracy: 0.913600\n",
      "Epoch  7, MNIST Batch 35: Loss:     0.3133 Validation Accuracy: 0.914200\n",
      "Epoch  7, MNIST Batch 36: Loss:     0.3884 Validation Accuracy: 0.914400\n",
      "Epoch  7, MNIST Batch 37: Loss:     0.3550 Validation Accuracy: 0.915000\n",
      "Epoch  7, MNIST Batch 38: Loss:     0.3083 Validation Accuracy: 0.914600\n",
      "Epoch  7, MNIST Batch 39: Loss:     0.3485 Validation Accuracy: 0.914800\n",
      "Epoch  7, MNIST Batch 40: Loss:     0.3601 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 41: Loss:     0.3840 Validation Accuracy: 0.915000\n",
      "Epoch  7, MNIST Batch 42: Loss:     0.3375 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 43: Loss:     0.2964 Validation Accuracy: 0.916000\n",
      "Epoch  7, MNIST Batch 44: Loss:     0.3117 Validation Accuracy: 0.915400\n",
      "Epoch  7, MNIST Batch 45: Loss:     0.3641 Validation Accuracy: 0.915600\n",
      "Epoch  7, MNIST Batch 46: Loss:     0.3466 Validation Accuracy: 0.916000\n",
      "Epoch  7, MNIST Batch 47: Loss:     0.3952 Validation Accuracy: 0.915600\n",
      "Epoch  7, MNIST Batch 48: Loss:     0.3840 Validation Accuracy: 0.915600\n",
      "Epoch  7, MNIST Batch 49: Loss:     0.3604 Validation Accuracy: 0.915600\n",
      "Epoch  7, MNIST Batch 50: Loss:     0.3363 Validation Accuracy: 0.916000\n",
      "Epoch  7, MNIST Batch 51: Loss:     0.3100 Validation Accuracy: 0.916400\n",
      "Epoch  7, MNIST Batch 52: Loss:     0.3313 Validation Accuracy: 0.916400\n",
      "Epoch  7, MNIST Batch 53: Loss:     0.3291 Validation Accuracy: 0.916400\n",
      "Epoch  7, MNIST Batch 54: Loss:     0.3272 Validation Accuracy: 0.916400\n",
      "Epoch  7, MNIST Batch 55: Loss:     0.3149 Validation Accuracy: 0.916400\n",
      "Epoch  7, MNIST Batch 56: Loss:     0.3377 Validation Accuracy: 0.916200\n",
      "Epoch  7, MNIST Batch 57: Loss:     0.3615 Validation Accuracy: 0.916000\n",
      "Epoch  7, MNIST Batch 58: Loss:     0.3801 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 59: Loss:     0.3453 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 60: Loss:     0.3365 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 61: Loss:     0.3352 Validation Accuracy: 0.915400\n",
      "Epoch  7, MNIST Batch 62: Loss:     0.3771 Validation Accuracy: 0.915800\n",
      "Epoch  7, MNIST Batch 63: Loss:     0.3525 Validation Accuracy: 0.916200\n",
      "Epoch  7, MNIST Batch 64: Loss:     0.3123 Validation Accuracy: 0.916200\n",
      "Epoch  7, MNIST Batch 65: Loss:     0.3198 Validation Accuracy: 0.917000\n",
      "Epoch  7, MNIST Batch 66: Loss:     0.3350 Validation Accuracy: 0.917800\n",
      "Epoch  7, MNIST Batch 67: Loss:     0.3157 Validation Accuracy: 0.917400\n",
      "Epoch  7, MNIST Batch 68: Loss:     0.3466 Validation Accuracy: 0.917800\n",
      "Epoch  7, MNIST Batch 69: Loss:     0.3849 Validation Accuracy: 0.917800\n",
      "Epoch  7, MNIST Batch 70: Loss:     0.3359 Validation Accuracy: 0.917600\n",
      "Epoch  7, MNIST Batch 71: Loss:     0.3236 Validation Accuracy: 0.918000\n",
      "Epoch  7, MNIST Batch 72: Loss:     0.3574 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 73: Loss:     0.3623 Validation Accuracy: 0.919000\n",
      "Epoch  7, MNIST Batch 74: Loss:     0.3276 Validation Accuracy: 0.919200\n",
      "Epoch  7, MNIST Batch 75: Loss:     0.3207 Validation Accuracy: 0.919200\n",
      "Epoch  7, MNIST Batch 76: Loss:     0.3157 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 77: Loss:     0.3257 Validation Accuracy: 0.918600\n",
      "Epoch  7, MNIST Batch 78: Loss:     0.3696 Validation Accuracy: 0.918600\n",
      "Epoch  7, MNIST Batch 79: Loss:     0.3748 Validation Accuracy: 0.919000\n",
      "Epoch  7, MNIST Batch 80: Loss:     0.3228 Validation Accuracy: 0.919200\n",
      "Epoch  7, MNIST Batch 81: Loss:     0.2937 Validation Accuracy: 0.919000\n",
      "Epoch  7, MNIST Batch 82: Loss:     0.3041 Validation Accuracy: 0.919200\n",
      "Epoch  7, MNIST Batch 83: Loss:     0.2707 Validation Accuracy: 0.919800\n",
      "Epoch  7, MNIST Batch 84: Loss:     0.3272 Validation Accuracy: 0.919200\n",
      "Epoch  7, MNIST Batch 85: Loss:     0.3035 Validation Accuracy: 0.919600\n",
      "Epoch  7, MNIST Batch 86: Loss:     0.2897 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 87: Loss:     0.3221 Validation Accuracy: 0.918600\n",
      "Epoch  7, MNIST Batch 88: Loss:     0.3380 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 89: Loss:     0.3140 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 90: Loss:     0.2695 Validation Accuracy: 0.918200\n",
      "Epoch  7, MNIST Batch 91: Loss:     0.3299 Validation Accuracy: 0.918400\n",
      "Epoch  7, MNIST Batch 92: Loss:     0.3125 Validation Accuracy: 0.918200\n",
      "Epoch  7, MNIST Batch 93: Loss:     0.2988 Validation Accuracy: 0.918600\n",
      "Epoch  7, MNIST Batch 94: Loss:     0.3896 Validation Accuracy: 0.918200\n",
      "Epoch  7, MNIST Batch 95: Loss:     0.3394 Validation Accuracy: 0.918000\n",
      "Epoch  7, MNIST Batch 96: Loss:     0.3298 Validation Accuracy: 0.918000\n",
      "Epoch  7, MNIST Batch 97: Loss:     0.3155 Validation Accuracy: 0.917800\n",
      "Epoch  7, MNIST Batch 98: Loss:     0.3539 Validation Accuracy: 0.918000\n",
      "Epoch  7, MNIST Batch 99: Loss:     0.3096 Validation Accuracy: 0.918200\n",
      "Epoch  7, MNIST Batch 100: Loss:     0.3982 Validation Accuracy: 0.918000\n",
      "Epoch  7, MNIST Batch 101: Loss:     0.3705 Validation Accuracy: 0.918200\n",
      "Epoch  7, MNIST Batch 102: Loss:     0.3052 Validation Accuracy: 0.918800\n",
      "Epoch  7, MNIST Batch 103: Loss:     0.3734 Validation Accuracy: 0.919600\n",
      "Epoch  7, MNIST Batch 104: Loss:     0.3205 Validation Accuracy: 0.919400\n",
      "Epoch  7, MNIST Batch 105: Loss:     0.3304 Validation Accuracy: 0.920000\n",
      "Epoch  7, MNIST Batch 106: Loss:     0.2841 Validation Accuracy: 0.920600\n",
      "Epoch  8, MNIST Batch 0: Loss:     0.2854 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 1: Loss:     0.2585 Validation Accuracy: 0.921800\n",
      "Epoch  8, MNIST Batch 2: Loss:     0.3133 Validation Accuracy: 0.922600\n",
      "Epoch  8, MNIST Batch 3: Loss:     0.3208 Validation Accuracy: 0.923000\n",
      "Epoch  8, MNIST Batch 4: Loss:     0.3786 Validation Accuracy: 0.923400\n",
      "Epoch  8, MNIST Batch 5: Loss:     0.2880 Validation Accuracy: 0.923800\n",
      "Epoch  8, MNIST Batch 6: Loss:     0.3096 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 7: Loss:     0.2958 Validation Accuracy: 0.924600\n",
      "Epoch  8, MNIST Batch 8: Loss:     0.3146 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 9: Loss:     0.3530 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 10: Loss:     0.3267 Validation Accuracy: 0.924200\n",
      "Epoch  8, MNIST Batch 11: Loss:     0.2660 Validation Accuracy: 0.923200\n",
      "Epoch  8, MNIST Batch 12: Loss:     0.2773 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 13: Loss:     0.3756 Validation Accuracy: 0.922600\n",
      "Epoch  8, MNIST Batch 14: Loss:     0.3518 Validation Accuracy: 0.921400\n",
      "Epoch  8, MNIST Batch 15: Loss:     0.3039 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 16: Loss:     0.3296 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 17: Loss:     0.3233 Validation Accuracy: 0.921200\n",
      "Epoch  8, MNIST Batch 18: Loss:     0.3234 Validation Accuracy: 0.921200\n",
      "Epoch  8, MNIST Batch 19: Loss:     0.3034 Validation Accuracy: 0.921000\n",
      "Epoch  8, MNIST Batch 20: Loss:     0.2970 Validation Accuracy: 0.921000\n",
      "Epoch  8, MNIST Batch 21: Loss:     0.3349 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 22: Loss:     0.3016 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 23: Loss:     0.3570 Validation Accuracy: 0.921200\n",
      "Epoch  8, MNIST Batch 24: Loss:     0.3429 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 25: Loss:     0.2861 Validation Accuracy: 0.922000\n",
      "Epoch  8, MNIST Batch 26: Loss:     0.2786 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 27: Loss:     0.3348 Validation Accuracy: 0.923200\n",
      "Epoch  8, MNIST Batch 28: Loss:     0.2816 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 29: Loss:     0.2933 Validation Accuracy: 0.922800\n",
      "Epoch  8, MNIST Batch 30: Loss:     0.2563 Validation Accuracy: 0.922200\n",
      "Epoch  8, MNIST Batch 31: Loss:     0.2934 Validation Accuracy: 0.922600\n",
      "Epoch  8, MNIST Batch 32: Loss:     0.3163 Validation Accuracy: 0.922000\n",
      "Epoch  8, MNIST Batch 33: Loss:     0.3063 Validation Accuracy: 0.922400\n",
      "Epoch  8, MNIST Batch 34: Loss:     0.2596 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 35: Loss:     0.3280 Validation Accuracy: 0.921400\n",
      "Epoch  8, MNIST Batch 36: Loss:     0.2892 Validation Accuracy: 0.920600\n",
      "Epoch  8, MNIST Batch 37: Loss:     0.2972 Validation Accuracy: 0.920400\n",
      "Epoch  8, MNIST Batch 38: Loss:     0.3479 Validation Accuracy: 0.919800\n",
      "Epoch  8, MNIST Batch 39: Loss:     0.3223 Validation Accuracy: 0.920400\n",
      "Epoch  8, MNIST Batch 40: Loss:     0.3075 Validation Accuracy: 0.921200\n",
      "Epoch  8, MNIST Batch 41: Loss:     0.2922 Validation Accuracy: 0.921600\n",
      "Epoch  8, MNIST Batch 42: Loss:     0.3103 Validation Accuracy: 0.921400\n",
      "Epoch  8, MNIST Batch 43: Loss:     0.3213 Validation Accuracy: 0.922000\n",
      "Epoch  8, MNIST Batch 44: Loss:     0.2689 Validation Accuracy: 0.922400\n",
      "Epoch  8, MNIST Batch 45: Loss:     0.3398 Validation Accuracy: 0.922800\n",
      "Epoch  8, MNIST Batch 46: Loss:     0.3109 Validation Accuracy: 0.923600\n",
      "Epoch  8, MNIST Batch 47: Loss:     0.3361 Validation Accuracy: 0.924200\n",
      "Epoch  8, MNIST Batch 48: Loss:     0.3299 Validation Accuracy: 0.923200\n",
      "Epoch  8, MNIST Batch 49: Loss:     0.3339 Validation Accuracy: 0.923800\n",
      "Epoch  8, MNIST Batch 50: Loss:     0.3122 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 51: Loss:     0.3132 Validation Accuracy: 0.924800\n",
      "Epoch  8, MNIST Batch 52: Loss:     0.2751 Validation Accuracy: 0.925200\n",
      "Epoch  8, MNIST Batch 53: Loss:     0.3023 Validation Accuracy: 0.925400\n",
      "Epoch  8, MNIST Batch 54: Loss:     0.3615 Validation Accuracy: 0.925200\n",
      "Epoch  8, MNIST Batch 55: Loss:     0.2996 Validation Accuracy: 0.924600\n",
      "Epoch  8, MNIST Batch 56: Loss:     0.3239 Validation Accuracy: 0.925600\n",
      "Epoch  8, MNIST Batch 57: Loss:     0.2724 Validation Accuracy: 0.925600\n",
      "Epoch  8, MNIST Batch 58: Loss:     0.3263 Validation Accuracy: 0.925600\n",
      "Epoch  8, MNIST Batch 59: Loss:     0.2698 Validation Accuracy: 0.926400\n",
      "Epoch  8, MNIST Batch 60: Loss:     0.2964 Validation Accuracy: 0.926400\n",
      "Epoch  8, MNIST Batch 61: Loss:     0.3214 Validation Accuracy: 0.924600\n",
      "Epoch  8, MNIST Batch 62: Loss:     0.3621 Validation Accuracy: 0.924200\n",
      "Epoch  8, MNIST Batch 63: Loss:     0.2685 Validation Accuracy: 0.923800\n",
      "Epoch  8, MNIST Batch 64: Loss:     0.2623 Validation Accuracy: 0.923200\n",
      "Epoch  8, MNIST Batch 65: Loss:     0.3412 Validation Accuracy: 0.923000\n",
      "Epoch  8, MNIST Batch 66: Loss:     0.3657 Validation Accuracy: 0.923600\n",
      "Epoch  8, MNIST Batch 67: Loss:     0.2896 Validation Accuracy: 0.923000\n",
      "Epoch  8, MNIST Batch 68: Loss:     0.3389 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 69: Loss:     0.3062 Validation Accuracy: 0.924800\n",
      "Epoch  8, MNIST Batch 70: Loss:     0.3184 Validation Accuracy: 0.924600\n",
      "Epoch  8, MNIST Batch 71: Loss:     0.3339 Validation Accuracy: 0.925000\n",
      "Epoch  8, MNIST Batch 72: Loss:     0.2572 Validation Accuracy: 0.925600\n",
      "Epoch  8, MNIST Batch 73: Loss:     0.3068 Validation Accuracy: 0.925400\n",
      "Epoch  8, MNIST Batch 74: Loss:     0.2947 Validation Accuracy: 0.926600\n",
      "Epoch  8, MNIST Batch 75: Loss:     0.2945 Validation Accuracy: 0.926600\n",
      "Epoch  8, MNIST Batch 76: Loss:     0.3013 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 77: Loss:     0.2807 Validation Accuracy: 0.928400\n",
      "Epoch  8, MNIST Batch 78: Loss:     0.2564 Validation Accuracy: 0.927800\n",
      "Epoch  8, MNIST Batch 79: Loss:     0.2811 Validation Accuracy: 0.927600\n",
      "Epoch  8, MNIST Batch 80: Loss:     0.2930 Validation Accuracy: 0.927400\n",
      "Epoch  8, MNIST Batch 81: Loss:     0.3194 Validation Accuracy: 0.927200\n",
      "Epoch  8, MNIST Batch 82: Loss:     0.2935 Validation Accuracy: 0.927400\n",
      "Epoch  8, MNIST Batch 83: Loss:     0.2669 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 84: Loss:     0.3017 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 85: Loss:     0.2913 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 86: Loss:     0.3128 Validation Accuracy: 0.927200\n",
      "Epoch  8, MNIST Batch 87: Loss:     0.2635 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 88: Loss:     0.3661 Validation Accuracy: 0.926600\n",
      "Epoch  8, MNIST Batch 89: Loss:     0.3026 Validation Accuracy: 0.926200\n",
      "Epoch  8, MNIST Batch 90: Loss:     0.3176 Validation Accuracy: 0.926400\n",
      "Epoch  8, MNIST Batch 91: Loss:     0.2992 Validation Accuracy: 0.925000\n",
      "Epoch  8, MNIST Batch 92: Loss:     0.3012 Validation Accuracy: 0.924800\n",
      "Epoch  8, MNIST Batch 93: Loss:     0.2895 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 94: Loss:     0.3177 Validation Accuracy: 0.924400\n",
      "Epoch  8, MNIST Batch 95: Loss:     0.3124 Validation Accuracy: 0.924200\n",
      "Epoch  8, MNIST Batch 96: Loss:     0.2692 Validation Accuracy: 0.924600\n",
      "Epoch  8, MNIST Batch 97: Loss:     0.3081 Validation Accuracy: 0.925200\n",
      "Epoch  8, MNIST Batch 98: Loss:     0.3652 Validation Accuracy: 0.925000\n",
      "Epoch  8, MNIST Batch 99: Loss:     0.3006 Validation Accuracy: 0.925200\n",
      "Epoch  8, MNIST Batch 100: Loss:     0.2757 Validation Accuracy: 0.925400\n",
      "Epoch  8, MNIST Batch 101: Loss:     0.3451 Validation Accuracy: 0.926600\n",
      "Epoch  8, MNIST Batch 102: Loss:     0.2893 Validation Accuracy: 0.926800\n",
      "Epoch  8, MNIST Batch 103: Loss:     0.2962 Validation Accuracy: 0.927200\n",
      "Epoch  8, MNIST Batch 104: Loss:     0.2537 Validation Accuracy: 0.927200\n",
      "Epoch  8, MNIST Batch 105: Loss:     0.2458 Validation Accuracy: 0.927400\n",
      "Epoch  8, MNIST Batch 106: Loss:     0.2589 Validation Accuracy: 0.926600\n",
      "Epoch  9, MNIST Batch 0: Loss:     0.2895 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 1: Loss:     0.3034 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 2: Loss:     0.2931 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 3: Loss:     0.2633 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 4: Loss:     0.3505 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 5: Loss:     0.3443 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 6: Loss:     0.2462 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 7: Loss:     0.3161 Validation Accuracy: 0.926600\n",
      "Epoch  9, MNIST Batch 8: Loss:     0.2921 Validation Accuracy: 0.926600\n",
      "Epoch  9, MNIST Batch 9: Loss:     0.2809 Validation Accuracy: 0.926600\n",
      "Epoch  9, MNIST Batch 10: Loss:     0.3041 Validation Accuracy: 0.926600\n",
      "Epoch  9, MNIST Batch 11: Loss:     0.3108 Validation Accuracy: 0.926800\n",
      "Epoch  9, MNIST Batch 12: Loss:     0.3397 Validation Accuracy: 0.927200\n",
      "Epoch  9, MNIST Batch 13: Loss:     0.2763 Validation Accuracy: 0.927600\n",
      "Epoch  9, MNIST Batch 14: Loss:     0.2678 Validation Accuracy: 0.927600\n",
      "Epoch  9, MNIST Batch 15: Loss:     0.2828 Validation Accuracy: 0.928000\n",
      "Epoch  9, MNIST Batch 16: Loss:     0.2872 Validation Accuracy: 0.928400\n",
      "Epoch  9, MNIST Batch 17: Loss:     0.2710 Validation Accuracy: 0.928800\n",
      "Epoch  9, MNIST Batch 18: Loss:     0.3002 Validation Accuracy: 0.928600\n",
      "Epoch  9, MNIST Batch 19: Loss:     0.3119 Validation Accuracy: 0.928400\n",
      "Epoch  9, MNIST Batch 20: Loss:     0.2652 Validation Accuracy: 0.928600\n",
      "Epoch  9, MNIST Batch 21: Loss:     0.3309 Validation Accuracy: 0.928200\n",
      "Epoch  9, MNIST Batch 22: Loss:     0.2797 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 23: Loss:     0.3038 Validation Accuracy: 0.928200\n",
      "Epoch  9, MNIST Batch 24: Loss:     0.2359 Validation Accuracy: 0.928200\n",
      "Epoch  9, MNIST Batch 25: Loss:     0.2777 Validation Accuracy: 0.928400\n",
      "Epoch  9, MNIST Batch 26: Loss:     0.2385 Validation Accuracy: 0.927600\n",
      "Epoch  9, MNIST Batch 27: Loss:     0.2762 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 28: Loss:     0.2916 Validation Accuracy: 0.927600\n",
      "Epoch  9, MNIST Batch 29: Loss:     0.2376 Validation Accuracy: 0.928000\n",
      "Epoch  9, MNIST Batch 30: Loss:     0.3113 Validation Accuracy: 0.928200\n",
      "Epoch  9, MNIST Batch 31: Loss:     0.3231 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 32: Loss:     0.3095 Validation Accuracy: 0.927200\n",
      "Epoch  9, MNIST Batch 33: Loss:     0.2960 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 34: Loss:     0.2801 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 35: Loss:     0.3143 Validation Accuracy: 0.928000\n",
      "Epoch  9, MNIST Batch 36: Loss:     0.3105 Validation Accuracy: 0.928000\n",
      "Epoch  9, MNIST Batch 37: Loss:     0.2764 Validation Accuracy: 0.928400\n",
      "Epoch  9, MNIST Batch 38: Loss:     0.3065 Validation Accuracy: 0.928600\n",
      "Epoch  9, MNIST Batch 39: Loss:     0.3058 Validation Accuracy: 0.929200\n",
      "Epoch  9, MNIST Batch 40: Loss:     0.3229 Validation Accuracy: 0.929600\n",
      "Epoch  9, MNIST Batch 41: Loss:     0.2722 Validation Accuracy: 0.929000\n",
      "Epoch  9, MNIST Batch 42: Loss:     0.3014 Validation Accuracy: 0.928800\n",
      "Epoch  9, MNIST Batch 43: Loss:     0.3019 Validation Accuracy: 0.928800\n",
      "Epoch  9, MNIST Batch 44: Loss:     0.3016 Validation Accuracy: 0.929400\n",
      "Epoch  9, MNIST Batch 45: Loss:     0.3291 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 46: Loss:     0.2677 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 47: Loss:     0.2922 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 48: Loss:     0.2565 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 49: Loss:     0.2170 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 50: Loss:     0.2820 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 51: Loss:     0.2897 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 52: Loss:     0.2606 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 53: Loss:     0.2731 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 54: Loss:     0.2544 Validation Accuracy: 0.929200\n",
      "Epoch  9, MNIST Batch 55: Loss:     0.2524 Validation Accuracy: 0.929200\n",
      "Epoch  9, MNIST Batch 56: Loss:     0.2623 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 57: Loss:     0.2668 Validation Accuracy: 0.927800\n",
      "Epoch  9, MNIST Batch 58: Loss:     0.2603 Validation Accuracy: 0.928000\n",
      "Epoch  9, MNIST Batch 59: Loss:     0.2826 Validation Accuracy: 0.928800\n",
      "Epoch  9, MNIST Batch 60: Loss:     0.2875 Validation Accuracy: 0.929600\n",
      "Epoch  9, MNIST Batch 61: Loss:     0.2447 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 62: Loss:     0.2821 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 63: Loss:     0.2673 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 64: Loss:     0.2694 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 65: Loss:     0.2925 Validation Accuracy: 0.929800\n",
      "Epoch  9, MNIST Batch 66: Loss:     0.2733 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 67: Loss:     0.2922 Validation Accuracy: 0.929400\n",
      "Epoch  9, MNIST Batch 68: Loss:     0.2951 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 69: Loss:     0.3241 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 70: Loss:     0.2864 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 71: Loss:     0.2479 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 72: Loss:     0.2057 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 73: Loss:     0.2430 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 74: Loss:     0.2737 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 75: Loss:     0.2912 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 76: Loss:     0.2522 Validation Accuracy: 0.929600\n",
      "Epoch  9, MNIST Batch 77: Loss:     0.2435 Validation Accuracy: 0.930000\n",
      "Epoch  9, MNIST Batch 78: Loss:     0.3051 Validation Accuracy: 0.930400\n",
      "Epoch  9, MNIST Batch 79: Loss:     0.2936 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 80: Loss:     0.2620 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 81: Loss:     0.2390 Validation Accuracy: 0.930400\n",
      "Epoch  9, MNIST Batch 82: Loss:     0.2651 Validation Accuracy: 0.931000\n",
      "Epoch  9, MNIST Batch 83: Loss:     0.2358 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 84: Loss:     0.2567 Validation Accuracy: 0.931200\n",
      "Epoch  9, MNIST Batch 85: Loss:     0.2682 Validation Accuracy: 0.931200\n",
      "Epoch  9, MNIST Batch 86: Loss:     0.2348 Validation Accuracy: 0.931400\n",
      "Epoch  9, MNIST Batch 87: Loss:     0.2836 Validation Accuracy: 0.931000\n",
      "Epoch  9, MNIST Batch 88: Loss:     0.2952 Validation Accuracy: 0.931600\n",
      "Epoch  9, MNIST Batch 89: Loss:     0.2856 Validation Accuracy: 0.931600\n",
      "Epoch  9, MNIST Batch 90: Loss:     0.2947 Validation Accuracy: 0.931400\n",
      "Epoch  9, MNIST Batch 91: Loss:     0.2538 Validation Accuracy: 0.931200\n",
      "Epoch  9, MNIST Batch 92: Loss:     0.2376 Validation Accuracy: 0.931400\n",
      "Epoch  9, MNIST Batch 93: Loss:     0.2679 Validation Accuracy: 0.931000\n",
      "Epoch  9, MNIST Batch 94: Loss:     0.2484 Validation Accuracy: 0.930600\n",
      "Epoch  9, MNIST Batch 95: Loss:     0.2994 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 96: Loss:     0.2398 Validation Accuracy: 0.931400\n",
      "Epoch  9, MNIST Batch 97: Loss:     0.2574 Validation Accuracy: 0.931200\n",
      "Epoch  9, MNIST Batch 98: Loss:     0.2977 Validation Accuracy: 0.931000\n",
      "Epoch  9, MNIST Batch 99: Loss:     0.2692 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 100: Loss:     0.2865 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 101: Loss:     0.2304 Validation Accuracy: 0.930800\n",
      "Epoch  9, MNIST Batch 102: Loss:     0.2282 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 103: Loss:     0.3869 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 104: Loss:     0.2911 Validation Accuracy: 0.930200\n",
      "Epoch  9, MNIST Batch 105: Loss:     0.2853 Validation Accuracy: 0.930400\n",
      "Epoch  9, MNIST Batch 106: Loss:     0.2505 Validation Accuracy: 0.930400\n",
      "Epoch 10, MNIST Batch 0: Loss:     0.2764 Validation Accuracy: 0.930800\n",
      "Epoch 10, MNIST Batch 1: Loss:     0.3392 Validation Accuracy: 0.930800\n",
      "Epoch 10, MNIST Batch 2: Loss:     0.2434 Validation Accuracy: 0.931600\n",
      "Epoch 10, MNIST Batch 3: Loss:     0.3165 Validation Accuracy: 0.931400\n",
      "Epoch 10, MNIST Batch 4: Loss:     0.2681 Validation Accuracy: 0.931400\n",
      "Epoch 10, MNIST Batch 5: Loss:     0.2385 Validation Accuracy: 0.931000\n",
      "Epoch 10, MNIST Batch 6: Loss:     0.2534 Validation Accuracy: 0.932400\n",
      "Epoch 10, MNIST Batch 7: Loss:     0.2508 Validation Accuracy: 0.932600\n",
      "Epoch 10, MNIST Batch 8: Loss:     0.2871 Validation Accuracy: 0.931600\n",
      "Epoch 10, MNIST Batch 9: Loss:     0.2362 Validation Accuracy: 0.931600\n",
      "Epoch 10, MNIST Batch 10: Loss:     0.2822 Validation Accuracy: 0.932000\n",
      "Epoch 10, MNIST Batch 11: Loss:     0.2647 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 12: Loss:     0.2324 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 13: Loss:     0.3474 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 14: Loss:     0.2329 Validation Accuracy: 0.933600\n",
      "Epoch 10, MNIST Batch 15: Loss:     0.2981 Validation Accuracy: 0.933400\n",
      "Epoch 10, MNIST Batch 16: Loss:     0.2352 Validation Accuracy: 0.933400\n",
      "Epoch 10, MNIST Batch 17: Loss:     0.2426 Validation Accuracy: 0.932200\n",
      "Epoch 10, MNIST Batch 18: Loss:     0.2477 Validation Accuracy: 0.932200\n",
      "Epoch 10, MNIST Batch 19: Loss:     0.2773 Validation Accuracy: 0.932800\n",
      "Epoch 10, MNIST Batch 20: Loss:     0.3128 Validation Accuracy: 0.932600\n",
      "Epoch 10, MNIST Batch 21: Loss:     0.2534 Validation Accuracy: 0.932000\n",
      "Epoch 10, MNIST Batch 22: Loss:     0.2007 Validation Accuracy: 0.931000\n",
      "Epoch 10, MNIST Batch 23: Loss:     0.2804 Validation Accuracy: 0.930600\n",
      "Epoch 10, MNIST Batch 24: Loss:     0.2785 Validation Accuracy: 0.930800\n",
      "Epoch 10, MNIST Batch 25: Loss:     0.2888 Validation Accuracy: 0.930200\n",
      "Epoch 10, MNIST Batch 26: Loss:     0.2960 Validation Accuracy: 0.930600\n",
      "Epoch 10, MNIST Batch 27: Loss:     0.3040 Validation Accuracy: 0.930000\n",
      "Epoch 10, MNIST Batch 28: Loss:     0.2193 Validation Accuracy: 0.930600\n",
      "Epoch 10, MNIST Batch 29: Loss:     0.2468 Validation Accuracy: 0.930800\n",
      "Epoch 10, MNIST Batch 30: Loss:     0.2698 Validation Accuracy: 0.931200\n",
      "Epoch 10, MNIST Batch 31: Loss:     0.2282 Validation Accuracy: 0.931600\n",
      "Epoch 10, MNIST Batch 32: Loss:     0.2385 Validation Accuracy: 0.931800\n",
      "Epoch 10, MNIST Batch 33: Loss:     0.2872 Validation Accuracy: 0.932400\n",
      "Epoch 10, MNIST Batch 34: Loss:     0.2888 Validation Accuracy: 0.932000\n",
      "Epoch 10, MNIST Batch 35: Loss:     0.2335 Validation Accuracy: 0.932800\n",
      "Epoch 10, MNIST Batch 36: Loss:     0.2574 Validation Accuracy: 0.933000\n",
      "Epoch 10, MNIST Batch 37: Loss:     0.2821 Validation Accuracy: 0.933000\n",
      "Epoch 10, MNIST Batch 38: Loss:     0.2768 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 39: Loss:     0.2559 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 40: Loss:     0.2462 Validation Accuracy: 0.933000\n",
      "Epoch 10, MNIST Batch 41: Loss:     0.3548 Validation Accuracy: 0.932600\n",
      "Epoch 10, MNIST Batch 42: Loss:     0.2348 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 43: Loss:     0.2745 Validation Accuracy: 0.933400\n",
      "Epoch 10, MNIST Batch 44: Loss:     0.2440 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 45: Loss:     0.2331 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 46: Loss:     0.2686 Validation Accuracy: 0.932400\n",
      "Epoch 10, MNIST Batch 47: Loss:     0.2223 Validation Accuracy: 0.932800\n",
      "Epoch 10, MNIST Batch 48: Loss:     0.2233 Validation Accuracy: 0.932800\n",
      "Epoch 10, MNIST Batch 49: Loss:     0.2620 Validation Accuracy: 0.933000\n",
      "Epoch 10, MNIST Batch 50: Loss:     0.2721 Validation Accuracy: 0.933000\n",
      "Epoch 10, MNIST Batch 51: Loss:     0.3088 Validation Accuracy: 0.933200\n",
      "Epoch 10, MNIST Batch 52: Loss:     0.2849 Validation Accuracy: 0.933600\n",
      "Epoch 10, MNIST Batch 53: Loss:     0.2279 Validation Accuracy: 0.933600\n",
      "Epoch 10, MNIST Batch 54: Loss:     0.2601 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 55: Loss:     0.2387 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 56: Loss:     0.3026 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 57: Loss:     0.2780 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 58: Loss:     0.3125 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 59: Loss:     0.2810 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 60: Loss:     0.3246 Validation Accuracy: 0.934800\n",
      "Epoch 10, MNIST Batch 61: Loss:     0.2493 Validation Accuracy: 0.934800\n",
      "Epoch 10, MNIST Batch 62: Loss:     0.2551 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 63: Loss:     0.2690 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 64: Loss:     0.2390 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 65: Loss:     0.2329 Validation Accuracy: 0.935000\n",
      "Epoch 10, MNIST Batch 66: Loss:     0.3309 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 67: Loss:     0.3214 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 68: Loss:     0.2205 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 69: Loss:     0.2792 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 70: Loss:     0.2625 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 71: Loss:     0.2346 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 72: Loss:     0.2894 Validation Accuracy: 0.934800\n",
      "Epoch 10, MNIST Batch 73: Loss:     0.2058 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 74: Loss:     0.2280 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 75: Loss:     0.2291 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 76: Loss:     0.2589 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 77: Loss:     0.2274 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 78: Loss:     0.3073 Validation Accuracy: 0.933600\n",
      "Epoch 10, MNIST Batch 79: Loss:     0.2887 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 80: Loss:     0.2041 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 81: Loss:     0.2596 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 82: Loss:     0.2587 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 83: Loss:     0.2831 Validation Accuracy: 0.933600\n",
      "Epoch 10, MNIST Batch 84: Loss:     0.2428 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 85: Loss:     0.2310 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 86: Loss:     0.2294 Validation Accuracy: 0.934000\n",
      "Epoch 10, MNIST Batch 87: Loss:     0.2535 Validation Accuracy: 0.933800\n",
      "Epoch 10, MNIST Batch 88: Loss:     0.2457 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 89: Loss:     0.2938 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 90: Loss:     0.2446 Validation Accuracy: 0.934800\n",
      "Epoch 10, MNIST Batch 91: Loss:     0.2330 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 92: Loss:     0.2058 Validation Accuracy: 0.935200\n",
      "Epoch 10, MNIST Batch 93: Loss:     0.2542 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 94: Loss:     0.2325 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 95: Loss:     0.2886 Validation Accuracy: 0.934600\n",
      "Epoch 10, MNIST Batch 96: Loss:     0.2132 Validation Accuracy: 0.934200\n",
      "Epoch 10, MNIST Batch 97: Loss:     0.2211 Validation Accuracy: 0.934400\n",
      "Epoch 10, MNIST Batch 98: Loss:     0.2788 Validation Accuracy: 0.935000\n",
      "Epoch 10, MNIST Batch 99: Loss:     0.2264 Validation Accuracy: 0.935800\n",
      "Epoch 10, MNIST Batch 100: Loss:     0.2831 Validation Accuracy: 0.936000\n",
      "Epoch 10, MNIST Batch 101: Loss:     0.2054 Validation Accuracy: 0.936400\n",
      "Epoch 10, MNIST Batch 102: Loss:     0.2117 Validation Accuracy: 0.936800\n",
      "Epoch 10, MNIST Batch 103: Loss:     0.2721 Validation Accuracy: 0.936600\n",
      "Epoch 10, MNIST Batch 104: Loss:     0.2160 Validation Accuracy: 0.937000\n",
      "Epoch 10, MNIST Batch 105: Loss:     0.3179 Validation Accuracy: 0.937200\n",
      "Epoch 10, MNIST Batch 106: Loss:     0.2846 Validation Accuracy: 0.937000\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './numbers_network_model'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables]\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            batch_features = batch[0].reshape((-1, 28, 28, 1))\n",
    "            batch_labels = batch[1]\n",
    "            train_neural_network(sess, optimizer, batch_features, batch_labels)\n",
    "            \n",
    "            print_training_stats(sess, epoch, i, \n",
    "                                 batch_features, batch_labels, \n",
    "                                 mnist.validation.images.reshape((-1, 28, 28, 1)), mnist.validation.labels,\n",
    "                                 cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testing the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Testing helpers\n",
    "\n",
    "def display_image_predictions(features, labels, predictions, n_classes):\n",
    "   \n",
    "    label_names = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=3)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "        axies[image_i][0].imshow(feature.reshape((feature.shape[0],feature.shape[1])))\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./numbers_network_model\n",
      "Testing Accuracy: 0.935546875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAAJ/CAYAAADRS4SdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf4c4464e0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 391
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    test_features = mnist.test.images.reshape((-1, 28, 28, 1))\n",
    "    test_labels = mnist.test.labels\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Getting Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for i in range(mnist.test.num_examples//batch_size):\n",
    "            batch = mnist.test.next_batch(batch_size)\n",
    "            test_feature_batch = batch[0].reshape((-1, 28, 28, 1))\n",
    "            test_label_batch = batch[1]\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0 })\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions, 10)\n",
    "        sess.close()\n",
    "test_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
