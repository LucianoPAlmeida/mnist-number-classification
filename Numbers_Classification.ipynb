{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualizing an image data set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkNTfAMTH3ba7J46EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feff243f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "label = mnist.train.labels[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(inputs, keep_prob):\n",
    "    conv = tf.layers.conv2d(inputs, 32, (5,5), padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    conv = tf.layers.max_pooling2d(conv,(2,2), padding='same')\n",
    "\n",
    "    conv = tf.layers.conv2d(conv, 64, (5,5), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    conv = tf.layers.max_pooling2d(conv,(2,2), padding='same')\n",
    "        \n",
    "    conv = tf.contrib.layers.flatten(conv)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 1024, activation_fn=tf.nn.relu)\n",
    "        \n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "\n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10, activation_fn=None)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max_pooling2d() missing 1 required positional argument: 'strides'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-f9c41424891c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-200-3d372a49c89f>\u001b[0m in \u001b[0;36mconv_net\u001b[0;34m(inputs, keep_prob)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: max_pooling2d() missing 1 required positional argument: 'strides'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='x')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='y')\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Network training hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 512\n",
    "keep_probability = 0.5\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Training helper functions    \n",
    "\n",
    "def train_neural_network(session, optimizer, keep_probability, learning_rate, feature_batch, label_batch):\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability,\n",
    "        lr: learning_rate\n",
    "    })\n",
    "    \n",
    "def print_training_stats(session, epoch, batch_i, feature_batch, label_batch, validation_feature, validation_label, cost, accuracy):\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x: validation_feature,\n",
    "                y: validation_label,\n",
    "                keep_prob: 1.0 })\n",
    "    print('Epoch {:>2}, MNIST Batch {}: Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch + 1, batch_i, loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, MNIST Batch 0: Loss:     2.2997 Validation Accuracy: 0.047000\n",
      "Epoch  1, MNIST Batch 1: Loss:     2.3024 Validation Accuracy: 0.051200\n",
      "Epoch  1, MNIST Batch 2: Loss:     2.3032 Validation Accuracy: 0.057800\n",
      "Epoch  1, MNIST Batch 3: Loss:     2.2961 Validation Accuracy: 0.066000\n",
      "Epoch  1, MNIST Batch 4: Loss:     2.2896 Validation Accuracy: 0.076400\n",
      "Epoch  1, MNIST Batch 5: Loss:     2.2904 Validation Accuracy: 0.086400\n",
      "Epoch  1, MNIST Batch 6: Loss:     2.2876 Validation Accuracy: 0.095600\n",
      "Epoch  1, MNIST Batch 7: Loss:     2.2890 Validation Accuracy: 0.109200\n",
      "Epoch  1, MNIST Batch 8: Loss:     2.2794 Validation Accuracy: 0.121400\n",
      "Epoch  1, MNIST Batch 9: Loss:     2.2785 Validation Accuracy: 0.139400\n",
      "Epoch  1, MNIST Batch 10: Loss:     2.2732 Validation Accuracy: 0.155200\n",
      "Epoch  1, MNIST Batch 11: Loss:     2.2686 Validation Accuracy: 0.170800\n",
      "Epoch  1, MNIST Batch 12: Loss:     2.2768 Validation Accuracy: 0.188000\n",
      "Epoch  1, MNIST Batch 13: Loss:     2.2665 Validation Accuracy: 0.199400\n",
      "Epoch  1, MNIST Batch 14: Loss:     2.2708 Validation Accuracy: 0.210200\n",
      "Epoch  1, MNIST Batch 15: Loss:     2.2623 Validation Accuracy: 0.223000\n",
      "Epoch  1, MNIST Batch 16: Loss:     2.2619 Validation Accuracy: 0.236800\n",
      "Epoch  1, MNIST Batch 17: Loss:     2.2658 Validation Accuracy: 0.247600\n",
      "Epoch  1, MNIST Batch 18: Loss:     2.2581 Validation Accuracy: 0.260000\n",
      "Epoch  1, MNIST Batch 19: Loss:     2.2534 Validation Accuracy: 0.273800\n",
      "Epoch  1, MNIST Batch 20: Loss:     2.2516 Validation Accuracy: 0.287800\n",
      "Epoch  1, MNIST Batch 21: Loss:     2.2459 Validation Accuracy: 0.302400\n",
      "Epoch  1, MNIST Batch 22: Loss:     2.2515 Validation Accuracy: 0.314200\n",
      "Epoch  1, MNIST Batch 23: Loss:     2.2432 Validation Accuracy: 0.323600\n",
      "Epoch  1, MNIST Batch 24: Loss:     2.2421 Validation Accuracy: 0.330200\n",
      "Epoch  1, MNIST Batch 25: Loss:     2.2389 Validation Accuracy: 0.337800\n",
      "Epoch  1, MNIST Batch 26: Loss:     2.2391 Validation Accuracy: 0.349600\n",
      "Epoch  1, MNIST Batch 27: Loss:     2.2354 Validation Accuracy: 0.357800\n",
      "Epoch  1, MNIST Batch 28: Loss:     2.2281 Validation Accuracy: 0.369200\n",
      "Epoch  1, MNIST Batch 29: Loss:     2.2274 Validation Accuracy: 0.377800\n",
      "Epoch  1, MNIST Batch 30: Loss:     2.2190 Validation Accuracy: 0.384800\n",
      "Epoch  1, MNIST Batch 31: Loss:     2.2199 Validation Accuracy: 0.388200\n",
      "Epoch  1, MNIST Batch 32: Loss:     2.2174 Validation Accuracy: 0.390200\n",
      "Epoch  1, MNIST Batch 33: Loss:     2.2169 Validation Accuracy: 0.397600\n",
      "Epoch  1, MNIST Batch 34: Loss:     2.2123 Validation Accuracy: 0.401000\n",
      "Epoch  1, MNIST Batch 35: Loss:     2.2092 Validation Accuracy: 0.407000\n",
      "Epoch  1, MNIST Batch 36: Loss:     2.2121 Validation Accuracy: 0.416200\n",
      "Epoch  1, MNIST Batch 37: Loss:     2.1978 Validation Accuracy: 0.423000\n",
      "Epoch  1, MNIST Batch 38: Loss:     2.2037 Validation Accuracy: 0.430200\n",
      "Epoch  1, MNIST Batch 39: Loss:     2.1970 Validation Accuracy: 0.435200\n",
      "Epoch  1, MNIST Batch 40: Loss:     2.2005 Validation Accuracy: 0.446600\n",
      "Epoch  1, MNIST Batch 41: Loss:     2.1983 Validation Accuracy: 0.453200\n",
      "Epoch  1, MNIST Batch 42: Loss:     2.1932 Validation Accuracy: 0.462200\n",
      "Epoch  1, MNIST Batch 43: Loss:     2.1905 Validation Accuracy: 0.471800\n",
      "Epoch  1, MNIST Batch 44: Loss:     2.1903 Validation Accuracy: 0.479000\n",
      "Epoch  1, MNIST Batch 45: Loss:     2.1829 Validation Accuracy: 0.490400\n",
      "Epoch  1, MNIST Batch 46: Loss:     2.1798 Validation Accuracy: 0.498000\n",
      "Epoch  1, MNIST Batch 47: Loss:     2.1777 Validation Accuracy: 0.507200\n",
      "Epoch  1, MNIST Batch 48: Loss:     2.1753 Validation Accuracy: 0.516000\n",
      "Epoch  1, MNIST Batch 49: Loss:     2.1695 Validation Accuracy: 0.527000\n",
      "Epoch  1, MNIST Batch 50: Loss:     2.1695 Validation Accuracy: 0.534000\n",
      "Epoch  1, MNIST Batch 51: Loss:     2.1639 Validation Accuracy: 0.546600\n",
      "Epoch  1, MNIST Batch 52: Loss:     2.1609 Validation Accuracy: 0.554400\n",
      "Epoch  1, MNIST Batch 53: Loss:     2.1496 Validation Accuracy: 0.562200\n",
      "Epoch  1, MNIST Batch 54: Loss:     2.1511 Validation Accuracy: 0.569800\n",
      "Epoch  1, MNIST Batch 55: Loss:     2.1478 Validation Accuracy: 0.576800\n",
      "Epoch  1, MNIST Batch 56: Loss:     2.1486 Validation Accuracy: 0.584200\n",
      "Epoch  1, MNIST Batch 57: Loss:     2.1448 Validation Accuracy: 0.589800\n",
      "Epoch  1, MNIST Batch 58: Loss:     2.1480 Validation Accuracy: 0.597800\n",
      "Epoch  1, MNIST Batch 59: Loss:     2.1455 Validation Accuracy: 0.608000\n",
      "Epoch  1, MNIST Batch 60: Loss:     2.1316 Validation Accuracy: 0.617600\n",
      "Epoch  1, MNIST Batch 61: Loss:     2.1376 Validation Accuracy: 0.626600\n",
      "Epoch  1, MNIST Batch 62: Loss:     2.1286 Validation Accuracy: 0.636200\n",
      "Epoch  1, MNIST Batch 63: Loss:     2.1264 Validation Accuracy: 0.645000\n",
      "Epoch  1, MNIST Batch 64: Loss:     2.1299 Validation Accuracy: 0.649600\n",
      "Epoch  1, MNIST Batch 65: Loss:     2.1190 Validation Accuracy: 0.658000\n",
      "Epoch  1, MNIST Batch 66: Loss:     2.1113 Validation Accuracy: 0.663800\n",
      "Epoch  1, MNIST Batch 67: Loss:     2.1111 Validation Accuracy: 0.668800\n",
      "Epoch  1, MNIST Batch 68: Loss:     2.1072 Validation Accuracy: 0.675400\n",
      "Epoch  1, MNIST Batch 69: Loss:     2.1013 Validation Accuracy: 0.680400\n",
      "Epoch  1, MNIST Batch 70: Loss:     2.0961 Validation Accuracy: 0.682000\n",
      "Epoch  1, MNIST Batch 71: Loss:     2.0970 Validation Accuracy: 0.685600\n",
      "Epoch  1, MNIST Batch 72: Loss:     2.0940 Validation Accuracy: 0.687800\n",
      "Epoch  1, MNIST Batch 73: Loss:     2.0823 Validation Accuracy: 0.692200\n",
      "Epoch  1, MNIST Batch 74: Loss:     2.0824 Validation Accuracy: 0.696600\n",
      "Epoch  1, MNIST Batch 75: Loss:     2.0663 Validation Accuracy: 0.700600\n",
      "Epoch  1, MNIST Batch 76: Loss:     2.0807 Validation Accuracy: 0.704000\n",
      "Epoch  1, MNIST Batch 77: Loss:     2.0732 Validation Accuracy: 0.706800\n",
      "Epoch  1, MNIST Batch 78: Loss:     2.0520 Validation Accuracy: 0.708800\n",
      "Epoch  1, MNIST Batch 79: Loss:     2.0653 Validation Accuracy: 0.710000\n",
      "Epoch  1, MNIST Batch 80: Loss:     2.0587 Validation Accuracy: 0.711600\n",
      "Epoch  1, MNIST Batch 81: Loss:     2.0509 Validation Accuracy: 0.715200\n",
      "Epoch  1, MNIST Batch 82: Loss:     2.0617 Validation Accuracy: 0.717600\n",
      "Epoch  1, MNIST Batch 83: Loss:     2.0387 Validation Accuracy: 0.720400\n",
      "Epoch  1, MNIST Batch 84: Loss:     2.0446 Validation Accuracy: 0.722600\n",
      "Epoch  1, MNIST Batch 85: Loss:     2.0471 Validation Accuracy: 0.727200\n",
      "Epoch  1, MNIST Batch 86: Loss:     2.0356 Validation Accuracy: 0.731400\n",
      "Epoch  1, MNIST Batch 87: Loss:     2.0328 Validation Accuracy: 0.733400\n",
      "Epoch  1, MNIST Batch 88: Loss:     2.0348 Validation Accuracy: 0.736000\n",
      "Epoch  1, MNIST Batch 89: Loss:     2.0192 Validation Accuracy: 0.740000\n",
      "Epoch  1, MNIST Batch 90: Loss:     2.0206 Validation Accuracy: 0.742600\n",
      "Epoch  1, MNIST Batch 91: Loss:     2.0129 Validation Accuracy: 0.745000\n",
      "Epoch  1, MNIST Batch 92: Loss:     1.9980 Validation Accuracy: 0.748000\n",
      "Epoch  1, MNIST Batch 93: Loss:     2.0171 Validation Accuracy: 0.751800\n",
      "Epoch  1, MNIST Batch 94: Loss:     1.9975 Validation Accuracy: 0.756600\n",
      "Epoch  1, MNIST Batch 95: Loss:     2.0017 Validation Accuracy: 0.759200\n",
      "Epoch  1, MNIST Batch 96: Loss:     1.9813 Validation Accuracy: 0.762600\n",
      "Epoch  1, MNIST Batch 97: Loss:     2.0022 Validation Accuracy: 0.765200\n",
      "Epoch  1, MNIST Batch 98: Loss:     1.9822 Validation Accuracy: 0.768800\n",
      "Epoch  1, MNIST Batch 99: Loss:     1.9726 Validation Accuracy: 0.770800\n",
      "Epoch  1, MNIST Batch 100: Loss:     1.9635 Validation Accuracy: 0.772200\n",
      "Epoch  1, MNIST Batch 101: Loss:     1.9664 Validation Accuracy: 0.774600\n",
      "Epoch  1, MNIST Batch 102: Loss:     1.9601 Validation Accuracy: 0.777200\n",
      "Epoch  1, MNIST Batch 103: Loss:     1.9597 Validation Accuracy: 0.779600\n",
      "Epoch  1, MNIST Batch 104: Loss:     1.9469 Validation Accuracy: 0.780400\n",
      "Epoch  1, MNIST Batch 105: Loss:     1.9602 Validation Accuracy: 0.781000\n",
      "Epoch  1, MNIST Batch 106: Loss:     1.9580 Validation Accuracy: 0.781600\n",
      "Epoch  2, MNIST Batch 0: Loss:     1.9298 Validation Accuracy: 0.782600\n",
      "Epoch  2, MNIST Batch 1: Loss:     1.9242 Validation Accuracy: 0.784600\n",
      "Epoch  2, MNIST Batch 2: Loss:     1.9368 Validation Accuracy: 0.786400\n",
      "Epoch  2, MNIST Batch 3: Loss:     1.9261 Validation Accuracy: 0.789000\n",
      "Epoch  2, MNIST Batch 4: Loss:     1.9199 Validation Accuracy: 0.791800\n",
      "Epoch  2, MNIST Batch 5: Loss:     1.9314 Validation Accuracy: 0.795000\n",
      "Epoch  2, MNIST Batch 6: Loss:     1.8915 Validation Accuracy: 0.797000\n",
      "Epoch  2, MNIST Batch 7: Loss:     1.8894 Validation Accuracy: 0.797600\n",
      "Epoch  2, MNIST Batch 8: Loss:     1.9050 Validation Accuracy: 0.800000\n",
      "Epoch  2, MNIST Batch 9: Loss:     1.8901 Validation Accuracy: 0.800000\n",
      "Epoch  2, MNIST Batch 10: Loss:     1.8988 Validation Accuracy: 0.799000\n",
      "Epoch  2, MNIST Batch 11: Loss:     1.9104 Validation Accuracy: 0.798600\n",
      "Epoch  2, MNIST Batch 12: Loss:     1.8929 Validation Accuracy: 0.799800\n",
      "Epoch  2, MNIST Batch 13: Loss:     1.9038 Validation Accuracy: 0.801400\n",
      "Epoch  2, MNIST Batch 14: Loss:     1.8568 Validation Accuracy: 0.802000\n",
      "Epoch  2, MNIST Batch 15: Loss:     1.8714 Validation Accuracy: 0.802600\n",
      "Epoch  2, MNIST Batch 16: Loss:     1.8586 Validation Accuracy: 0.803200\n",
      "Epoch  2, MNIST Batch 17: Loss:     1.8497 Validation Accuracy: 0.802800\n",
      "Epoch  2, MNIST Batch 18: Loss:     1.8604 Validation Accuracy: 0.803200\n",
      "Epoch  2, MNIST Batch 19: Loss:     1.8396 Validation Accuracy: 0.803400\n",
      "Epoch  2, MNIST Batch 20: Loss:     1.8374 Validation Accuracy: 0.802600\n",
      "Epoch  2, MNIST Batch 21: Loss:     1.8350 Validation Accuracy: 0.802400\n",
      "Epoch  2, MNIST Batch 22: Loss:     1.8103 Validation Accuracy: 0.801400\n",
      "Epoch  2, MNIST Batch 23: Loss:     1.8345 Validation Accuracy: 0.801600\n",
      "Epoch  2, MNIST Batch 24: Loss:     1.8159 Validation Accuracy: 0.802400\n",
      "Epoch  2, MNIST Batch 25: Loss:     1.8243 Validation Accuracy: 0.801600\n",
      "Epoch  2, MNIST Batch 26: Loss:     1.8035 Validation Accuracy: 0.802200\n",
      "Epoch  2, MNIST Batch 27: Loss:     1.8057 Validation Accuracy: 0.802000\n",
      "Epoch  2, MNIST Batch 28: Loss:     1.7908 Validation Accuracy: 0.804600\n",
      "Epoch  2, MNIST Batch 29: Loss:     1.7996 Validation Accuracy: 0.804600\n",
      "Epoch  2, MNIST Batch 30: Loss:     1.8136 Validation Accuracy: 0.805400\n",
      "Epoch  2, MNIST Batch 31: Loss:     1.7623 Validation Accuracy: 0.804600\n",
      "Epoch  2, MNIST Batch 32: Loss:     1.7801 Validation Accuracy: 0.805400\n",
      "Epoch  2, MNIST Batch 33: Loss:     1.7849 Validation Accuracy: 0.805200\n",
      "Epoch  2, MNIST Batch 34: Loss:     1.7656 Validation Accuracy: 0.806200\n",
      "Epoch  2, MNIST Batch 35: Loss:     1.7587 Validation Accuracy: 0.807200\n",
      "Epoch  2, MNIST Batch 36: Loss:     1.7807 Validation Accuracy: 0.808600\n",
      "Epoch  2, MNIST Batch 37: Loss:     1.7400 Validation Accuracy: 0.811000\n",
      "Epoch  2, MNIST Batch 38: Loss:     1.7344 Validation Accuracy: 0.811400\n",
      "Epoch  2, MNIST Batch 39: Loss:     1.7286 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 40: Loss:     1.7242 Validation Accuracy: 0.813400\n",
      "Epoch  2, MNIST Batch 41: Loss:     1.7307 Validation Accuracy: 0.814800\n",
      "Epoch  2, MNIST Batch 42: Loss:     1.7224 Validation Accuracy: 0.815800\n",
      "Epoch  2, MNIST Batch 43: Loss:     1.7259 Validation Accuracy: 0.816000\n",
      "Epoch  2, MNIST Batch 44: Loss:     1.7133 Validation Accuracy: 0.817000\n",
      "Epoch  2, MNIST Batch 45: Loss:     1.7207 Validation Accuracy: 0.816000\n",
      "Epoch  2, MNIST Batch 46: Loss:     1.7108 Validation Accuracy: 0.817200\n",
      "Epoch  2, MNIST Batch 47: Loss:     1.6988 Validation Accuracy: 0.817000\n",
      "Epoch  2, MNIST Batch 48: Loss:     1.6701 Validation Accuracy: 0.816600\n",
      "Epoch  2, MNIST Batch 49: Loss:     1.6886 Validation Accuracy: 0.817200\n",
      "Epoch  2, MNIST Batch 50: Loss:     1.6727 Validation Accuracy: 0.816800\n",
      "Epoch  2, MNIST Batch 51: Loss:     1.6628 Validation Accuracy: 0.815200\n",
      "Epoch  2, MNIST Batch 52: Loss:     1.6417 Validation Accuracy: 0.814200\n",
      "Epoch  2, MNIST Batch 53: Loss:     1.6377 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 54: Loss:     1.6511 Validation Accuracy: 0.812200\n",
      "Epoch  2, MNIST Batch 55: Loss:     1.6156 Validation Accuracy: 0.811400\n",
      "Epoch  2, MNIST Batch 56: Loss:     1.6367 Validation Accuracy: 0.810800\n",
      "Epoch  2, MNIST Batch 57: Loss:     1.6592 Validation Accuracy: 0.809800\n",
      "Epoch  2, MNIST Batch 58: Loss:     1.6158 Validation Accuracy: 0.810400\n",
      "Epoch  2, MNIST Batch 59: Loss:     1.6141 Validation Accuracy: 0.810600\n",
      "Epoch  2, MNIST Batch 60: Loss:     1.6129 Validation Accuracy: 0.812000\n",
      "Epoch  2, MNIST Batch 61: Loss:     1.5956 Validation Accuracy: 0.813000\n",
      "Epoch  2, MNIST Batch 62: Loss:     1.6155 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 63: Loss:     1.5607 Validation Accuracy: 0.814400\n",
      "Epoch  2, MNIST Batch 64: Loss:     1.5653 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 65: Loss:     1.5642 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 66: Loss:     1.5701 Validation Accuracy: 0.813400\n",
      "Epoch  2, MNIST Batch 67: Loss:     1.5709 Validation Accuracy: 0.813000\n",
      "Epoch  2, MNIST Batch 68: Loss:     1.5865 Validation Accuracy: 0.812000\n",
      "Epoch  2, MNIST Batch 69: Loss:     1.5599 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 70: Loss:     1.5619 Validation Accuracy: 0.814000\n",
      "Epoch  2, MNIST Batch 71: Loss:     1.5497 Validation Accuracy: 0.812400\n",
      "Epoch  2, MNIST Batch 72: Loss:     1.5620 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 73: Loss:     1.5537 Validation Accuracy: 0.813600\n",
      "Epoch  2, MNIST Batch 74: Loss:     1.5455 Validation Accuracy: 0.813600\n",
      "Epoch  2, MNIST Batch 75: Loss:     1.5135 Validation Accuracy: 0.814200\n",
      "Epoch  2, MNIST Batch 76: Loss:     1.5313 Validation Accuracy: 0.814600\n",
      "Epoch  2, MNIST Batch 77: Loss:     1.4992 Validation Accuracy: 0.815800\n",
      "Epoch  2, MNIST Batch 78: Loss:     1.5129 Validation Accuracy: 0.816200\n",
      "Epoch  2, MNIST Batch 79: Loss:     1.4961 Validation Accuracy: 0.816000\n",
      "Epoch  2, MNIST Batch 80: Loss:     1.4781 Validation Accuracy: 0.814800\n",
      "Epoch  2, MNIST Batch 81: Loss:     1.4899 Validation Accuracy: 0.813600\n",
      "Epoch  2, MNIST Batch 82: Loss:     1.5002 Validation Accuracy: 0.815600\n",
      "Epoch  2, MNIST Batch 83: Loss:     1.4602 Validation Accuracy: 0.815600\n",
      "Epoch  2, MNIST Batch 84: Loss:     1.4432 Validation Accuracy: 0.816000\n",
      "Epoch  2, MNIST Batch 85: Loss:     1.4680 Validation Accuracy: 0.816600\n",
      "Epoch  2, MNIST Batch 86: Loss:     1.4718 Validation Accuracy: 0.816400\n",
      "Epoch  2, MNIST Batch 87: Loss:     1.4448 Validation Accuracy: 0.816400\n",
      "Epoch  2, MNIST Batch 88: Loss:     1.4572 Validation Accuracy: 0.815800\n",
      "Epoch  2, MNIST Batch 89: Loss:     1.4208 Validation Accuracy: 0.814200\n",
      "Epoch  2, MNIST Batch 90: Loss:     1.4255 Validation Accuracy: 0.813400\n",
      "Epoch  2, MNIST Batch 91: Loss:     1.4197 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 92: Loss:     1.4335 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 93: Loss:     1.3906 Validation Accuracy: 0.813000\n",
      "Epoch  2, MNIST Batch 94: Loss:     1.4185 Validation Accuracy: 0.813800\n",
      "Epoch  2, MNIST Batch 95: Loss:     1.4252 Validation Accuracy: 0.813600\n",
      "Epoch  2, MNIST Batch 96: Loss:     1.4198 Validation Accuracy: 0.813400\n",
      "Epoch  2, MNIST Batch 97: Loss:     1.4165 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 98: Loss:     1.3846 Validation Accuracy: 0.813200\n",
      "Epoch  2, MNIST Batch 99: Loss:     1.3820 Validation Accuracy: 0.814200\n",
      "Epoch  2, MNIST Batch 100: Loss:     1.3721 Validation Accuracy: 0.816200\n",
      "Epoch  2, MNIST Batch 101: Loss:     1.3951 Validation Accuracy: 0.817600\n",
      "Epoch  2, MNIST Batch 102: Loss:     1.3672 Validation Accuracy: 0.817000\n",
      "Epoch  2, MNIST Batch 103: Loss:     1.3507 Validation Accuracy: 0.818000\n",
      "Epoch  2, MNIST Batch 104: Loss:     1.3270 Validation Accuracy: 0.817800\n",
      "Epoch  2, MNIST Batch 105: Loss:     1.3650 Validation Accuracy: 0.819400\n",
      "Epoch  2, MNIST Batch 106: Loss:     1.3270 Validation Accuracy: 0.819200\n",
      "Epoch  3, MNIST Batch 0: Loss:     1.3386 Validation Accuracy: 0.820600\n",
      "Epoch  3, MNIST Batch 1: Loss:     1.3521 Validation Accuracy: 0.820800\n",
      "Epoch  3, MNIST Batch 2: Loss:     1.3235 Validation Accuracy: 0.820000\n",
      "Epoch  3, MNIST Batch 3: Loss:     1.3565 Validation Accuracy: 0.819400\n",
      "Epoch  3, MNIST Batch 4: Loss:     1.3131 Validation Accuracy: 0.818600\n",
      "Epoch  3, MNIST Batch 5: Loss:     1.3091 Validation Accuracy: 0.818600\n",
      "Epoch  3, MNIST Batch 6: Loss:     1.3085 Validation Accuracy: 0.818200\n",
      "Epoch  3, MNIST Batch 7: Loss:     1.3089 Validation Accuracy: 0.818400\n",
      "Epoch  3, MNIST Batch 8: Loss:     1.2980 Validation Accuracy: 0.817800\n",
      "Epoch  3, MNIST Batch 9: Loss:     1.2760 Validation Accuracy: 0.817800\n",
      "Epoch  3, MNIST Batch 10: Loss:     1.2868 Validation Accuracy: 0.817800\n",
      "Epoch  3, MNIST Batch 11: Loss:     1.2857 Validation Accuracy: 0.818000\n",
      "Epoch  3, MNIST Batch 12: Loss:     1.2465 Validation Accuracy: 0.818000\n",
      "Epoch  3, MNIST Batch 13: Loss:     1.2474 Validation Accuracy: 0.817800\n",
      "Epoch  3, MNIST Batch 14: Loss:     1.2671 Validation Accuracy: 0.818000\n",
      "Epoch  3, MNIST Batch 15: Loss:     1.2681 Validation Accuracy: 0.817400\n",
      "Epoch  3, MNIST Batch 16: Loss:     1.2586 Validation Accuracy: 0.818200\n",
      "Epoch  3, MNIST Batch 17: Loss:     1.2208 Validation Accuracy: 0.818000\n",
      "Epoch  3, MNIST Batch 18: Loss:     1.2755 Validation Accuracy: 0.817800\n",
      "Epoch  3, MNIST Batch 19: Loss:     1.2172 Validation Accuracy: 0.818800\n",
      "Epoch  3, MNIST Batch 20: Loss:     1.2616 Validation Accuracy: 0.819800\n",
      "Epoch  3, MNIST Batch 21: Loss:     1.1958 Validation Accuracy: 0.819800\n",
      "Epoch  3, MNIST Batch 22: Loss:     1.2081 Validation Accuracy: 0.820200\n",
      "Epoch  3, MNIST Batch 23: Loss:     1.2169 Validation Accuracy: 0.820600\n",
      "Epoch  3, MNIST Batch 24: Loss:     1.2120 Validation Accuracy: 0.821200\n",
      "Epoch  3, MNIST Batch 25: Loss:     1.1926 Validation Accuracy: 0.821600\n",
      "Epoch  3, MNIST Batch 26: Loss:     1.2016 Validation Accuracy: 0.821400\n",
      "Epoch  3, MNIST Batch 27: Loss:     1.1607 Validation Accuracy: 0.822600\n",
      "Epoch  3, MNIST Batch 28: Loss:     1.2241 Validation Accuracy: 0.823400\n",
      "Epoch  3, MNIST Batch 29: Loss:     1.1494 Validation Accuracy: 0.823200\n",
      "Epoch  3, MNIST Batch 30: Loss:     1.1853 Validation Accuracy: 0.824200\n",
      "Epoch  3, MNIST Batch 31: Loss:     1.1595 Validation Accuracy: 0.824800\n",
      "Epoch  3, MNIST Batch 32: Loss:     1.1763 Validation Accuracy: 0.825600\n",
      "Epoch  3, MNIST Batch 33: Loss:     1.1672 Validation Accuracy: 0.825000\n",
      "Epoch  3, MNIST Batch 34: Loss:     1.1388 Validation Accuracy: 0.825400\n",
      "Epoch  3, MNIST Batch 35: Loss:     1.1401 Validation Accuracy: 0.825200\n",
      "Epoch  3, MNIST Batch 36: Loss:     1.1422 Validation Accuracy: 0.825800\n",
      "Epoch  3, MNIST Batch 37: Loss:     1.1584 Validation Accuracy: 0.826400\n",
      "Epoch  3, MNIST Batch 38: Loss:     1.0965 Validation Accuracy: 0.825800\n",
      "Epoch  3, MNIST Batch 39: Loss:     1.1075 Validation Accuracy: 0.826000\n",
      "Epoch  3, MNIST Batch 40: Loss:     1.1032 Validation Accuracy: 0.826600\n",
      "Epoch  3, MNIST Batch 41: Loss:     1.1128 Validation Accuracy: 0.828000\n",
      "Epoch  3, MNIST Batch 42: Loss:     1.1351 Validation Accuracy: 0.828600\n",
      "Epoch  3, MNIST Batch 43: Loss:     1.0817 Validation Accuracy: 0.828600\n",
      "Epoch  3, MNIST Batch 44: Loss:     1.0896 Validation Accuracy: 0.828200\n",
      "Epoch  3, MNIST Batch 45: Loss:     1.1049 Validation Accuracy: 0.827400\n",
      "Epoch  3, MNIST Batch 46: Loss:     1.1065 Validation Accuracy: 0.828000\n",
      "Epoch  3, MNIST Batch 47: Loss:     1.0777 Validation Accuracy: 0.827800\n",
      "Epoch  3, MNIST Batch 48: Loss:     1.1040 Validation Accuracy: 0.828400\n",
      "Epoch  3, MNIST Batch 49: Loss:     1.0475 Validation Accuracy: 0.827400\n",
      "Epoch  3, MNIST Batch 50: Loss:     1.0433 Validation Accuracy: 0.828200\n",
      "Epoch  3, MNIST Batch 51: Loss:     1.1092 Validation Accuracy: 0.828800\n",
      "Epoch  3, MNIST Batch 52: Loss:     1.0385 Validation Accuracy: 0.829200\n",
      "Epoch  3, MNIST Batch 53: Loss:     1.0562 Validation Accuracy: 0.829800\n",
      "Epoch  3, MNIST Batch 54: Loss:     1.0387 Validation Accuracy: 0.830600\n",
      "Epoch  3, MNIST Batch 55: Loss:     1.0164 Validation Accuracy: 0.830800\n",
      "Epoch  3, MNIST Batch 56: Loss:     1.0499 Validation Accuracy: 0.831000\n",
      "Epoch  3, MNIST Batch 57: Loss:     1.0253 Validation Accuracy: 0.830200\n",
      "Epoch  3, MNIST Batch 58: Loss:     1.0336 Validation Accuracy: 0.828800\n",
      "Epoch  3, MNIST Batch 59: Loss:     1.0543 Validation Accuracy: 0.828200\n",
      "Epoch  3, MNIST Batch 60: Loss:     1.0463 Validation Accuracy: 0.828600\n",
      "Epoch  3, MNIST Batch 61: Loss:     1.0374 Validation Accuracy: 0.828800\n",
      "Epoch  3, MNIST Batch 62: Loss:     1.0168 Validation Accuracy: 0.829400\n",
      "Epoch  3, MNIST Batch 63: Loss:     1.0393 Validation Accuracy: 0.829800\n",
      "Epoch  3, MNIST Batch 64: Loss:     0.9912 Validation Accuracy: 0.829600\n",
      "Epoch  3, MNIST Batch 65: Loss:     1.0173 Validation Accuracy: 0.829000\n",
      "Epoch  3, MNIST Batch 66: Loss:     1.0235 Validation Accuracy: 0.829400\n",
      "Epoch  3, MNIST Batch 67: Loss:     0.9592 Validation Accuracy: 0.828600\n",
      "Epoch  3, MNIST Batch 68: Loss:     1.0011 Validation Accuracy: 0.829000\n",
      "Epoch  3, MNIST Batch 69: Loss:     0.9959 Validation Accuracy: 0.829600\n",
      "Epoch  3, MNIST Batch 70: Loss:     1.0098 Validation Accuracy: 0.829600\n",
      "Epoch  3, MNIST Batch 71: Loss:     0.9621 Validation Accuracy: 0.829800\n",
      "Epoch  3, MNIST Batch 72: Loss:     0.9727 Validation Accuracy: 0.829800\n",
      "Epoch  3, MNIST Batch 73: Loss:     1.0037 Validation Accuracy: 0.830200\n",
      "Epoch  3, MNIST Batch 74: Loss:     0.9458 Validation Accuracy: 0.829800\n",
      "Epoch  3, MNIST Batch 75: Loss:     0.9524 Validation Accuracy: 0.829400\n",
      "Epoch  3, MNIST Batch 76: Loss:     0.9512 Validation Accuracy: 0.831400\n",
      "Epoch  3, MNIST Batch 77: Loss:     0.9723 Validation Accuracy: 0.831800\n",
      "Epoch  3, MNIST Batch 78: Loss:     0.9632 Validation Accuracy: 0.831200\n",
      "Epoch  3, MNIST Batch 79: Loss:     0.9167 Validation Accuracy: 0.832000\n",
      "Epoch  3, MNIST Batch 80: Loss:     0.9601 Validation Accuracy: 0.832800\n",
      "Epoch  3, MNIST Batch 81: Loss:     0.9843 Validation Accuracy: 0.834000\n",
      "Epoch  3, MNIST Batch 82: Loss:     0.9523 Validation Accuracy: 0.834400\n",
      "Epoch  3, MNIST Batch 83: Loss:     0.9176 Validation Accuracy: 0.834400\n",
      "Epoch  3, MNIST Batch 84: Loss:     0.9352 Validation Accuracy: 0.834000\n",
      "Epoch  3, MNIST Batch 85: Loss:     0.9304 Validation Accuracy: 0.834400\n",
      "Epoch  3, MNIST Batch 86: Loss:     0.9419 Validation Accuracy: 0.835200\n",
      "Epoch  3, MNIST Batch 87: Loss:     0.9597 Validation Accuracy: 0.834800\n",
      "Epoch  3, MNIST Batch 88: Loss:     0.9281 Validation Accuracy: 0.835200\n",
      "Epoch  3, MNIST Batch 89: Loss:     0.9484 Validation Accuracy: 0.835000\n",
      "Epoch  3, MNIST Batch 90: Loss:     0.9707 Validation Accuracy: 0.835600\n",
      "Epoch  3, MNIST Batch 91: Loss:     0.9185 Validation Accuracy: 0.835800\n",
      "Epoch  3, MNIST Batch 92: Loss:     0.9125 Validation Accuracy: 0.836000\n",
      "Epoch  3, MNIST Batch 93: Loss:     0.8980 Validation Accuracy: 0.836600\n",
      "Epoch  3, MNIST Batch 94: Loss:     0.8929 Validation Accuracy: 0.836800\n",
      "Epoch  3, MNIST Batch 95: Loss:     0.8963 Validation Accuracy: 0.837200\n",
      "Epoch  3, MNIST Batch 96: Loss:     0.8848 Validation Accuracy: 0.837600\n",
      "Epoch  3, MNIST Batch 97: Loss:     0.8887 Validation Accuracy: 0.837600\n",
      "Epoch  3, MNIST Batch 98: Loss:     0.8694 Validation Accuracy: 0.838000\n",
      "Epoch  3, MNIST Batch 99: Loss:     0.9067 Validation Accuracy: 0.838800\n",
      "Epoch  3, MNIST Batch 100: Loss:     0.8744 Validation Accuracy: 0.839800\n",
      "Epoch  3, MNIST Batch 101: Loss:     0.8665 Validation Accuracy: 0.840400\n",
      "Epoch  3, MNIST Batch 102: Loss:     0.8480 Validation Accuracy: 0.842000\n",
      "Epoch  3, MNIST Batch 103: Loss:     0.8805 Validation Accuracy: 0.841400\n",
      "Epoch  3, MNIST Batch 104: Loss:     0.8439 Validation Accuracy: 0.840800\n",
      "Epoch  3, MNIST Batch 105: Loss:     0.8342 Validation Accuracy: 0.840600\n",
      "Epoch  3, MNIST Batch 106: Loss:     0.8940 Validation Accuracy: 0.841600\n",
      "Epoch  4, MNIST Batch 0: Loss:     0.8732 Validation Accuracy: 0.842200\n",
      "Epoch  4, MNIST Batch 1: Loss:     0.8597 Validation Accuracy: 0.842600\n",
      "Epoch  4, MNIST Batch 2: Loss:     0.8558 Validation Accuracy: 0.842600\n",
      "Epoch  4, MNIST Batch 3: Loss:     0.8570 Validation Accuracy: 0.842600\n",
      "Epoch  4, MNIST Batch 4: Loss:     0.8488 Validation Accuracy: 0.842600\n",
      "Epoch  4, MNIST Batch 5: Loss:     0.8632 Validation Accuracy: 0.842000\n",
      "Epoch  4, MNIST Batch 6: Loss:     0.8668 Validation Accuracy: 0.841800\n",
      "Epoch  4, MNIST Batch 7: Loss:     0.8666 Validation Accuracy: 0.840200\n",
      "Epoch  4, MNIST Batch 8: Loss:     0.8202 Validation Accuracy: 0.840600\n",
      "Epoch  4, MNIST Batch 9: Loss:     0.8081 Validation Accuracy: 0.840600\n",
      "Epoch  4, MNIST Batch 10: Loss:     0.8367 Validation Accuracy: 0.840400\n",
      "Epoch  4, MNIST Batch 11: Loss:     0.8679 Validation Accuracy: 0.840600\n",
      "Epoch  4, MNIST Batch 12: Loss:     0.8641 Validation Accuracy: 0.839200\n",
      "Epoch  4, MNIST Batch 13: Loss:     0.8174 Validation Accuracy: 0.840400\n",
      "Epoch  4, MNIST Batch 14: Loss:     0.8297 Validation Accuracy: 0.841200\n",
      "Epoch  4, MNIST Batch 15: Loss:     0.8669 Validation Accuracy: 0.842000\n",
      "Epoch  4, MNIST Batch 16: Loss:     0.8278 Validation Accuracy: 0.843000\n",
      "Epoch  4, MNIST Batch 17: Loss:     0.8613 Validation Accuracy: 0.844000\n",
      "Epoch  4, MNIST Batch 18: Loss:     0.7951 Validation Accuracy: 0.843200\n",
      "Epoch  4, MNIST Batch 19: Loss:     0.7885 Validation Accuracy: 0.843400\n",
      "Epoch  4, MNIST Batch 20: Loss:     0.8224 Validation Accuracy: 0.843800\n",
      "Epoch  4, MNIST Batch 21: Loss:     0.7794 Validation Accuracy: 0.844800\n",
      "Epoch  4, MNIST Batch 22: Loss:     0.8054 Validation Accuracy: 0.845000\n",
      "Epoch  4, MNIST Batch 23: Loss:     0.8110 Validation Accuracy: 0.846800\n",
      "Epoch  4, MNIST Batch 24: Loss:     0.8137 Validation Accuracy: 0.847000\n",
      "Epoch  4, MNIST Batch 25: Loss:     0.8419 Validation Accuracy: 0.848200\n",
      "Epoch  4, MNIST Batch 26: Loss:     0.8666 Validation Accuracy: 0.847800\n",
      "Epoch  4, MNIST Batch 27: Loss:     0.8021 Validation Accuracy: 0.849000\n",
      "Epoch  4, MNIST Batch 28: Loss:     0.7936 Validation Accuracy: 0.849400\n",
      "Epoch  4, MNIST Batch 29: Loss:     0.8160 Validation Accuracy: 0.849000\n",
      "Epoch  4, MNIST Batch 30: Loss:     0.7736 Validation Accuracy: 0.850000\n",
      "Epoch  4, MNIST Batch 31: Loss:     0.7714 Validation Accuracy: 0.849200\n",
      "Epoch  4, MNIST Batch 32: Loss:     0.7434 Validation Accuracy: 0.849200\n",
      "Epoch  4, MNIST Batch 33: Loss:     0.7440 Validation Accuracy: 0.849200\n",
      "Epoch  4, MNIST Batch 34: Loss:     0.7234 Validation Accuracy: 0.848600\n",
      "Epoch  4, MNIST Batch 35: Loss:     0.7490 Validation Accuracy: 0.849000\n",
      "Epoch  4, MNIST Batch 36: Loss:     0.7729 Validation Accuracy: 0.849200\n",
      "Epoch  4, MNIST Batch 37: Loss:     0.7850 Validation Accuracy: 0.850200\n",
      "Epoch  4, MNIST Batch 38: Loss:     0.7475 Validation Accuracy: 0.850000\n",
      "Epoch  4, MNIST Batch 39: Loss:     0.7613 Validation Accuracy: 0.849800\n",
      "Epoch  4, MNIST Batch 40: Loss:     0.7777 Validation Accuracy: 0.850000\n",
      "Epoch  4, MNIST Batch 41: Loss:     0.7582 Validation Accuracy: 0.851000\n",
      "Epoch  4, MNIST Batch 42: Loss:     0.7414 Validation Accuracy: 0.851200\n",
      "Epoch  4, MNIST Batch 43: Loss:     0.7478 Validation Accuracy: 0.852200\n",
      "Epoch  4, MNIST Batch 44: Loss:     0.7190 Validation Accuracy: 0.852800\n",
      "Epoch  4, MNIST Batch 45: Loss:     0.7857 Validation Accuracy: 0.852800\n",
      "Epoch  4, MNIST Batch 46: Loss:     0.8030 Validation Accuracy: 0.853000\n",
      "Epoch  4, MNIST Batch 47: Loss:     0.6980 Validation Accuracy: 0.854400\n",
      "Epoch  4, MNIST Batch 48: Loss:     0.7430 Validation Accuracy: 0.854000\n",
      "Epoch  4, MNIST Batch 49: Loss:     0.7334 Validation Accuracy: 0.854400\n",
      "Epoch  4, MNIST Batch 50: Loss:     0.7692 Validation Accuracy: 0.853800\n",
      "Epoch  4, MNIST Batch 51: Loss:     0.7496 Validation Accuracy: 0.853800\n",
      "Epoch  4, MNIST Batch 52: Loss:     0.6850 Validation Accuracy: 0.854400\n",
      "Epoch  4, MNIST Batch 53: Loss:     0.7164 Validation Accuracy: 0.854800\n",
      "Epoch  4, MNIST Batch 54: Loss:     0.7162 Validation Accuracy: 0.854800\n",
      "Epoch  4, MNIST Batch 55: Loss:     0.7229 Validation Accuracy: 0.856200\n",
      "Epoch  4, MNIST Batch 56: Loss:     0.6780 Validation Accuracy: 0.855600\n",
      "Epoch  4, MNIST Batch 57: Loss:     0.7701 Validation Accuracy: 0.855800\n",
      "Epoch  4, MNIST Batch 58: Loss:     0.6970 Validation Accuracy: 0.856000\n",
      "Epoch  4, MNIST Batch 59: Loss:     0.7316 Validation Accuracy: 0.856200\n",
      "Epoch  4, MNIST Batch 60: Loss:     0.7316 Validation Accuracy: 0.856800\n",
      "Epoch  4, MNIST Batch 61: Loss:     0.7477 Validation Accuracy: 0.857200\n",
      "Epoch  4, MNIST Batch 62: Loss:     0.6900 Validation Accuracy: 0.857200\n",
      "Epoch  4, MNIST Batch 63: Loss:     0.7204 Validation Accuracy: 0.857200\n",
      "Epoch  4, MNIST Batch 64: Loss:     0.6602 Validation Accuracy: 0.857000\n",
      "Epoch  4, MNIST Batch 65: Loss:     0.6939 Validation Accuracy: 0.856800\n",
      "Epoch  4, MNIST Batch 66: Loss:     0.7371 Validation Accuracy: 0.856400\n",
      "Epoch  4, MNIST Batch 67: Loss:     0.6830 Validation Accuracy: 0.856200\n",
      "Epoch  4, MNIST Batch 68: Loss:     0.6838 Validation Accuracy: 0.857200\n",
      "Epoch  4, MNIST Batch 69: Loss:     0.6756 Validation Accuracy: 0.858000\n",
      "Epoch  4, MNIST Batch 70: Loss:     0.6937 Validation Accuracy: 0.857000\n",
      "Epoch  4, MNIST Batch 71: Loss:     0.6750 Validation Accuracy: 0.856800\n",
      "Epoch  4, MNIST Batch 72: Loss:     0.6834 Validation Accuracy: 0.857000\n",
      "Epoch  4, MNIST Batch 73: Loss:     0.6565 Validation Accuracy: 0.858400\n",
      "Epoch  4, MNIST Batch 74: Loss:     0.7079 Validation Accuracy: 0.858400\n",
      "Epoch  4, MNIST Batch 75: Loss:     0.6820 Validation Accuracy: 0.858800\n",
      "Epoch  4, MNIST Batch 76: Loss:     0.6900 Validation Accuracy: 0.859400\n",
      "Epoch  4, MNIST Batch 77: Loss:     0.6714 Validation Accuracy: 0.860200\n",
      "Epoch  4, MNIST Batch 78: Loss:     0.6644 Validation Accuracy: 0.860800\n",
      "Epoch  4, MNIST Batch 79: Loss:     0.6812 Validation Accuracy: 0.861200\n",
      "Epoch  4, MNIST Batch 80: Loss:     0.6879 Validation Accuracy: 0.861200\n",
      "Epoch  4, MNIST Batch 81: Loss:     0.6799 Validation Accuracy: 0.861200\n",
      "Epoch  4, MNIST Batch 82: Loss:     0.6925 Validation Accuracy: 0.861400\n",
      "Epoch  4, MNIST Batch 83: Loss:     0.6939 Validation Accuracy: 0.861600\n",
      "Epoch  4, MNIST Batch 84: Loss:     0.6344 Validation Accuracy: 0.862200\n",
      "Epoch  4, MNIST Batch 85: Loss:     0.6854 Validation Accuracy: 0.862000\n",
      "Epoch  4, MNIST Batch 86: Loss:     0.6650 Validation Accuracy: 0.862200\n",
      "Epoch  4, MNIST Batch 87: Loss:     0.6298 Validation Accuracy: 0.862000\n",
      "Epoch  4, MNIST Batch 88: Loss:     0.6473 Validation Accuracy: 0.862000\n",
      "Epoch  4, MNIST Batch 89: Loss:     0.6122 Validation Accuracy: 0.862400\n",
      "Epoch  4, MNIST Batch 90: Loss:     0.6369 Validation Accuracy: 0.863000\n",
      "Epoch  4, MNIST Batch 91: Loss:     0.6464 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 92: Loss:     0.5872 Validation Accuracy: 0.862400\n",
      "Epoch  4, MNIST Batch 93: Loss:     0.6392 Validation Accuracy: 0.862400\n",
      "Epoch  4, MNIST Batch 94: Loss:     0.6385 Validation Accuracy: 0.862600\n",
      "Epoch  4, MNIST Batch 95: Loss:     0.6784 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 96: Loss:     0.6719 Validation Accuracy: 0.862600\n",
      "Epoch  4, MNIST Batch 97: Loss:     0.6097 Validation Accuracy: 0.862600\n",
      "Epoch  4, MNIST Batch 98: Loss:     0.6270 Validation Accuracy: 0.862400\n",
      "Epoch  4, MNIST Batch 99: Loss:     0.6212 Validation Accuracy: 0.863400\n",
      "Epoch  4, MNIST Batch 100: Loss:     0.6555 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 101: Loss:     0.6521 Validation Accuracy: 0.862200\n",
      "Epoch  4, MNIST Batch 102: Loss:     0.6648 Validation Accuracy: 0.862800\n",
      "Epoch  4, MNIST Batch 103: Loss:     0.6292 Validation Accuracy: 0.863200\n",
      "Epoch  4, MNIST Batch 104: Loss:     0.6220 Validation Accuracy: 0.863200\n",
      "Epoch  4, MNIST Batch 105: Loss:     0.6585 Validation Accuracy: 0.864600\n",
      "Epoch  4, MNIST Batch 106: Loss:     0.5752 Validation Accuracy: 0.864200\n",
      "Epoch  5, MNIST Batch 0: Loss:     0.6428 Validation Accuracy: 0.864000\n",
      "Epoch  5, MNIST Batch 1: Loss:     0.5949 Validation Accuracy: 0.865400\n",
      "Epoch  5, MNIST Batch 2: Loss:     0.6125 Validation Accuracy: 0.866000\n",
      "Epoch  5, MNIST Batch 3: Loss:     0.5741 Validation Accuracy: 0.866000\n",
      "Epoch  5, MNIST Batch 4: Loss:     0.5911 Validation Accuracy: 0.865400\n",
      "Epoch  5, MNIST Batch 5: Loss:     0.6170 Validation Accuracy: 0.866200\n",
      "Epoch  5, MNIST Batch 6: Loss:     0.6564 Validation Accuracy: 0.866800\n",
      "Epoch  5, MNIST Batch 7: Loss:     0.6224 Validation Accuracy: 0.867000\n",
      "Epoch  5, MNIST Batch 8: Loss:     0.6246 Validation Accuracy: 0.867000\n",
      "Epoch  5, MNIST Batch 9: Loss:     0.5977 Validation Accuracy: 0.867600\n",
      "Epoch  5, MNIST Batch 10: Loss:     0.6223 Validation Accuracy: 0.867800\n",
      "Epoch  5, MNIST Batch 11: Loss:     0.6157 Validation Accuracy: 0.867800\n",
      "Epoch  5, MNIST Batch 12: Loss:     0.5937 Validation Accuracy: 0.867200\n",
      "Epoch  5, MNIST Batch 13: Loss:     0.6054 Validation Accuracy: 0.867800\n",
      "Epoch  5, MNIST Batch 14: Loss:     0.6105 Validation Accuracy: 0.867400\n",
      "Epoch  5, MNIST Batch 15: Loss:     0.5586 Validation Accuracy: 0.867400\n",
      "Epoch  5, MNIST Batch 16: Loss:     0.6214 Validation Accuracy: 0.868000\n",
      "Epoch  5, MNIST Batch 17: Loss:     0.6076 Validation Accuracy: 0.867800\n",
      "Epoch  5, MNIST Batch 18: Loss:     0.5697 Validation Accuracy: 0.868000\n",
      "Epoch  5, MNIST Batch 19: Loss:     0.5708 Validation Accuracy: 0.867800\n",
      "Epoch  5, MNIST Batch 20: Loss:     0.5829 Validation Accuracy: 0.867000\n",
      "Epoch  5, MNIST Batch 21: Loss:     0.5753 Validation Accuracy: 0.867200\n",
      "Epoch  5, MNIST Batch 22: Loss:     0.5896 Validation Accuracy: 0.867600\n",
      "Epoch  5, MNIST Batch 23: Loss:     0.6174 Validation Accuracy: 0.867600\n",
      "Epoch  5, MNIST Batch 24: Loss:     0.6531 Validation Accuracy: 0.868600\n",
      "Epoch  5, MNIST Batch 25: Loss:     0.6024 Validation Accuracy: 0.868200\n",
      "Epoch  5, MNIST Batch 26: Loss:     0.6020 Validation Accuracy: 0.869000\n",
      "Epoch  5, MNIST Batch 27: Loss:     0.6050 Validation Accuracy: 0.869400\n",
      "Epoch  5, MNIST Batch 28: Loss:     0.6186 Validation Accuracy: 0.870600\n",
      "Epoch  5, MNIST Batch 29: Loss:     0.6096 Validation Accuracy: 0.871200\n",
      "Epoch  5, MNIST Batch 30: Loss:     0.6320 Validation Accuracy: 0.871400\n",
      "Epoch  5, MNIST Batch 31: Loss:     0.5599 Validation Accuracy: 0.871800\n",
      "Epoch  5, MNIST Batch 32: Loss:     0.5646 Validation Accuracy: 0.871000\n",
      "Epoch  5, MNIST Batch 33: Loss:     0.6064 Validation Accuracy: 0.871200\n",
      "Epoch  5, MNIST Batch 34: Loss:     0.6122 Validation Accuracy: 0.871200\n",
      "Epoch  5, MNIST Batch 35: Loss:     0.5861 Validation Accuracy: 0.871600\n",
      "Epoch  5, MNIST Batch 36: Loss:     0.5599 Validation Accuracy: 0.871800\n",
      "Epoch  5, MNIST Batch 37: Loss:     0.5433 Validation Accuracy: 0.871800\n",
      "Epoch  5, MNIST Batch 38: Loss:     0.5818 Validation Accuracy: 0.871800\n",
      "Epoch  5, MNIST Batch 39: Loss:     0.5614 Validation Accuracy: 0.871400\n",
      "Epoch  5, MNIST Batch 40: Loss:     0.5272 Validation Accuracy: 0.871000\n",
      "Epoch  5, MNIST Batch 41: Loss:     0.5334 Validation Accuracy: 0.871600\n",
      "Epoch  5, MNIST Batch 42: Loss:     0.5634 Validation Accuracy: 0.871400\n",
      "Epoch  5, MNIST Batch 43: Loss:     0.5772 Validation Accuracy: 0.872400\n",
      "Epoch  5, MNIST Batch 44: Loss:     0.5443 Validation Accuracy: 0.872400\n",
      "Epoch  5, MNIST Batch 45: Loss:     0.5005 Validation Accuracy: 0.872400\n",
      "Epoch  5, MNIST Batch 46: Loss:     0.5332 Validation Accuracy: 0.872600\n",
      "Epoch  5, MNIST Batch 47: Loss:     0.5479 Validation Accuracy: 0.872800\n",
      "Epoch  5, MNIST Batch 48: Loss:     0.5816 Validation Accuracy: 0.873000\n",
      "Epoch  5, MNIST Batch 49: Loss:     0.5858 Validation Accuracy: 0.873200\n",
      "Epoch  5, MNIST Batch 50: Loss:     0.5768 Validation Accuracy: 0.872600\n",
      "Epoch  5, MNIST Batch 51: Loss:     0.5351 Validation Accuracy: 0.873600\n",
      "Epoch  5, MNIST Batch 52: Loss:     0.5009 Validation Accuracy: 0.874000\n",
      "Epoch  5, MNIST Batch 53: Loss:     0.5812 Validation Accuracy: 0.874600\n",
      "Epoch  5, MNIST Batch 54: Loss:     0.5429 Validation Accuracy: 0.875000\n",
      "Epoch  5, MNIST Batch 55: Loss:     0.5427 Validation Accuracy: 0.875200\n",
      "Epoch  5, MNIST Batch 56: Loss:     0.5181 Validation Accuracy: 0.875000\n",
      "Epoch  5, MNIST Batch 57: Loss:     0.5704 Validation Accuracy: 0.875400\n",
      "Epoch  5, MNIST Batch 58: Loss:     0.5808 Validation Accuracy: 0.875800\n",
      "Epoch  5, MNIST Batch 59: Loss:     0.5123 Validation Accuracy: 0.877000\n",
      "Epoch  5, MNIST Batch 60: Loss:     0.5677 Validation Accuracy: 0.877200\n",
      "Epoch  5, MNIST Batch 61: Loss:     0.5302 Validation Accuracy: 0.877600\n",
      "Epoch  5, MNIST Batch 62: Loss:     0.5178 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 63: Loss:     0.5217 Validation Accuracy: 0.876600\n",
      "Epoch  5, MNIST Batch 64: Loss:     0.5395 Validation Accuracy: 0.876600\n",
      "Epoch  5, MNIST Batch 65: Loss:     0.5296 Validation Accuracy: 0.876800\n",
      "Epoch  5, MNIST Batch 66: Loss:     0.5429 Validation Accuracy: 0.876800\n",
      "Epoch  5, MNIST Batch 67: Loss:     0.5519 Validation Accuracy: 0.877400\n",
      "Epoch  5, MNIST Batch 68: Loss:     0.5538 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 69: Loss:     0.5232 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 70: Loss:     0.5214 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 71: Loss:     0.5478 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 72: Loss:     0.5555 Validation Accuracy: 0.876400\n",
      "Epoch  5, MNIST Batch 73: Loss:     0.5018 Validation Accuracy: 0.876800\n",
      "Epoch  5, MNIST Batch 74: Loss:     0.4838 Validation Accuracy: 0.876800\n",
      "Epoch  5, MNIST Batch 75: Loss:     0.5372 Validation Accuracy: 0.877600\n",
      "Epoch  5, MNIST Batch 76: Loss:     0.4855 Validation Accuracy: 0.877800\n",
      "Epoch  5, MNIST Batch 77: Loss:     0.5327 Validation Accuracy: 0.878600\n",
      "Epoch  5, MNIST Batch 78: Loss:     0.5238 Validation Accuracy: 0.879400\n",
      "Epoch  5, MNIST Batch 79: Loss:     0.5360 Validation Accuracy: 0.879000\n",
      "Epoch  5, MNIST Batch 80: Loss:     0.5857 Validation Accuracy: 0.878800\n",
      "Epoch  5, MNIST Batch 81: Loss:     0.5198 Validation Accuracy: 0.879000\n",
      "Epoch  5, MNIST Batch 82: Loss:     0.5182 Validation Accuracy: 0.879400\n",
      "Epoch  5, MNIST Batch 83: Loss:     0.5630 Validation Accuracy: 0.879600\n",
      "Epoch  5, MNIST Batch 84: Loss:     0.4971 Validation Accuracy: 0.879800\n",
      "Epoch  5, MNIST Batch 85: Loss:     0.5228 Validation Accuracy: 0.881000\n",
      "Epoch  5, MNIST Batch 86: Loss:     0.5252 Validation Accuracy: 0.882000\n",
      "Epoch  5, MNIST Batch 87: Loss:     0.4938 Validation Accuracy: 0.882400\n",
      "Epoch  5, MNIST Batch 88: Loss:     0.5771 Validation Accuracy: 0.883000\n",
      "Epoch  5, MNIST Batch 89: Loss:     0.4521 Validation Accuracy: 0.882200\n",
      "Epoch  5, MNIST Batch 90: Loss:     0.4599 Validation Accuracy: 0.882600\n",
      "Epoch  5, MNIST Batch 91: Loss:     0.4572 Validation Accuracy: 0.882200\n",
      "Epoch  5, MNIST Batch 92: Loss:     0.5194 Validation Accuracy: 0.882600\n",
      "Epoch  5, MNIST Batch 93: Loss:     0.5253 Validation Accuracy: 0.881800\n",
      "Epoch  5, MNIST Batch 94: Loss:     0.5000 Validation Accuracy: 0.881200\n",
      "Epoch  5, MNIST Batch 95: Loss:     0.5325 Validation Accuracy: 0.880600\n",
      "Epoch  5, MNIST Batch 96: Loss:     0.5043 Validation Accuracy: 0.881000\n",
      "Epoch  5, MNIST Batch 97: Loss:     0.4701 Validation Accuracy: 0.880800\n",
      "Epoch  5, MNIST Batch 98: Loss:     0.5359 Validation Accuracy: 0.879600\n",
      "Epoch  5, MNIST Batch 99: Loss:     0.4948 Validation Accuracy: 0.879400\n",
      "Epoch  5, MNIST Batch 100: Loss:     0.5003 Validation Accuracy: 0.880200\n",
      "Epoch  5, MNIST Batch 101: Loss:     0.5332 Validation Accuracy: 0.881000\n",
      "Epoch  5, MNIST Batch 102: Loss:     0.4783 Validation Accuracy: 0.881400\n",
      "Epoch  5, MNIST Batch 103: Loss:     0.4810 Validation Accuracy: 0.881800\n",
      "Epoch  5, MNIST Batch 104: Loss:     0.5236 Validation Accuracy: 0.881400\n",
      "Epoch  5, MNIST Batch 105: Loss:     0.5142 Validation Accuracy: 0.882200\n",
      "Epoch  5, MNIST Batch 106: Loss:     0.5028 Validation Accuracy: 0.882600\n",
      "Epoch  6, MNIST Batch 0: Loss:     0.5208 Validation Accuracy: 0.883200\n",
      "Epoch  6, MNIST Batch 1: Loss:     0.5197 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 2: Loss:     0.5607 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 3: Loss:     0.4792 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 4: Loss:     0.4904 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 5: Loss:     0.5015 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 6: Loss:     0.5049 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 7: Loss:     0.5288 Validation Accuracy: 0.884000\n",
      "Epoch  6, MNIST Batch 8: Loss:     0.5062 Validation Accuracy: 0.884600\n",
      "Epoch  6, MNIST Batch 9: Loss:     0.4846 Validation Accuracy: 0.884200\n",
      "Epoch  6, MNIST Batch 10: Loss:     0.5145 Validation Accuracy: 0.884200\n",
      "Epoch  6, MNIST Batch 11: Loss:     0.5128 Validation Accuracy: 0.885200\n",
      "Epoch  6, MNIST Batch 12: Loss:     0.5044 Validation Accuracy: 0.885600\n",
      "Epoch  6, MNIST Batch 13: Loss:     0.4769 Validation Accuracy: 0.885800\n",
      "Epoch  6, MNIST Batch 14: Loss:     0.4752 Validation Accuracy: 0.885600\n",
      "Epoch  6, MNIST Batch 15: Loss:     0.4515 Validation Accuracy: 0.885800\n",
      "Epoch  6, MNIST Batch 16: Loss:     0.4906 Validation Accuracy: 0.886400\n",
      "Epoch  6, MNIST Batch 17: Loss:     0.5241 Validation Accuracy: 0.885800\n",
      "Epoch  6, MNIST Batch 18: Loss:     0.4731 Validation Accuracy: 0.885000\n",
      "Epoch  6, MNIST Batch 19: Loss:     0.5504 Validation Accuracy: 0.885000\n",
      "Epoch  6, MNIST Batch 20: Loss:     0.4911 Validation Accuracy: 0.884800\n",
      "Epoch  6, MNIST Batch 21: Loss:     0.5182 Validation Accuracy: 0.884000\n",
      "Epoch  6, MNIST Batch 22: Loss:     0.4587 Validation Accuracy: 0.883800\n",
      "Epoch  6, MNIST Batch 23: Loss:     0.4370 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 24: Loss:     0.4968 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 25: Loss:     0.4494 Validation Accuracy: 0.883600\n",
      "Epoch  6, MNIST Batch 26: Loss:     0.4601 Validation Accuracy: 0.883800\n",
      "Epoch  6, MNIST Batch 27: Loss:     0.5147 Validation Accuracy: 0.883400\n",
      "Epoch  6, MNIST Batch 28: Loss:     0.5346 Validation Accuracy: 0.883400\n",
      "Epoch  6, MNIST Batch 29: Loss:     0.4885 Validation Accuracy: 0.883800\n",
      "Epoch  6, MNIST Batch 30: Loss:     0.4816 Validation Accuracy: 0.884200\n",
      "Epoch  6, MNIST Batch 31: Loss:     0.5412 Validation Accuracy: 0.885800\n",
      "Epoch  6, MNIST Batch 32: Loss:     0.4400 Validation Accuracy: 0.886000\n",
      "Epoch  6, MNIST Batch 33: Loss:     0.4906 Validation Accuracy: 0.886800\n",
      "Epoch  6, MNIST Batch 34: Loss:     0.5030 Validation Accuracy: 0.887800\n",
      "Epoch  6, MNIST Batch 35: Loss:     0.4775 Validation Accuracy: 0.888000\n",
      "Epoch  6, MNIST Batch 36: Loss:     0.5074 Validation Accuracy: 0.887800\n",
      "Epoch  6, MNIST Batch 37: Loss:     0.4652 Validation Accuracy: 0.888600\n",
      "Epoch  6, MNIST Batch 38: Loss:     0.4548 Validation Accuracy: 0.888800\n",
      "Epoch  6, MNIST Batch 39: Loss:     0.4315 Validation Accuracy: 0.889000\n",
      "Epoch  6, MNIST Batch 40: Loss:     0.4958 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 41: Loss:     0.4725 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 42: Loss:     0.4830 Validation Accuracy: 0.889800\n",
      "Epoch  6, MNIST Batch 43: Loss:     0.4867 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 44: Loss:     0.4742 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 45: Loss:     0.4993 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 46: Loss:     0.4563 Validation Accuracy: 0.889800\n",
      "Epoch  6, MNIST Batch 47: Loss:     0.4687 Validation Accuracy: 0.889600\n",
      "Epoch  6, MNIST Batch 48: Loss:     0.4552 Validation Accuracy: 0.888800\n",
      "Epoch  6, MNIST Batch 49: Loss:     0.4518 Validation Accuracy: 0.889000\n",
      "Epoch  6, MNIST Batch 50: Loss:     0.4387 Validation Accuracy: 0.888400\n",
      "Epoch  6, MNIST Batch 51: Loss:     0.4424 Validation Accuracy: 0.888000\n",
      "Epoch  6, MNIST Batch 52: Loss:     0.4463 Validation Accuracy: 0.888400\n",
      "Epoch  6, MNIST Batch 53: Loss:     0.4714 Validation Accuracy: 0.888800\n",
      "Epoch  6, MNIST Batch 54: Loss:     0.4103 Validation Accuracy: 0.888800\n",
      "Epoch  6, MNIST Batch 55: Loss:     0.5038 Validation Accuracy: 0.888800\n",
      "Epoch  6, MNIST Batch 56: Loss:     0.4170 Validation Accuracy: 0.889400\n",
      "Epoch  6, MNIST Batch 57: Loss:     0.4536 Validation Accuracy: 0.890600\n",
      "Epoch  6, MNIST Batch 58: Loss:     0.4976 Validation Accuracy: 0.891200\n",
      "Epoch  6, MNIST Batch 59: Loss:     0.4254 Validation Accuracy: 0.890400\n",
      "Epoch  6, MNIST Batch 60: Loss:     0.4202 Validation Accuracy: 0.890800\n",
      "Epoch  6, MNIST Batch 61: Loss:     0.4660 Validation Accuracy: 0.892000\n",
      "Epoch  6, MNIST Batch 62: Loss:     0.4597 Validation Accuracy: 0.892800\n",
      "Epoch  6, MNIST Batch 63: Loss:     0.4317 Validation Accuracy: 0.892400\n",
      "Epoch  6, MNIST Batch 64: Loss:     0.4914 Validation Accuracy: 0.892200\n",
      "Epoch  6, MNIST Batch 65: Loss:     0.4551 Validation Accuracy: 0.892000\n",
      "Epoch  6, MNIST Batch 66: Loss:     0.4381 Validation Accuracy: 0.891400\n",
      "Epoch  6, MNIST Batch 67: Loss:     0.4854 Validation Accuracy: 0.891600\n",
      "Epoch  6, MNIST Batch 68: Loss:     0.4879 Validation Accuracy: 0.891400\n",
      "Epoch  6, MNIST Batch 69: Loss:     0.5068 Validation Accuracy: 0.892000\n",
      "Epoch  6, MNIST Batch 70: Loss:     0.4125 Validation Accuracy: 0.892400\n",
      "Epoch  6, MNIST Batch 71: Loss:     0.4284 Validation Accuracy: 0.892400\n",
      "Epoch  6, MNIST Batch 72: Loss:     0.4533 Validation Accuracy: 0.893000\n",
      "Epoch  6, MNIST Batch 73: Loss:     0.4105 Validation Accuracy: 0.893000\n",
      "Epoch  6, MNIST Batch 74: Loss:     0.4265 Validation Accuracy: 0.892000\n",
      "Epoch  6, MNIST Batch 75: Loss:     0.4148 Validation Accuracy: 0.892000\n",
      "Epoch  6, MNIST Batch 76: Loss:     0.4260 Validation Accuracy: 0.892600\n",
      "Epoch  6, MNIST Batch 77: Loss:     0.3945 Validation Accuracy: 0.892400\n",
      "Epoch  6, MNIST Batch 78: Loss:     0.4362 Validation Accuracy: 0.892400\n",
      "Epoch  6, MNIST Batch 79: Loss:     0.4461 Validation Accuracy: 0.891600\n",
      "Epoch  6, MNIST Batch 80: Loss:     0.5118 Validation Accuracy: 0.891800\n",
      "Epoch  6, MNIST Batch 81: Loss:     0.4630 Validation Accuracy: 0.891800\n",
      "Epoch  6, MNIST Batch 82: Loss:     0.4305 Validation Accuracy: 0.891400\n",
      "Epoch  6, MNIST Batch 83: Loss:     0.4398 Validation Accuracy: 0.891200\n",
      "Epoch  6, MNIST Batch 84: Loss:     0.4196 Validation Accuracy: 0.891200\n",
      "Epoch  6, MNIST Batch 85: Loss:     0.4268 Validation Accuracy: 0.890200\n",
      "Epoch  6, MNIST Batch 86: Loss:     0.4661 Validation Accuracy: 0.890200\n",
      "Epoch  6, MNIST Batch 87: Loss:     0.4273 Validation Accuracy: 0.890400\n",
      "Epoch  6, MNIST Batch 88: Loss:     0.4186 Validation Accuracy: 0.891800\n",
      "Epoch  6, MNIST Batch 89: Loss:     0.4351 Validation Accuracy: 0.893000\n",
      "Epoch  6, MNIST Batch 90: Loss:     0.4156 Validation Accuracy: 0.894000\n",
      "Epoch  6, MNIST Batch 91: Loss:     0.4160 Validation Accuracy: 0.895200\n",
      "Epoch  6, MNIST Batch 92: Loss:     0.4100 Validation Accuracy: 0.894400\n",
      "Epoch  6, MNIST Batch 93: Loss:     0.4509 Validation Accuracy: 0.895600\n",
      "Epoch  6, MNIST Batch 94: Loss:     0.4139 Validation Accuracy: 0.896200\n",
      "Epoch  6, MNIST Batch 95: Loss:     0.4599 Validation Accuracy: 0.897000\n",
      "Epoch  6, MNIST Batch 96: Loss:     0.4190 Validation Accuracy: 0.896200\n",
      "Epoch  6, MNIST Batch 97: Loss:     0.4857 Validation Accuracy: 0.896600\n",
      "Epoch  6, MNIST Batch 98: Loss:     0.4540 Validation Accuracy: 0.897200\n",
      "Epoch  6, MNIST Batch 99: Loss:     0.4457 Validation Accuracy: 0.897000\n",
      "Epoch  6, MNIST Batch 100: Loss:     0.4588 Validation Accuracy: 0.896800\n",
      "Epoch  6, MNIST Batch 101: Loss:     0.4019 Validation Accuracy: 0.897800\n",
      "Epoch  6, MNIST Batch 102: Loss:     0.3628 Validation Accuracy: 0.897600\n",
      "Epoch  6, MNIST Batch 103: Loss:     0.3829 Validation Accuracy: 0.897600\n",
      "Epoch  6, MNIST Batch 104: Loss:     0.4205 Validation Accuracy: 0.897000\n",
      "Epoch  6, MNIST Batch 105: Loss:     0.3898 Validation Accuracy: 0.897400\n",
      "Epoch  6, MNIST Batch 106: Loss:     0.4387 Validation Accuracy: 0.898000\n",
      "Epoch  7, MNIST Batch 0: Loss:     0.4653 Validation Accuracy: 0.897600\n",
      "Epoch  7, MNIST Batch 1: Loss:     0.4126 Validation Accuracy: 0.897000\n",
      "Epoch  7, MNIST Batch 2: Loss:     0.3816 Validation Accuracy: 0.897200\n",
      "Epoch  7, MNIST Batch 3: Loss:     0.4111 Validation Accuracy: 0.896800\n",
      "Epoch  7, MNIST Batch 4: Loss:     0.3933 Validation Accuracy: 0.897600\n",
      "Epoch  7, MNIST Batch 5: Loss:     0.4183 Validation Accuracy: 0.898400\n",
      "Epoch  7, MNIST Batch 6: Loss:     0.4613 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 7: Loss:     0.4020 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 8: Loss:     0.4529 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 9: Loss:     0.3992 Validation Accuracy: 0.899200\n",
      "Epoch  7, MNIST Batch 10: Loss:     0.3937 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 11: Loss:     0.4077 Validation Accuracy: 0.898800\n",
      "Epoch  7, MNIST Batch 12: Loss:     0.4136 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 13: Loss:     0.4090 Validation Accuracy: 0.899000\n",
      "Epoch  7, MNIST Batch 14: Loss:     0.4133 Validation Accuracy: 0.898400\n",
      "Epoch  7, MNIST Batch 15: Loss:     0.3909 Validation Accuracy: 0.898200\n",
      "Epoch  7, MNIST Batch 16: Loss:     0.3947 Validation Accuracy: 0.898000\n",
      "Epoch  7, MNIST Batch 17: Loss:     0.3853 Validation Accuracy: 0.897800\n",
      "Epoch  7, MNIST Batch 18: Loss:     0.3988 Validation Accuracy: 0.897600\n",
      "Epoch  7, MNIST Batch 19: Loss:     0.4105 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 20: Loss:     0.4096 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 21: Loss:     0.3979 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 22: Loss:     0.3885 Validation Accuracy: 0.898600\n",
      "Epoch  7, MNIST Batch 23: Loss:     0.3852 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 24: Loss:     0.4149 Validation Accuracy: 0.899800\n",
      "Epoch  7, MNIST Batch 25: Loss:     0.3920 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 26: Loss:     0.3719 Validation Accuracy: 0.900000\n",
      "Epoch  7, MNIST Batch 27: Loss:     0.4000 Validation Accuracy: 0.899800\n",
      "Epoch  7, MNIST Batch 28: Loss:     0.4566 Validation Accuracy: 0.899400\n",
      "Epoch  7, MNIST Batch 29: Loss:     0.3937 Validation Accuracy: 0.899400\n",
      "Epoch  7, MNIST Batch 30: Loss:     0.3746 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 31: Loss:     0.4173 Validation Accuracy: 0.899800\n",
      "Epoch  7, MNIST Batch 32: Loss:     0.4023 Validation Accuracy: 0.899800\n",
      "Epoch  7, MNIST Batch 33: Loss:     0.3848 Validation Accuracy: 0.900200\n",
      "Epoch  7, MNIST Batch 34: Loss:     0.3953 Validation Accuracy: 0.900400\n",
      "Epoch  7, MNIST Batch 35: Loss:     0.3715 Validation Accuracy: 0.900400\n",
      "Epoch  7, MNIST Batch 36: Loss:     0.4060 Validation Accuracy: 0.900200\n",
      "Epoch  7, MNIST Batch 37: Loss:     0.4106 Validation Accuracy: 0.900000\n",
      "Epoch  7, MNIST Batch 38: Loss:     0.3583 Validation Accuracy: 0.899000\n",
      "Epoch  7, MNIST Batch 39: Loss:     0.4400 Validation Accuracy: 0.899600\n",
      "Epoch  7, MNIST Batch 40: Loss:     0.4066 Validation Accuracy: 0.899800\n",
      "Epoch  7, MNIST Batch 41: Loss:     0.4178 Validation Accuracy: 0.900600\n",
      "Epoch  7, MNIST Batch 42: Loss:     0.3948 Validation Accuracy: 0.900600\n",
      "Epoch  7, MNIST Batch 43: Loss:     0.3588 Validation Accuracy: 0.900600\n",
      "Epoch  7, MNIST Batch 44: Loss:     0.4074 Validation Accuracy: 0.900600\n",
      "Epoch  7, MNIST Batch 45: Loss:     0.3858 Validation Accuracy: 0.900800\n",
      "Epoch  7, MNIST Batch 46: Loss:     0.4136 Validation Accuracy: 0.900600\n",
      "Epoch  7, MNIST Batch 47: Loss:     0.4034 Validation Accuracy: 0.901000\n",
      "Epoch  7, MNIST Batch 48: Loss:     0.3904 Validation Accuracy: 0.901200\n",
      "Epoch  7, MNIST Batch 49: Loss:     0.4249 Validation Accuracy: 0.901000\n",
      "Epoch  7, MNIST Batch 50: Loss:     0.4373 Validation Accuracy: 0.902800\n",
      "Epoch  7, MNIST Batch 51: Loss:     0.3872 Validation Accuracy: 0.902800\n",
      "Epoch  7, MNIST Batch 52: Loss:     0.3438 Validation Accuracy: 0.903000\n",
      "Epoch  7, MNIST Batch 53: Loss:     0.3954 Validation Accuracy: 0.903000\n",
      "Epoch  7, MNIST Batch 54: Loss:     0.3627 Validation Accuracy: 0.903400\n",
      "Epoch  7, MNIST Batch 55: Loss:     0.3994 Validation Accuracy: 0.904200\n",
      "Epoch  7, MNIST Batch 56: Loss:     0.3521 Validation Accuracy: 0.904400\n",
      "Epoch  7, MNIST Batch 57: Loss:     0.3957 Validation Accuracy: 0.904200\n",
      "Epoch  7, MNIST Batch 58: Loss:     0.4222 Validation Accuracy: 0.903800\n",
      "Epoch  7, MNIST Batch 59: Loss:     0.3717 Validation Accuracy: 0.903400\n",
      "Epoch  7, MNIST Batch 60: Loss:     0.4536 Validation Accuracy: 0.903000\n",
      "Epoch  7, MNIST Batch 61: Loss:     0.4024 Validation Accuracy: 0.904000\n",
      "Epoch  7, MNIST Batch 62: Loss:     0.3560 Validation Accuracy: 0.903200\n",
      "Epoch  7, MNIST Batch 63: Loss:     0.3370 Validation Accuracy: 0.903400\n",
      "Epoch  7, MNIST Batch 64: Loss:     0.4306 Validation Accuracy: 0.904000\n",
      "Epoch  7, MNIST Batch 65: Loss:     0.3895 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 66: Loss:     0.3922 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 67: Loss:     0.4012 Validation Accuracy: 0.904200\n",
      "Epoch  7, MNIST Batch 68: Loss:     0.3882 Validation Accuracy: 0.904400\n",
      "Epoch  7, MNIST Batch 69: Loss:     0.3534 Validation Accuracy: 0.905000\n",
      "Epoch  7, MNIST Batch 70: Loss:     0.4384 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 71: Loss:     0.3867 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 72: Loss:     0.4174 Validation Accuracy: 0.904000\n",
      "Epoch  7, MNIST Batch 73: Loss:     0.3733 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 74: Loss:     0.3670 Validation Accuracy: 0.904800\n",
      "Epoch  7, MNIST Batch 75: Loss:     0.3709 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 76: Loss:     0.3173 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 77: Loss:     0.3681 Validation Accuracy: 0.904400\n",
      "Epoch  7, MNIST Batch 78: Loss:     0.4058 Validation Accuracy: 0.904400\n",
      "Epoch  7, MNIST Batch 79: Loss:     0.3742 Validation Accuracy: 0.904200\n",
      "Epoch  7, MNIST Batch 80: Loss:     0.4148 Validation Accuracy: 0.904600\n",
      "Epoch  7, MNIST Batch 81: Loss:     0.3966 Validation Accuracy: 0.904800\n",
      "Epoch  7, MNIST Batch 82: Loss:     0.3816 Validation Accuracy: 0.905000\n",
      "Epoch  7, MNIST Batch 83: Loss:     0.3678 Validation Accuracy: 0.905400\n",
      "Epoch  7, MNIST Batch 84: Loss:     0.3437 Validation Accuracy: 0.905400\n",
      "Epoch  7, MNIST Batch 85: Loss:     0.3512 Validation Accuracy: 0.905800\n",
      "Epoch  7, MNIST Batch 86: Loss:     0.3762 Validation Accuracy: 0.906000\n",
      "Epoch  7, MNIST Batch 87: Loss:     0.3666 Validation Accuracy: 0.906400\n",
      "Epoch  7, MNIST Batch 88: Loss:     0.3825 Validation Accuracy: 0.906200\n",
      "Epoch  7, MNIST Batch 89: Loss:     0.3796 Validation Accuracy: 0.906600\n",
      "Epoch  7, MNIST Batch 90: Loss:     0.3474 Validation Accuracy: 0.907000\n",
      "Epoch  7, MNIST Batch 91: Loss:     0.3811 Validation Accuracy: 0.906800\n",
      "Epoch  7, MNIST Batch 92: Loss:     0.3661 Validation Accuracy: 0.907000\n",
      "Epoch  7, MNIST Batch 93: Loss:     0.3716 Validation Accuracy: 0.907000\n",
      "Epoch  7, MNIST Batch 94: Loss:     0.3996 Validation Accuracy: 0.907400\n",
      "Epoch  7, MNIST Batch 95: Loss:     0.3390 Validation Accuracy: 0.907200\n",
      "Epoch  7, MNIST Batch 96: Loss:     0.3507 Validation Accuracy: 0.907200\n",
      "Epoch  7, MNIST Batch 97: Loss:     0.3976 Validation Accuracy: 0.907600\n",
      "Epoch  7, MNIST Batch 98: Loss:     0.3529 Validation Accuracy: 0.907600\n",
      "Epoch  7, MNIST Batch 99: Loss:     0.3555 Validation Accuracy: 0.908000\n",
      "Epoch  7, MNIST Batch 100: Loss:     0.3334 Validation Accuracy: 0.908200\n",
      "Epoch  7, MNIST Batch 101: Loss:     0.3585 Validation Accuracy: 0.907600\n",
      "Epoch  7, MNIST Batch 102: Loss:     0.3844 Validation Accuracy: 0.907600\n",
      "Epoch  7, MNIST Batch 103: Loss:     0.3472 Validation Accuracy: 0.908600\n",
      "Epoch  7, MNIST Batch 104: Loss:     0.4007 Validation Accuracy: 0.909000\n",
      "Epoch  7, MNIST Batch 105: Loss:     0.4130 Validation Accuracy: 0.908400\n",
      "Epoch  7, MNIST Batch 106: Loss:     0.3746 Validation Accuracy: 0.908800\n",
      "Epoch  8, MNIST Batch 0: Loss:     0.3902 Validation Accuracy: 0.910200\n",
      "Epoch  8, MNIST Batch 1: Loss:     0.3468 Validation Accuracy: 0.910600\n",
      "Epoch  8, MNIST Batch 2: Loss:     0.4116 Validation Accuracy: 0.911200\n",
      "Epoch  8, MNIST Batch 3: Loss:     0.3893 Validation Accuracy: 0.910800\n",
      "Epoch  8, MNIST Batch 4: Loss:     0.3295 Validation Accuracy: 0.910800\n",
      "Epoch  8, MNIST Batch 5: Loss:     0.3651 Validation Accuracy: 0.910600\n",
      "Epoch  8, MNIST Batch 6: Loss:     0.4065 Validation Accuracy: 0.910400\n",
      "Epoch  8, MNIST Batch 7: Loss:     0.3718 Validation Accuracy: 0.910400\n",
      "Epoch  8, MNIST Batch 8: Loss:     0.3723 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 9: Loss:     0.3066 Validation Accuracy: 0.909200\n",
      "Epoch  8, MNIST Batch 10: Loss:     0.3712 Validation Accuracy: 0.909400\n",
      "Epoch  8, MNIST Batch 11: Loss:     0.3612 Validation Accuracy: 0.908600\n",
      "Epoch  8, MNIST Batch 12: Loss:     0.4118 Validation Accuracy: 0.908400\n",
      "Epoch  8, MNIST Batch 13: Loss:     0.3954 Validation Accuracy: 0.908400\n",
      "Epoch  8, MNIST Batch 14: Loss:     0.3282 Validation Accuracy: 0.908200\n",
      "Epoch  8, MNIST Batch 15: Loss:     0.3922 Validation Accuracy: 0.908200\n",
      "Epoch  8, MNIST Batch 16: Loss:     0.3569 Validation Accuracy: 0.908800\n",
      "Epoch  8, MNIST Batch 17: Loss:     0.3502 Validation Accuracy: 0.909000\n",
      "Epoch  8, MNIST Batch 18: Loss:     0.3532 Validation Accuracy: 0.909400\n",
      "Epoch  8, MNIST Batch 19: Loss:     0.4055 Validation Accuracy: 0.909200\n",
      "Epoch  8, MNIST Batch 20: Loss:     0.3736 Validation Accuracy: 0.909400\n",
      "Epoch  8, MNIST Batch 21: Loss:     0.3614 Validation Accuracy: 0.909400\n",
      "Epoch  8, MNIST Batch 22: Loss:     0.3537 Validation Accuracy: 0.909800\n",
      "Epoch  8, MNIST Batch 23: Loss:     0.3405 Validation Accuracy: 0.909800\n",
      "Epoch  8, MNIST Batch 24: Loss:     0.3680 Validation Accuracy: 0.909800\n",
      "Epoch  8, MNIST Batch 25: Loss:     0.3839 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 26: Loss:     0.4113 Validation Accuracy: 0.909800\n",
      "Epoch  8, MNIST Batch 27: Loss:     0.3118 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 28: Loss:     0.3151 Validation Accuracy: 0.910200\n",
      "Epoch  8, MNIST Batch 29: Loss:     0.3184 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 30: Loss:     0.4265 Validation Accuracy: 0.909800\n",
      "Epoch  8, MNIST Batch 31: Loss:     0.3511 Validation Accuracy: 0.909400\n",
      "Epoch  8, MNIST Batch 32: Loss:     0.3520 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 33: Loss:     0.3813 Validation Accuracy: 0.910000\n",
      "Epoch  8, MNIST Batch 34: Loss:     0.3598 Validation Accuracy: 0.911200\n",
      "Epoch  8, MNIST Batch 35: Loss:     0.3217 Validation Accuracy: 0.910600\n",
      "Epoch  8, MNIST Batch 36: Loss:     0.3729 Validation Accuracy: 0.910600\n",
      "Epoch  8, MNIST Batch 37: Loss:     0.3347 Validation Accuracy: 0.911000\n",
      "Epoch  8, MNIST Batch 38: Loss:     0.3040 Validation Accuracy: 0.911200\n",
      "Epoch  8, MNIST Batch 39: Loss:     0.3631 Validation Accuracy: 0.911400\n",
      "Epoch  8, MNIST Batch 40: Loss:     0.3845 Validation Accuracy: 0.911600\n",
      "Epoch  8, MNIST Batch 41: Loss:     0.3595 Validation Accuracy: 0.911800\n",
      "Epoch  8, MNIST Batch 42: Loss:     0.3215 Validation Accuracy: 0.912400\n",
      "Epoch  8, MNIST Batch 43: Loss:     0.3225 Validation Accuracy: 0.912800\n",
      "Epoch  8, MNIST Batch 44: Loss:     0.3192 Validation Accuracy: 0.913000\n",
      "Epoch  8, MNIST Batch 45: Loss:     0.3420 Validation Accuracy: 0.913200\n",
      "Epoch  8, MNIST Batch 46: Loss:     0.3710 Validation Accuracy: 0.913000\n",
      "Epoch  8, MNIST Batch 47: Loss:     0.3011 Validation Accuracy: 0.912600\n",
      "Epoch  8, MNIST Batch 48: Loss:     0.3363 Validation Accuracy: 0.912600\n",
      "Epoch  8, MNIST Batch 49: Loss:     0.3502 Validation Accuracy: 0.912800\n",
      "Epoch  8, MNIST Batch 50: Loss:     0.4037 Validation Accuracy: 0.912600\n",
      "Epoch  8, MNIST Batch 51: Loss:     0.3189 Validation Accuracy: 0.912600\n",
      "Epoch  8, MNIST Batch 52: Loss:     0.3856 Validation Accuracy: 0.912400\n",
      "Epoch  8, MNIST Batch 53: Loss:     0.3530 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 54: Loss:     0.3811 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 55: Loss:     0.3688 Validation Accuracy: 0.911800\n",
      "Epoch  8, MNIST Batch 56: Loss:     0.3679 Validation Accuracy: 0.912200\n",
      "Epoch  8, MNIST Batch 57: Loss:     0.3814 Validation Accuracy: 0.912200\n",
      "Epoch  8, MNIST Batch 58: Loss:     0.3435 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 59: Loss:     0.3305 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 60: Loss:     0.3437 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 61: Loss:     0.3342 Validation Accuracy: 0.912000\n",
      "Epoch  8, MNIST Batch 62: Loss:     0.3398 Validation Accuracy: 0.912200\n",
      "Epoch  8, MNIST Batch 63: Loss:     0.3264 Validation Accuracy: 0.912800\n",
      "Epoch  8, MNIST Batch 64: Loss:     0.3193 Validation Accuracy: 0.913200\n",
      "Epoch  8, MNIST Batch 65: Loss:     0.3639 Validation Accuracy: 0.913600\n",
      "Epoch  8, MNIST Batch 66: Loss:     0.3327 Validation Accuracy: 0.914000\n",
      "Epoch  8, MNIST Batch 67: Loss:     0.3127 Validation Accuracy: 0.914000\n",
      "Epoch  8, MNIST Batch 68: Loss:     0.3516 Validation Accuracy: 0.914200\n",
      "Epoch  8, MNIST Batch 69: Loss:     0.3159 Validation Accuracy: 0.914000\n",
      "Epoch  8, MNIST Batch 70: Loss:     0.3181 Validation Accuracy: 0.913600\n",
      "Epoch  8, MNIST Batch 71: Loss:     0.3821 Validation Accuracy: 0.914000\n",
      "Epoch  8, MNIST Batch 72: Loss:     0.3346 Validation Accuracy: 0.913800\n",
      "Epoch  8, MNIST Batch 73: Loss:     0.3146 Validation Accuracy: 0.913800\n",
      "Epoch  8, MNIST Batch 74: Loss:     0.3202 Validation Accuracy: 0.914800\n",
      "Epoch  8, MNIST Batch 75: Loss:     0.3450 Validation Accuracy: 0.915400\n",
      "Epoch  8, MNIST Batch 76: Loss:     0.3400 Validation Accuracy: 0.915800\n",
      "Epoch  8, MNIST Batch 77: Loss:     0.3624 Validation Accuracy: 0.916200\n",
      "Epoch  8, MNIST Batch 78: Loss:     0.2921 Validation Accuracy: 0.917200\n",
      "Epoch  8, MNIST Batch 79: Loss:     0.2917 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 80: Loss:     0.3170 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 81: Loss:     0.2675 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 82: Loss:     0.3391 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 83: Loss:     0.3458 Validation Accuracy: 0.917400\n",
      "Epoch  8, MNIST Batch 84: Loss:     0.3040 Validation Accuracy: 0.917000\n",
      "Epoch  8, MNIST Batch 85: Loss:     0.3586 Validation Accuracy: 0.917200\n",
      "Epoch  8, MNIST Batch 86: Loss:     0.3109 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 87: Loss:     0.3684 Validation Accuracy: 0.917000\n",
      "Epoch  8, MNIST Batch 88: Loss:     0.3165 Validation Accuracy: 0.916200\n",
      "Epoch  8, MNIST Batch 89: Loss:     0.4028 Validation Accuracy: 0.915800\n",
      "Epoch  8, MNIST Batch 90: Loss:     0.3288 Validation Accuracy: 0.915400\n",
      "Epoch  8, MNIST Batch 91: Loss:     0.3386 Validation Accuracy: 0.916200\n",
      "Epoch  8, MNIST Batch 92: Loss:     0.3486 Validation Accuracy: 0.916400\n",
      "Epoch  8, MNIST Batch 93: Loss:     0.3288 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 94: Loss:     0.3790 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 95: Loss:     0.3385 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 96: Loss:     0.3053 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 97: Loss:     0.2981 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 98: Loss:     0.3577 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 99: Loss:     0.2943 Validation Accuracy: 0.917000\n",
      "Epoch  8, MNIST Batch 100: Loss:     0.3378 Validation Accuracy: 0.917400\n",
      "Epoch  8, MNIST Batch 101: Loss:     0.3485 Validation Accuracy: 0.917200\n",
      "Epoch  8, MNIST Batch 102: Loss:     0.2984 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 103: Loss:     0.3271 Validation Accuracy: 0.916800\n",
      "Epoch  8, MNIST Batch 104: Loss:     0.3252 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 105: Loss:     0.3495 Validation Accuracy: 0.916600\n",
      "Epoch  8, MNIST Batch 106: Loss:     0.3566 Validation Accuracy: 0.916400\n",
      "Epoch  9, MNIST Batch 0: Loss:     0.3554 Validation Accuracy: 0.916200\n",
      "Epoch  9, MNIST Batch 1: Loss:     0.3240 Validation Accuracy: 0.916800\n",
      "Epoch  9, MNIST Batch 2: Loss:     0.3669 Validation Accuracy: 0.916800\n",
      "Epoch  9, MNIST Batch 3: Loss:     0.3400 Validation Accuracy: 0.916000\n",
      "Epoch  9, MNIST Batch 4: Loss:     0.3415 Validation Accuracy: 0.916400\n",
      "Epoch  9, MNIST Batch 5: Loss:     0.3910 Validation Accuracy: 0.917200\n",
      "Epoch  9, MNIST Batch 6: Loss:     0.3720 Validation Accuracy: 0.917200\n",
      "Epoch  9, MNIST Batch 7: Loss:     0.3168 Validation Accuracy: 0.918000\n",
      "Epoch  9, MNIST Batch 8: Loss:     0.3416 Validation Accuracy: 0.917600\n",
      "Epoch  9, MNIST Batch 9: Loss:     0.3748 Validation Accuracy: 0.918800\n",
      "Epoch  9, MNIST Batch 10: Loss:     0.2932 Validation Accuracy: 0.918200\n",
      "Epoch  9, MNIST Batch 11: Loss:     0.3507 Validation Accuracy: 0.918000\n",
      "Epoch  9, MNIST Batch 12: Loss:     0.3621 Validation Accuracy: 0.918200\n",
      "Epoch  9, MNIST Batch 13: Loss:     0.3746 Validation Accuracy: 0.918200\n",
      "Epoch  9, MNIST Batch 14: Loss:     0.3698 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 15: Loss:     0.3044 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 16: Loss:     0.3181 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 17: Loss:     0.2978 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 18: Loss:     0.3298 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 19: Loss:     0.2968 Validation Accuracy: 0.920400\n",
      "Epoch  9, MNIST Batch 20: Loss:     0.3241 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 21: Loss:     0.3368 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 22: Loss:     0.2944 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 23: Loss:     0.3373 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 24: Loss:     0.2912 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 25: Loss:     0.3466 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 26: Loss:     0.3197 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 27: Loss:     0.3272 Validation Accuracy: 0.919800\n",
      "Epoch  9, MNIST Batch 28: Loss:     0.3193 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 29: Loss:     0.3157 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 30: Loss:     0.3066 Validation Accuracy: 0.919800\n",
      "Epoch  9, MNIST Batch 31: Loss:     0.3322 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 32: Loss:     0.3616 Validation Accuracy: 0.919000\n",
      "Epoch  9, MNIST Batch 33: Loss:     0.3073 Validation Accuracy: 0.918800\n",
      "Epoch  9, MNIST Batch 34: Loss:     0.3400 Validation Accuracy: 0.919000\n",
      "Epoch  9, MNIST Batch 35: Loss:     0.3035 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 36: Loss:     0.3195 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 37: Loss:     0.3028 Validation Accuracy: 0.919800\n",
      "Epoch  9, MNIST Batch 38: Loss:     0.3198 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 39: Loss:     0.3068 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 40: Loss:     0.2734 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 41: Loss:     0.3245 Validation Accuracy: 0.919800\n",
      "Epoch  9, MNIST Batch 42: Loss:     0.2967 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 43: Loss:     0.3381 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 44: Loss:     0.3564 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 45: Loss:     0.3483 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 46: Loss:     0.3399 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 47: Loss:     0.3010 Validation Accuracy: 0.919000\n",
      "Epoch  9, MNIST Batch 48: Loss:     0.3329 Validation Accuracy: 0.919000\n",
      "Epoch  9, MNIST Batch 49: Loss:     0.3243 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 50: Loss:     0.3342 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 51: Loss:     0.3514 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 52: Loss:     0.3071 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 53: Loss:     0.3057 Validation Accuracy: 0.919200\n",
      "Epoch  9, MNIST Batch 54: Loss:     0.3357 Validation Accuracy: 0.918800\n",
      "Epoch  9, MNIST Batch 55: Loss:     0.3201 Validation Accuracy: 0.918800\n",
      "Epoch  9, MNIST Batch 56: Loss:     0.2799 Validation Accuracy: 0.918800\n",
      "Epoch  9, MNIST Batch 57: Loss:     0.2628 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 58: Loss:     0.2973 Validation Accuracy: 0.919400\n",
      "Epoch  9, MNIST Batch 59: Loss:     0.3195 Validation Accuracy: 0.919000\n",
      "Epoch  9, MNIST Batch 60: Loss:     0.2671 Validation Accuracy: 0.919600\n",
      "Epoch  9, MNIST Batch 61: Loss:     0.3205 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 62: Loss:     0.3033 Validation Accuracy: 0.920400\n",
      "Epoch  9, MNIST Batch 63: Loss:     0.3308 Validation Accuracy: 0.920200\n",
      "Epoch  9, MNIST Batch 64: Loss:     0.2927 Validation Accuracy: 0.920400\n",
      "Epoch  9, MNIST Batch 65: Loss:     0.2687 Validation Accuracy: 0.920400\n",
      "Epoch  9, MNIST Batch 66: Loss:     0.3070 Validation Accuracy: 0.920400\n",
      "Epoch  9, MNIST Batch 67: Loss:     0.3210 Validation Accuracy: 0.920000\n",
      "Epoch  9, MNIST Batch 68: Loss:     0.3215 Validation Accuracy: 0.921000\n",
      "Epoch  9, MNIST Batch 69: Loss:     0.2824 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 70: Loss:     0.3403 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 71: Loss:     0.3128 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 72: Loss:     0.3271 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 73: Loss:     0.2868 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 74: Loss:     0.2990 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 75: Loss:     0.2942 Validation Accuracy: 0.921200\n",
      "Epoch  9, MNIST Batch 76: Loss:     0.2977 Validation Accuracy: 0.921800\n",
      "Epoch  9, MNIST Batch 77: Loss:     0.2390 Validation Accuracy: 0.922000\n",
      "Epoch  9, MNIST Batch 78: Loss:     0.3023 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 79: Loss:     0.2723 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 80: Loss:     0.3407 Validation Accuracy: 0.922000\n",
      "Epoch  9, MNIST Batch 81: Loss:     0.3875 Validation Accuracy: 0.921800\n",
      "Epoch  9, MNIST Batch 82: Loss:     0.3531 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 83: Loss:     0.3466 Validation Accuracy: 0.921800\n",
      "Epoch  9, MNIST Batch 84: Loss:     0.2969 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 85: Loss:     0.2931 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 86: Loss:     0.3226 Validation Accuracy: 0.922000\n",
      "Epoch  9, MNIST Batch 87: Loss:     0.3078 Validation Accuracy: 0.921800\n",
      "Epoch  9, MNIST Batch 88: Loss:     0.3109 Validation Accuracy: 0.922600\n",
      "Epoch  9, MNIST Batch 89: Loss:     0.2681 Validation Accuracy: 0.922200\n",
      "Epoch  9, MNIST Batch 90: Loss:     0.2921 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 91: Loss:     0.3490 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 92: Loss:     0.2981 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 93: Loss:     0.3289 Validation Accuracy: 0.921200\n",
      "Epoch  9, MNIST Batch 94: Loss:     0.3074 Validation Accuracy: 0.921200\n",
      "Epoch  9, MNIST Batch 95: Loss:     0.3049 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 96: Loss:     0.2965 Validation Accuracy: 0.921200\n",
      "Epoch  9, MNIST Batch 97: Loss:     0.3214 Validation Accuracy: 0.921600\n",
      "Epoch  9, MNIST Batch 98: Loss:     0.3279 Validation Accuracy: 0.921400\n",
      "Epoch  9, MNIST Batch 99: Loss:     0.2763 Validation Accuracy: 0.922200\n",
      "Epoch  9, MNIST Batch 100: Loss:     0.3240 Validation Accuracy: 0.923000\n",
      "Epoch  9, MNIST Batch 101: Loss:     0.2458 Validation Accuracy: 0.923200\n",
      "Epoch  9, MNIST Batch 102: Loss:     0.3503 Validation Accuracy: 0.923800\n",
      "Epoch  9, MNIST Batch 103: Loss:     0.3403 Validation Accuracy: 0.924000\n",
      "Epoch  9, MNIST Batch 104: Loss:     0.3381 Validation Accuracy: 0.924600\n",
      "Epoch  9, MNIST Batch 105: Loss:     0.2713 Validation Accuracy: 0.924800\n",
      "Epoch  9, MNIST Batch 106: Loss:     0.3185 Validation Accuracy: 0.924600\n",
      "Epoch 10, MNIST Batch 0: Loss:     0.3659 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 1: Loss:     0.2827 Validation Accuracy: 0.923600\n",
      "Epoch 10, MNIST Batch 2: Loss:     0.3638 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 3: Loss:     0.2899 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 4: Loss:     0.2793 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 5: Loss:     0.3080 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 6: Loss:     0.2581 Validation Accuracy: 0.923800\n",
      "Epoch 10, MNIST Batch 7: Loss:     0.2675 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 8: Loss:     0.2842 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 9: Loss:     0.2948 Validation Accuracy: 0.923800\n",
      "Epoch 10, MNIST Batch 10: Loss:     0.3283 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 11: Loss:     0.2817 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 12: Loss:     0.2374 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 13: Loss:     0.2684 Validation Accuracy: 0.923800\n",
      "Epoch 10, MNIST Batch 14: Loss:     0.2775 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 15: Loss:     0.3298 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 16: Loss:     0.2698 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 17: Loss:     0.2885 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 18: Loss:     0.2784 Validation Accuracy: 0.924600\n",
      "Epoch 10, MNIST Batch 19: Loss:     0.3599 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 20: Loss:     0.2921 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 21: Loss:     0.3339 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 22: Loss:     0.2931 Validation Accuracy: 0.924200\n",
      "Epoch 10, MNIST Batch 23: Loss:     0.2670 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 24: Loss:     0.3106 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 25: Loss:     0.2558 Validation Accuracy: 0.924800\n",
      "Epoch 10, MNIST Batch 26: Loss:     0.3040 Validation Accuracy: 0.925600\n",
      "Epoch 10, MNIST Batch 27: Loss:     0.2875 Validation Accuracy: 0.925200\n",
      "Epoch 10, MNIST Batch 28: Loss:     0.3193 Validation Accuracy: 0.925200\n",
      "Epoch 10, MNIST Batch 29: Loss:     0.2534 Validation Accuracy: 0.925000\n",
      "Epoch 10, MNIST Batch 30: Loss:     0.2731 Validation Accuracy: 0.925000\n",
      "Epoch 10, MNIST Batch 31: Loss:     0.2989 Validation Accuracy: 0.924800\n",
      "Epoch 10, MNIST Batch 32: Loss:     0.2847 Validation Accuracy: 0.924800\n",
      "Epoch 10, MNIST Batch 33: Loss:     0.3168 Validation Accuracy: 0.924000\n",
      "Epoch 10, MNIST Batch 34: Loss:     0.3011 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 35: Loss:     0.2855 Validation Accuracy: 0.924400\n",
      "Epoch 10, MNIST Batch 36: Loss:     0.3244 Validation Accuracy: 0.925000\n",
      "Epoch 10, MNIST Batch 37: Loss:     0.2791 Validation Accuracy: 0.924800\n",
      "Epoch 10, MNIST Batch 38: Loss:     0.2770 Validation Accuracy: 0.925400\n",
      "Epoch 10, MNIST Batch 39: Loss:     0.3085 Validation Accuracy: 0.925600\n",
      "Epoch 10, MNIST Batch 40: Loss:     0.3243 Validation Accuracy: 0.926200\n",
      "Epoch 10, MNIST Batch 41: Loss:     0.3139 Validation Accuracy: 0.926200\n",
      "Epoch 10, MNIST Batch 42: Loss:     0.2648 Validation Accuracy: 0.926000\n",
      "Epoch 10, MNIST Batch 43: Loss:     0.3169 Validation Accuracy: 0.926600\n",
      "Epoch 10, MNIST Batch 44: Loss:     0.3111 Validation Accuracy: 0.926800\n",
      "Epoch 10, MNIST Batch 45: Loss:     0.2544 Validation Accuracy: 0.927000\n",
      "Epoch 10, MNIST Batch 46: Loss:     0.3177 Validation Accuracy: 0.927400\n",
      "Epoch 10, MNIST Batch 47: Loss:     0.2682 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 48: Loss:     0.2049 Validation Accuracy: 0.927400\n",
      "Epoch 10, MNIST Batch 49: Loss:     0.3176 Validation Accuracy: 0.926400\n",
      "Epoch 10, MNIST Batch 50: Loss:     0.2969 Validation Accuracy: 0.926800\n",
      "Epoch 10, MNIST Batch 51: Loss:     0.2819 Validation Accuracy: 0.926800\n",
      "Epoch 10, MNIST Batch 52: Loss:     0.2759 Validation Accuracy: 0.926800\n",
      "Epoch 10, MNIST Batch 53: Loss:     0.2897 Validation Accuracy: 0.926800\n",
      "Epoch 10, MNIST Batch 54: Loss:     0.2997 Validation Accuracy: 0.927200\n",
      "Epoch 10, MNIST Batch 55: Loss:     0.2916 Validation Accuracy: 0.927800\n",
      "Epoch 10, MNIST Batch 56: Loss:     0.2850 Validation Accuracy: 0.928200\n",
      "Epoch 10, MNIST Batch 57: Loss:     0.2536 Validation Accuracy: 0.928200\n",
      "Epoch 10, MNIST Batch 58: Loss:     0.2830 Validation Accuracy: 0.928000\n",
      "Epoch 10, MNIST Batch 59: Loss:     0.2981 Validation Accuracy: 0.927800\n",
      "Epoch 10, MNIST Batch 60: Loss:     0.3229 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 61: Loss:     0.2814 Validation Accuracy: 0.928000\n",
      "Epoch 10, MNIST Batch 62: Loss:     0.2463 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 63: Loss:     0.2980 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 64: Loss:     0.2222 Validation Accuracy: 0.928400\n",
      "Epoch 10, MNIST Batch 65: Loss:     0.2971 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 66: Loss:     0.2333 Validation Accuracy: 0.927600\n",
      "Epoch 10, MNIST Batch 67: Loss:     0.3388 Validation Accuracy: 0.926600\n",
      "Epoch 10, MNIST Batch 68: Loss:     0.2706 Validation Accuracy: 0.926600\n",
      "Epoch 10, MNIST Batch 69: Loss:     0.2876 Validation Accuracy: 0.926000\n",
      "Epoch 10, MNIST Batch 70: Loss:     0.3423 Validation Accuracy: 0.925000\n",
      "Epoch 10, MNIST Batch 71: Loss:     0.2441 Validation Accuracy: 0.925200\n",
      "Epoch 10, MNIST Batch 72: Loss:     0.2566 Validation Accuracy: 0.926000\n",
      "Epoch 10, MNIST Batch 73: Loss:     0.2288 Validation Accuracy: 0.925800\n",
      "Epoch 10, MNIST Batch 74: Loss:     0.3072 Validation Accuracy: 0.926400\n",
      "Epoch 10, MNIST Batch 75: Loss:     0.2696 Validation Accuracy: 0.926400\n",
      "Epoch 10, MNIST Batch 76: Loss:     0.3055 Validation Accuracy: 0.926000\n",
      "Epoch 10, MNIST Batch 77: Loss:     0.3513 Validation Accuracy: 0.926000\n",
      "Epoch 10, MNIST Batch 78: Loss:     0.3196 Validation Accuracy: 0.925200\n",
      "Epoch 10, MNIST Batch 79: Loss:     0.3023 Validation Accuracy: 0.925000\n",
      "Epoch 10, MNIST Batch 80: Loss:     0.2604 Validation Accuracy: 0.925400\n",
      "Epoch 10, MNIST Batch 81: Loss:     0.2440 Validation Accuracy: 0.925600\n",
      "Epoch 10, MNIST Batch 82: Loss:     0.2777 Validation Accuracy: 0.925600\n",
      "Epoch 10, MNIST Batch 83: Loss:     0.2589 Validation Accuracy: 0.925400\n",
      "Epoch 10, MNIST Batch 84: Loss:     0.2418 Validation Accuracy: 0.925800\n",
      "Epoch 10, MNIST Batch 85: Loss:     0.2431 Validation Accuracy: 0.925600\n",
      "Epoch 10, MNIST Batch 86: Loss:     0.2986 Validation Accuracy: 0.925800\n",
      "Epoch 10, MNIST Batch 87: Loss:     0.3052 Validation Accuracy: 0.927400\n",
      "Epoch 10, MNIST Batch 88: Loss:     0.2767 Validation Accuracy: 0.927400\n",
      "Epoch 10, MNIST Batch 89: Loss:     0.3034 Validation Accuracy: 0.927200\n",
      "Epoch 10, MNIST Batch 90: Loss:     0.2978 Validation Accuracy: 0.928000\n",
      "Epoch 10, MNIST Batch 91: Loss:     0.3081 Validation Accuracy: 0.928800\n",
      "Epoch 10, MNIST Batch 92: Loss:     0.2388 Validation Accuracy: 0.929000\n",
      "Epoch 10, MNIST Batch 93: Loss:     0.2853 Validation Accuracy: 0.928600\n",
      "Epoch 10, MNIST Batch 94: Loss:     0.2332 Validation Accuracy: 0.928600\n",
      "Epoch 10, MNIST Batch 95: Loss:     0.2390 Validation Accuracy: 0.928400\n",
      "Epoch 10, MNIST Batch 96: Loss:     0.2587 Validation Accuracy: 0.928800\n",
      "Epoch 10, MNIST Batch 97: Loss:     0.2613 Validation Accuracy: 0.929000\n",
      "Epoch 10, MNIST Batch 98: Loss:     0.2625 Validation Accuracy: 0.929200\n",
      "Epoch 10, MNIST Batch 99: Loss:     0.2798 Validation Accuracy: 0.929000\n",
      "Epoch 10, MNIST Batch 100: Loss:     0.3162 Validation Accuracy: 0.929000\n",
      "Epoch 10, MNIST Batch 101: Loss:     0.2368 Validation Accuracy: 0.928800\n",
      "Epoch 10, MNIST Batch 102: Loss:     0.2358 Validation Accuracy: 0.928800\n",
      "Epoch 10, MNIST Batch 103: Loss:     0.2719 Validation Accuracy: 0.928400\n",
      "Epoch 10, MNIST Batch 104: Loss:     0.2804 Validation Accuracy: 0.928400\n",
      "Epoch 10, MNIST Batch 105: Loss:     0.3070 Validation Accuracy: 0.928600\n",
      "Epoch 10, MNIST Batch 106: Loss:     0.2575 Validation Accuracy: 0.928200\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './numbers_network_model'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            batch_features = batch[0].reshape((-1, 28, 28, 1))\n",
    "            batch_labels = batch[1]\n",
    "            train_neural_network(sess, optimizer, keep_probability, learning_rate, batch_features, batch_labels)\n",
    "            \n",
    "            print_training_stats(sess, epoch, i, \n",
    "                                 batch_features, batch_labels, \n",
    "                                 mnist.validation.images.reshape((-1, 28, 28, 1)), mnist.validation.labels,\n",
    "                                 cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testing the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Testing helpers\n",
    "\n",
    "def display_image_predictions(features, labels, predictions, n_classes):\n",
    "   \n",
    "    label_names = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=3)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "        axies[image_i][0].imshow(feature.reshape((feature.shape[0],feature.shape[1])))\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./numbers_network_model\n",
      "Testing Accuracy: 0.09498355263157894\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAAJ/CAYAAADRS4SdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAMCQ4AAAAQ4IDAAAw9AsYeLYN4ZSTBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feef66d9da0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 391
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    test_features = mnist.test.images.reshape((-1, 28, 28, 1))\n",
    "    test_labels = mnist.test.labels\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Getting Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for i in range(mnist.test.num_examples//batch_size):\n",
    "            batch = mnist.test.next_batch(batch_size)\n",
    "            test_feature_batch = batch[0].reshape((-1, 28, 28, 1))\n",
    "            test_label_batch = batch[1]\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0 })\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions, 10)\n",
    "        sess.close()\n",
    "test_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
