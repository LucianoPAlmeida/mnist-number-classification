{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing an image data set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaQIP5DU/wHqtjK9R1KWEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121e07518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "label = mnist.train.labels[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(inputs):\n",
    "    conv = tf.layers.conv2d(inputs, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    conv = tf.layers.max_pooling2d(conv, 16, (2,2), padding='same')\n",
    "    \n",
    "    conv = tf.layers.conv2d(inputs, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    conv = tf.layers.max_pooling2d(conv, 8, (2,2), padding='same')\n",
    "        \n",
    "    conv = tf.layers.conv2d(inputs, 4, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    conv = tf.layers.max_pooling2d(conv, 4, (2,2), padding='same')\n",
    "    \n",
    "    conv = tf.contrib.layers.flatten(conv)\n",
    "    \n",
    "    conv = tf.contrib.layers.fully_connected(conv, 10)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name='inputs')\n",
    "targets_ = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='targets')\n",
    "\n",
    "#Building the network\n",
    "\n",
    "logits = conv_net(inputs_)\n",
    "\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets_))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(targets_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network training hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training helper functions    \n",
    "\n",
    "def train_neural_network(session, optimizer, feature_batch, label_batch):\n",
    "    session.run(optimizer, feed_dict={\n",
    "        inputs_: feature_batch,\n",
    "        targets_: label_batch,\n",
    "        keep_prob: keep_probability \n",
    "    })\n",
    "    \n",
    "def print_training_stats(session, epoch, batch_i, feature_batch, label_batch, validation_feature, validation_label, cost, accuracy):\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "                inputs_: feature_batch,\n",
    "                targets_: label_batch})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                inputs_: validation_feature,\n",
    "                targets_: validation_label })\n",
    "    print('Epoch {:>2}, MNIST Batch {}: Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch + 1, batch_i, loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, MNIST Batch 0: Loss:     2.2739 Validation Accuracy: 0.138600\n",
      "Epoch  1, MNIST Batch 1: Loss:     2.2557 Validation Accuracy: 0.159800\n",
      "Epoch  1, MNIST Batch 2: Loss:     2.2157 Validation Accuracy: 0.180400\n",
      "Epoch  1, MNIST Batch 3: Loss:     2.2235 Validation Accuracy: 0.209600\n",
      "Epoch  1, MNIST Batch 4: Loss:     2.1742 Validation Accuracy: 0.243200\n",
      "Epoch  1, MNIST Batch 5: Loss:     2.1860 Validation Accuracy: 0.285800\n",
      "Epoch  1, MNIST Batch 6: Loss:     2.1483 Validation Accuracy: 0.324400\n",
      "Epoch  1, MNIST Batch 7: Loss:     2.1285 Validation Accuracy: 0.362800\n",
      "Epoch  1, MNIST Batch 8: Loss:     2.1259 Validation Accuracy: 0.397600\n",
      "Epoch  1, MNIST Batch 9: Loss:     2.1217 Validation Accuracy: 0.426200\n",
      "Epoch  1, MNIST Batch 10: Loss:     2.0699 Validation Accuracy: 0.457600\n",
      "Epoch  1, MNIST Batch 11: Loss:     2.0291 Validation Accuracy: 0.485400\n",
      "Epoch  1, MNIST Batch 12: Loss:     2.0106 Validation Accuracy: 0.506200\n",
      "Epoch  1, MNIST Batch 13: Loss:     1.9947 Validation Accuracy: 0.521000\n",
      "Epoch  1, MNIST Batch 14: Loss:     2.0295 Validation Accuracy: 0.543600\n",
      "Epoch  1, MNIST Batch 15: Loss:     1.9427 Validation Accuracy: 0.560800\n",
      "Epoch  1, MNIST Batch 16: Loss:     1.9167 Validation Accuracy: 0.579800\n",
      "Epoch  1, MNIST Batch 17: Loss:     1.9330 Validation Accuracy: 0.597600\n",
      "Epoch  1, MNIST Batch 18: Loss:     1.8922 Validation Accuracy: 0.609800\n",
      "Epoch  1, MNIST Batch 19: Loss:     1.8502 Validation Accuracy: 0.626800\n",
      "Epoch  1, MNIST Batch 20: Loss:     1.8417 Validation Accuracy: 0.640200\n",
      "Epoch  1, MNIST Batch 21: Loss:     1.8561 Validation Accuracy: 0.656600\n",
      "Epoch  1, MNIST Batch 22: Loss:     1.7742 Validation Accuracy: 0.663600\n",
      "Epoch  1, MNIST Batch 23: Loss:     1.7915 Validation Accuracy: 0.677600\n",
      "Epoch  1, MNIST Batch 24: Loss:     1.7648 Validation Accuracy: 0.686200\n",
      "Epoch  1, MNIST Batch 25: Loss:     1.7209 Validation Accuracy: 0.693600\n",
      "Epoch  1, MNIST Batch 26: Loss:     1.6834 Validation Accuracy: 0.699000\n",
      "Epoch  1, MNIST Batch 27: Loss:     1.7090 Validation Accuracy: 0.702000\n",
      "Epoch  1, MNIST Batch 28: Loss:     1.6046 Validation Accuracy: 0.709400\n",
      "Epoch  1, MNIST Batch 29: Loss:     1.6470 Validation Accuracy: 0.709800\n",
      "Epoch  1, MNIST Batch 30: Loss:     1.5700 Validation Accuracy: 0.713200\n",
      "Epoch  1, MNIST Batch 31: Loss:     1.5987 Validation Accuracy: 0.717800\n",
      "Epoch  1, MNIST Batch 32: Loss:     1.6091 Validation Accuracy: 0.721200\n",
      "Epoch  1, MNIST Batch 33: Loss:     1.5810 Validation Accuracy: 0.724600\n",
      "Epoch  1, MNIST Batch 34: Loss:     1.5854 Validation Accuracy: 0.727400\n",
      "Epoch  1, MNIST Batch 35: Loss:     1.5189 Validation Accuracy: 0.731200\n",
      "Epoch  1, MNIST Batch 36: Loss:     1.4381 Validation Accuracy: 0.730000\n",
      "Epoch  1, MNIST Batch 37: Loss:     1.4824 Validation Accuracy: 0.727600\n",
      "Epoch  1, MNIST Batch 38: Loss:     1.4264 Validation Accuracy: 0.726400\n",
      "Epoch  1, MNIST Batch 39: Loss:     1.4088 Validation Accuracy: 0.723400\n",
      "Epoch  1, MNIST Batch 40: Loss:     1.3816 Validation Accuracy: 0.722000\n",
      "Epoch  1, MNIST Batch 41: Loss:     1.3552 Validation Accuracy: 0.720400\n",
      "Epoch  1, MNIST Batch 42: Loss:     1.3901 Validation Accuracy: 0.719600\n",
      "Epoch  1, MNIST Batch 43: Loss:     1.3722 Validation Accuracy: 0.721200\n",
      "Epoch  1, MNIST Batch 44: Loss:     1.3650 Validation Accuracy: 0.725800\n",
      "Epoch  1, MNIST Batch 45: Loss:     1.3108 Validation Accuracy: 0.728600\n",
      "Epoch  1, MNIST Batch 46: Loss:     1.2307 Validation Accuracy: 0.733200\n",
      "Epoch  1, MNIST Batch 47: Loss:     1.2633 Validation Accuracy: 0.735800\n",
      "Epoch  1, MNIST Batch 48: Loss:     1.3197 Validation Accuracy: 0.741000\n",
      "Epoch  1, MNIST Batch 49: Loss:     1.3029 Validation Accuracy: 0.744600\n",
      "Epoch  1, MNIST Batch 50: Loss:     1.2401 Validation Accuracy: 0.748600\n",
      "Epoch  1, MNIST Batch 51: Loss:     1.1941 Validation Accuracy: 0.750800\n",
      "Epoch  1, MNIST Batch 52: Loss:     1.2460 Validation Accuracy: 0.751800\n",
      "Epoch  1, MNIST Batch 53: Loss:     1.2792 Validation Accuracy: 0.751600\n",
      "Epoch  1, MNIST Batch 54: Loss:     1.1484 Validation Accuracy: 0.751600\n",
      "Epoch  1, MNIST Batch 55: Loss:     1.1936 Validation Accuracy: 0.753400\n",
      "Epoch  1, MNIST Batch 56: Loss:     1.2060 Validation Accuracy: 0.753400\n",
      "Epoch  1, MNIST Batch 57: Loss:     1.0859 Validation Accuracy: 0.751600\n",
      "Epoch  1, MNIST Batch 58: Loss:     1.0588 Validation Accuracy: 0.751200\n",
      "Epoch  1, MNIST Batch 59: Loss:     1.1039 Validation Accuracy: 0.752000\n",
      "Epoch  1, MNIST Batch 60: Loss:     1.1386 Validation Accuracy: 0.754600\n",
      "Epoch  1, MNIST Batch 61: Loss:     1.0315 Validation Accuracy: 0.754000\n",
      "Epoch  1, MNIST Batch 62: Loss:     1.1125 Validation Accuracy: 0.757000\n",
      "Epoch  1, MNIST Batch 63: Loss:     1.0991 Validation Accuracy: 0.757800\n",
      "Epoch  1, MNIST Batch 64: Loss:     0.9709 Validation Accuracy: 0.760000\n",
      "Epoch  1, MNIST Batch 65: Loss:     1.0441 Validation Accuracy: 0.761000\n",
      "Epoch  1, MNIST Batch 66: Loss:     1.0431 Validation Accuracy: 0.761800\n",
      "Epoch  1, MNIST Batch 67: Loss:     1.0950 Validation Accuracy: 0.758400\n",
      "Epoch  1, MNIST Batch 68: Loss:     1.0562 Validation Accuracy: 0.761600\n",
      "Epoch  1, MNIST Batch 69: Loss:     1.0762 Validation Accuracy: 0.762200\n",
      "Epoch  1, MNIST Batch 70: Loss:     0.9805 Validation Accuracy: 0.761400\n",
      "Epoch  1, MNIST Batch 71: Loss:     1.0059 Validation Accuracy: 0.763000\n",
      "Epoch  1, MNIST Batch 72: Loss:     0.8772 Validation Accuracy: 0.765600\n",
      "Epoch  1, MNIST Batch 73: Loss:     0.9554 Validation Accuracy: 0.766600\n",
      "Epoch  1, MNIST Batch 74: Loss:     0.9547 Validation Accuracy: 0.769200\n",
      "Epoch  1, MNIST Batch 75: Loss:     0.9450 Validation Accuracy: 0.773200\n",
      "Epoch  1, MNIST Batch 76: Loss:     1.0325 Validation Accuracy: 0.772600\n",
      "Epoch  1, MNIST Batch 77: Loss:     0.9449 Validation Accuracy: 0.773000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-c3a26ccffe06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                  \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                  \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                  cost, accuracy)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-d5df4150aa41>\u001b[0m in \u001b[0;36mprint_training_stats\u001b[0;34m(session, epoch, batch_i, feature_batch, label_batch, validation_feature, validation_label, cost, accuracy)\u001b[0m\n\u001b[1;32m     14\u001b[0m     validation_accuracy = sess.run(accuracy, feed_dict={\n\u001b[1;32m     15\u001b[0m                 \u001b[0minputs_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 targets_: validation_label })\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:>2}, MNIST Batch {}: Loss: {:>10.4f} Validation Accuracy: {:.6f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_path = './network_model'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            batch_features = batch[0].reshape((-1, 28, 28, 1))\n",
    "            batch_labels = batch[1]\n",
    "            train_neural_network(sess, optimizer, batch_features, batch_labels)\n",
    "            \n",
    "            print_training_stats(sess, epoch, i, \n",
    "                                 batch_features, batch_labels, \n",
    "                                 mnist.validation.images.reshape((-1, 28, 28, 1)), mnist.validation.labels,\n",
    "                                 cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
